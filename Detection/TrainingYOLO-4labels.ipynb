{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de TrainingYOLO(4labels2,9loss).ipynb","provenance":[{"file_id":"11A2i5OzVt6-m3-doIIfJiRqT4X19mrKr","timestamp":1602106731803}],"collapsed_sections":[],"authorship_tag":"ABX9TyM86r+xPiqPCJtY8KVHO5zp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zCojgxQTMXok"},"source":["# Drive Mount"]},{"cell_type":"code","metadata":{"id":"KiJXSl65MVyQ","executionInfo":{"status":"ok","timestamp":1602094926757,"user_tz":-120,"elapsed":1224,"user":{"displayName":"ENRIC BONET","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnZRbbgPP9GLTgkDSgeJtYq-mOg5Pp-nCFLVRrRg=s64","userId":"02183648625159651878"}},"outputId":"345a86c1-d6bb-4435-ed3d-e23cbd25818f","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","\n","drive.mount('/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4vmEZ943WWuL"},"source":["#Requeriments"]},{"cell_type":"code","metadata":{"id":"naVTvamTWalw","executionInfo":{"status":"ok","timestamp":1602094929099,"user_tz":-120,"elapsed":3556,"user":{"displayName":"ENRIC BONET","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnZRbbgPP9GLTgkDSgeJtYq-mOg5Pp-nCFLVRrRg=s64","userId":"02183648625159651878"}},"outputId":"e9406bd5-6323-4af7-954a-911ff0285874","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip3 install -r '/drive/My Drive/GTSDB/requirements.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 1)) (0.9.0)\n","Requirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 2)) (0.8.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 3)) (0.2.2)\n","Requirement already satisfied: google-pasta==0.1.8 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 4)) (0.1.8)\n","Requirement already satisfied: grpcio==1.26.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 5)) (1.26.0)\n","Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 6)) (2.10.0)\n","Requirement already satisfied: Keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 7)) (2.3.1)\n","Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 8)) (1.0.8)\n","Requirement already satisfied: Keras-Preprocessing==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 9)) (1.1.0)\n","Requirement already satisfied: Markdown==3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 10)) (3.1.1)\n","Requirement already satisfied: numpy==1.18.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 11)) (1.18.1)\n","Requirement already satisfied: opencv-contrib-python==4.1.2.30 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 12)) (4.1.2.30)\n","Requirement already satisfied: opt-einsum==3.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 13)) (3.1.0)\n","Requirement already satisfied: protobuf==3.11.2 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 14)) (3.11.2)\n","Requirement already satisfied: PyYAML==5.3 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 15)) (5.3)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 16)) (1.4.1)\n","Requirement already satisfied: six==1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 17)) (1.14.0)\n","Requirement already satisfied: tensorboard==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 19)) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 20)) (1.15.1)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 21)) (1.1.0)\n","Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 22)) (4.41.1)\n","Requirement already satisfied: Werkzeug==0.16.0 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 23)) (0.16.0)\n","Requirement already satisfied: wrapt==1.11.2 in /usr/local/lib/python3.6/dist-packages (from -r /drive/My Drive/GTSDB/requirements.txt (line 24)) (1.11.2)\n","Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from Markdown==3.1.1->-r /drive/My Drive/GTSDB/requirements.txt (line 10)) (50.3.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->-r /drive/My Drive/GTSDB/requirements.txt (line 18)) (0.35.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P_FUSDo-NnR9"},"source":["# colors.py"]},{"cell_type":"code","metadata":{"id":"_Nh6e2zkNZkH"},"source":["def get_color(label):\n","    \"\"\" Return a color from a set of predefined colors. Contains 80 colors in total.\n","    code originally from https://github.com/fizyr/keras-retinanet/\n","    Args\n","        label: The label to get the color for.\n","    Returns\n","        A list of three values representing a RGB color.\n","    \"\"\"\n","    if label < len(colors):\n","        return colors[label]\n","    else:\n","        print('Label {} has no color, returning default.'.format(label))\n","        return (0, 255, 0)\n","\n","colors = [\n","    [31  , 0   , 255] ,\n","    [0   , 159 , 255] ,\n","    [255 , 95  , 0]   ,\n","    [255 , 19  , 0]   ,\n","    [255 , 0   , 0]   ,\n","    [255 , 38  , 0]   ,\n","    [0   , 255 , 25]  ,\n","    [255 , 0   , 133] ,\n","    [255 , 172 , 0]   ,\n","    [108 , 0   , 255] ,\n","    [0   , 82  , 255] ,\n","    [0   , 255 , 6]   ,\n","    [255 , 0   , 152] ,\n","    [223 , 0   , 255] ,\n","    [12  , 0   , 255] ,\n","    [0   , 255 , 178] ,\n","    [108 , 255 , 0]   ,\n","    [184 , 0   , 255] ,\n","    [255 , 0   , 76]  ,\n","    [146 , 255 , 0]   ,\n","    [51  , 0   , 255] ,\n","    [0   , 197 , 255] ,\n","    [255 , 248 , 0]   ,\n","    [255 , 0   , 19]  ,\n","    [255 , 0   , 38]  ,\n","    [89  , 255 , 0]   ,\n","    [127 , 255 , 0]   ,\n","    [255 , 153 , 0]   ,\n","    [0   , 255 , 255] ,\n","    [0   , 255 , 216] ,\n","    [0   , 255 , 121] ,\n","    [255 , 0   , 248] ,\n","    [70  , 0   , 255] ,\n","    [0   , 255 , 159] ,\n","    [0   , 216 , 255] ,\n","    [0   , 6   , 255] ,\n","    [0   , 63  , 255] ,\n","    [31  , 255 , 0]   ,\n","    [255 , 57  , 0]   ,\n","    [255 , 0   , 210] ,\n","    [0   , 255 , 102] ,\n","    [242 , 255 , 0]   ,\n","    [255 , 191 , 0]   ,\n","    [0   , 255 , 63]  ,\n","    [255 , 0   , 95]  ,\n","    [146 , 0   , 255] ,\n","    [184 , 255 , 0]   ,\n","    [255 , 114 , 0]   ,\n","    [0   , 255 , 235] ,\n","    [255 , 229 , 0]   ,\n","    [0   , 178 , 255] ,\n","    [255 , 0   , 114] ,\n","    [255 , 0   , 57]  ,\n","    [0   , 140 , 255] ,\n","    [0   , 121 , 255] ,\n","    [12  , 255 , 0]   ,\n","    [255 , 210 , 0]   ,\n","    [0   , 255 , 44]  ,\n","    [165 , 255 , 0]   ,\n","    [0   , 25  , 255] ,\n","    [0   , 255 , 140] ,\n","    [0   , 101 , 255] ,\n","    [0   , 255 , 82]  ,\n","    [223 , 255 , 0]   ,\n","    [242 , 0   , 255] ,\n","    [89  , 0   , 255] ,\n","    [165 , 0   , 255] ,\n","    [70  , 255 , 0]   ,\n","    [255 , 0   , 172] ,\n","    [255 , 76  , 0]   ,\n","    [203 , 255 , 0]   ,\n","    [204 , 0   , 255] ,\n","    [255 , 0   , 229] ,\n","    [255 , 133 , 0]   ,\n","    [127 , 0   , 255] ,\n","    [0   , 235 , 255] ,\n","    [0   , 255 , 197] ,\n","    [255 , 0   , 191] ,\n","    [0   , 44  , 255] ,\n","    [50  , 255 , 0]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EK4iUI-uNB9p"},"source":["# bbox.py"]},{"cell_type":"code","metadata":{"id":"dw0eYlEKNBfY"},"source":["import numpy as np\n","import os\n","import cv2\n","\n","class BoundBox:\n","    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n","        self.xmin = xmin\n","        self.ymin = ymin\n","        self.xmax = xmax\n","        self.ymax = ymax\n","        \n","        self.c       = c\n","        self.classes = classes\n","\n","        self.label = -1\n","        self.score = -1\n","\n","    def get_label(self):\n","        if self.label == -1:\n","            self.label = np.argmax(self.classes)\n","        \n","        return self.label\n","    \n","    def get_score(self):\n","        if self.score == -1:\n","            self.score = self.classes[self.get_label()]\n","            \n","        return self.score      \n","\n","def _interval_overlap(interval_a, interval_b):\n","    x1, x2 = interval_a\n","    x3, x4 = interval_b\n","\n","    if x3 < x1:\n","        if x4 < x1:\n","            return 0\n","        else:\n","            return min(x2,x4) - x1\n","    else:\n","        if x2 < x3:\n","             return 0\n","        else:\n","            return min(x2,x4) - x3    \n","\n","def bbox_iou(box1, box2):\n","    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n","    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n","    \n","    intersect = intersect_w * intersect_h\n","\n","    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n","    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n","    \n","    union = w1*h1 + w2*h2 - intersect\n","    \n","    return float(intersect) / union\n","\n","def draw_boxes(image, boxes, labels, obj_thresh, quiet=True):\n","    for box in boxes:\n","        label_str = ''\n","        label = -1\n","        \n","        for i in range(len(labels)):\n","            if box.classes[i] > obj_thresh:\n","                if label_str != '': label_str += ', '\n","                label_str += (labels[i] + ' ' + str(round(box.get_score()*100, 2)) + '%')\n","                label = i\n","            if not quiet: print(label_str)\n","                \n","        if label >= 0:\n","            text_size = cv2.getTextSize(label_str, cv2.FONT_HERSHEY_SIMPLEX, 1.1e-3 * image.shape[0], 5)\n","            width, height = text_size[0][0], text_size[0][1]\n","            region = np.array([[box.xmin-3,        box.ymin], \n","                               [box.xmin-3,        box.ymin-height-26], \n","                               [box.xmin+width+13, box.ymin-height-26], \n","                               [box.xmin+width+13, box.ymin]], dtype='int32')  \n","\n","            cv2.rectangle(img=image, pt1=(box.xmin,box.ymin), pt2=(box.xmax,box.ymax), color=get_color(label), thickness=5)\n","            cv2.fillPoly(img=image, pts=[region], color=get_color(label))\n","            cv2.putText(img=image, \n","                        text=label_str, \n","                        org=(box.xmin+13, box.ymin - 13), \n","                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n","                        fontScale=1e-3 * image.shape[0], \n","                        color=(0,0,0), \n","                        thickness=2)\n","        \n","    return image          "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArsZKMpyPq4z"},"source":["# image.py"]},{"cell_type":"code","metadata":{"id":"f3hY4WOJPtBh"},"source":["import cv2\n","import numpy as np\n","import copy\n","\n","def _rand_scale(scale):\n","    scale = np.random.uniform(1, scale)\n","    return scale if (np.random.randint(2) == 0) else 1./scale;\n","\n","def _constrain(min_v, max_v, value):\n","    if value < min_v: return min_v\n","    if value > max_v: return max_v\n","    return value \n","\n","def random_flip(image, flip):\n","    if flip == 1: return cv2.flip(image, 1)\n","    return image\n","\n","def correct_bounding_boxes(boxes, new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h):\n","    boxes = copy.deepcopy(boxes)\n","\n","    # randomize boxes' order\n","    np.random.shuffle(boxes)\n","\n","    # correct sizes and positions\n","    sx, sy = float(new_w)/image_w, float(new_h)/image_h\n","    zero_boxes = []\n","\n","    for i in range(len(boxes)):\n","        boxes[i]['xmin'] = int(_constrain(0, net_w, boxes[i]['xmin']*sx + dx))\n","        boxes[i]['xmax'] = int(_constrain(0, net_w, boxes[i]['xmax']*sx + dx))\n","        boxes[i]['ymin'] = int(_constrain(0, net_h, boxes[i]['ymin']*sy + dy))\n","        boxes[i]['ymax'] = int(_constrain(0, net_h, boxes[i]['ymax']*sy + dy))\n","\n","        if boxes[i]['xmax'] <= boxes[i]['xmin'] or boxes[i]['ymax'] <= boxes[i]['ymin']:\n","            zero_boxes += [i]\n","            continue\n","\n","        if flip == 1:\n","            swap = boxes[i]['xmin'];\n","            boxes[i]['xmin'] = net_w - boxes[i]['xmax']\n","            boxes[i]['xmax'] = net_w - swap\n","\n","    boxes = [boxes[i] for i in range(len(boxes)) if i not in zero_boxes]\n","\n","    return boxes\n","\n","def random_distort_image(image, hue=18, saturation=1.5, exposure=1.5):\n","    # determine scale factors\n","    dhue = np.random.uniform(-hue, hue)\n","    dsat = _rand_scale(saturation);\n","    dexp = _rand_scale(exposure);     \n","\n","    # convert RGB space to HSV space\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype('float')\n","    \n","    # change satuation and exposure\n","    image[:,:,1] *= dsat\n","    image[:,:,2] *= dexp\n","    \n","    # change hue\n","    image[:,:,0] += dhue\n","    image[:,:,0] -= (image[:,:,0] > 180)*180\n","    image[:,:,0] += (image[:,:,0] < 0)  *180\n","    \n","    # convert back to RGB from HSV\n","    return cv2.cvtColor(image.astype('uint8'), cv2.COLOR_HSV2RGB)\n","\n","def apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy):\n","    im_sized = cv2.resize(image, (new_w, new_h))\n","    \n","    if dx > 0: \n","        im_sized = np.pad(im_sized, ((0,0), (dx,0), (0,0)), mode='constant', constant_values=127)\n","    else:\n","        im_sized = im_sized[:,-dx:,:]\n","    if (new_w + dx) < net_w:\n","        im_sized = np.pad(im_sized, ((0,0), (0, net_w - (new_w+dx)), (0,0)), mode='constant', constant_values=127)\n","               \n","    if dy > 0: \n","        im_sized = np.pad(im_sized, ((dy,0), (0,0), (0,0)), mode='constant', constant_values=127)\n","    else:\n","        im_sized = im_sized[-dy:,:,:]\n","        \n","    if (new_h + dy) < net_h:\n","        im_sized = np.pad(im_sized, ((0, net_h - (new_h+dy)), (0,0), (0,0)), mode='constant', constant_values=127)\n","        \n","    return im_sized[:net_h, :net_w,:]     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RMh0EYYmODzB"},"source":["# utils.py"]},{"cell_type":"code","metadata":{"id":"9PCPElVSOGR6"},"source":["import cv2\n","import numpy as np\n","import os\n","from scipy.special import expit\n","\n","def _sigmoid(x):\n","    return expit(x)\n","\n","def makedirs(path):\n","    try:\n","        os.makedirs(path)\n","    except OSError:\n","        if not os.path.isdir(path):\n","            raise\n","\n","def evaluate(model, \n","             generator, \n","             iou_threshold=0.5,\n","             obj_thresh=0.5,\n","             nms_thresh=0.45,\n","             net_h=416,\n","             net_w=416,\n","             save_path=None):\n","    \"\"\" Evaluate a given dataset using a given model.\n","    code originally from https://github.com/fizyr/keras-retinanet\n","\n","    # Arguments\n","        model           : The model to evaluate.\n","        generator       : The generator that represents the dataset to evaluate.\n","        iou_threshold   : The threshold used to consider when a detection is positive or negative.\n","        obj_thresh      : The threshold used to distinguish between object and non-object\n","        nms_thresh      : The threshold used to determine whether two detections are duplicates\n","        net_h           : The height of the input image to the model, higher value results in better accuracy\n","        net_w           : The width of the input image to the model\n","        save_path       : The path to save images with visualized detections to.\n","    # Returns\n","        A dict mapping class names to mAP scores.\n","    \"\"\"    \n","    # gather all detections and annotations\n","    all_detections     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n","    all_annotations    = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n","\n","    for i in range(generator.size()):\n","        raw_image = [generator.load_image(i)]\n","\n","        # make the boxes and the labels\n","        pred_boxes = get_yolo_boxes(model, raw_image, net_h, net_w, generator.get_anchors(), obj_thresh, nms_thresh)[0]\n","\n","        score = np.array([box.get_score() for box in pred_boxes])\n","        pred_labels = np.array([box.label for box in pred_boxes])        \n","        \n","        if len(pred_boxes) > 0:\n","            pred_boxes = np.array([[box.xmin, box.ymin, box.xmax, box.ymax, box.get_score()] for box in pred_boxes]) \n","        else:\n","            pred_boxes = np.array([[]])  \n","        \n","        # sort the boxes and the labels according to scores\n","        score_sort = np.argsort(-score)\n","        pred_labels = pred_labels[score_sort]\n","        pred_boxes  = pred_boxes[score_sort]\n","        \n","        # copy detections to all_detections\n","        for label in range(generator.num_classes()):\n","            all_detections[i][label] = pred_boxes[pred_labels == label, :]\n","\n","        annotations = generator.load_annotation(i)\n","        \n","        # copy detections to all_annotations\n","        for label in range(generator.num_classes()):\n","            all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n","\n","    # compute mAP by comparing all detections and all annotations\n","    average_precisions = {}\n","    \n","    for label in range(generator.num_classes()):\n","        false_positives = np.zeros((0,))\n","        true_positives  = np.zeros((0,))\n","        scores          = np.zeros((0,))\n","        num_annotations = 0.0\n","\n","        for i in range(generator.size()):\n","            detections           = all_detections[i][label]\n","            annotations          = all_annotations[i][label]\n","            num_annotations     += annotations.shape[0]\n","            detected_annotations = []\n","\n","            for d in detections:\n","                scores = np.append(scores, d[4])\n","\n","                if annotations.shape[0] == 0:\n","                    false_positives = np.append(false_positives, 1)\n","                    true_positives  = np.append(true_positives, 0)\n","                    continue\n","\n","                overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n","                assigned_annotation = np.argmax(overlaps, axis=1)\n","                max_overlap         = overlaps[0, assigned_annotation]\n","\n","                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n","                    false_positives = np.append(false_positives, 0)\n","                    true_positives  = np.append(true_positives, 1)\n","                    detected_annotations.append(assigned_annotation)\n","                else:\n","                    false_positives = np.append(false_positives, 1)\n","                    true_positives  = np.append(true_positives, 0)\n","\n","        # no annotations -> AP for this class is 0 (is this correct?)\n","        if num_annotations == 0:\n","            average_precisions[label] = 0\n","            continue\n","\n","        # sort by score\n","        indices         = np.argsort(-scores)\n","        false_positives = false_positives[indices]\n","        true_positives  = true_positives[indices]\n","\n","        # compute false positives and true positives\n","        false_positives = np.cumsum(false_positives)\n","        true_positives  = np.cumsum(true_positives)\n","\n","        # compute recall and precision\n","        recall    = true_positives / num_annotations\n","        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n","\n","        # compute average precision\n","        average_precision  = compute_ap(recall, precision)  \n","        average_precisions[label] = average_precision\n","\n","    return average_precisions    \n","\n","def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n","    if (float(net_w)/image_w) < (float(net_h)/image_h):\n","        new_w = net_w\n","        new_h = (image_h*net_w)/image_w\n","    else:\n","        new_h = net_w\n","        new_w = (image_w*net_h)/image_h\n","        \n","    for i in range(len(boxes)):\n","        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n","        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n","        \n","        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n","        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n","        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n","        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n","        \n","def do_nms(boxes, nms_thresh):\n","    if len(boxes) > 0:\n","        nb_class = len(boxes[0].classes)\n","    else:\n","        return\n","        \n","    for c in range(nb_class):\n","        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n","\n","        for i in range(len(sorted_indices)):\n","            index_i = sorted_indices[i]\n","\n","            if boxes[index_i].classes[c] == 0: continue\n","\n","            for j in range(i+1, len(sorted_indices)):\n","                index_j = sorted_indices[j]\n","\n","                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n","                    boxes[index_j].classes[c] = 0\n","\n","def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n","    grid_h, grid_w = netout.shape[:2]\n","    nb_box = 3\n","    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n","    nb_class = netout.shape[-1] - 5\n","\n","    boxes = []\n","\n","    netout[..., :2]  = _sigmoid(netout[..., :2])\n","    netout[..., 4]   = _sigmoid(netout[..., 4])\n","    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n","    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n","\n","    for i in range(grid_h*grid_w):\n","        row = i // grid_w\n","        col = i % grid_w\n","        \n","        for b in range(nb_box):\n","            # 4th element is objectness score\n","            objectness = netout[row, col, b, 4]\n","            \n","            if(objectness <= obj_thresh): continue\n","            \n","            # first 4 elements are x, y, w, and h\n","            x, y, w, h = netout[row,col,b,:4]\n","\n","            x = (col + x) / grid_w # center position, unit: image width\n","            y = (row + y) / grid_h # center position, unit: image height\n","            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n","            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n","            \n","            # last elements are class probabilities\n","            classes = netout[row,col,b,5:]\n","            \n","            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n","\n","            boxes.append(box)\n","\n","    return boxes\n","\n","def preprocess_input(image, net_h, net_w):\n","    new_h, new_w, _ = image.shape\n","\n","    # determine the new size of the image\n","    if (float(net_w)/new_w) < (float(net_h)/new_h):\n","        new_h = (new_h * net_w)//new_w\n","        new_w = net_w\n","    else:\n","        new_w = (new_w * net_h)//new_h\n","        new_h = net_h\n","\n","    # resize the image to the new size\n","    resized = cv2.resize(image[:,:,::-1]/255., (new_w, new_h))\n","\n","    # embed the image into the standard letter box\n","    new_image = np.ones((net_h, net_w, 3)) * 0.5\n","    new_image[(net_h-new_h)//2:(net_h+new_h)//2, (net_w-new_w)//2:(net_w+new_w)//2, :] = resized\n","    new_image = np.expand_dims(new_image, 0)\n","\n","    return new_image\n","\n","def normalize(image):\n","    return image/255.\n","       \n","def get_yolo_boxes(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh):\n","    image_h, image_w, _ = images[0].shape\n","    nb_images           = len(images)\n","    batch_input         = np.zeros((nb_images, net_h, net_w, 3))\n","\n","    # preprocess the input\n","    for i in range(nb_images):\n","        batch_input[i] = preprocess_input(images[i], net_h, net_w)        \n","\n","    # run the prediction\n","    batch_output = model.predict_on_batch(batch_input)\n","    batch_boxes  = [None]*nb_images\n","\n","    for i in range(nb_images):\n","        yolos = [batch_output[0][i], batch_output[1][i], batch_output[2][i]]\n","        boxes = []\n","\n","        # decode the output of the network\n","        for j in range(len(yolos)):\n","            yolo_anchors = anchors[(2-j)*6:(3-j)*6] # config['model']['anchors']\n","            boxes += decode_netout(yolos[j], yolo_anchors, obj_thresh, net_h, net_w)\n","\n","        # correct the sizes of the bounding boxes\n","        correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n","\n","        # suppress non-maximal boxes\n","        do_nms(boxes, nms_thresh)        \n","           \n","        batch_boxes[i] = boxes\n","\n","    return batch_boxes        \n","\n","def compute_overlap(a, b):\n","    \"\"\"\n","    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n","    Parameters\n","    ----------\n","    a: (N, 4) ndarray of float\n","    b: (K, 4) ndarray of float\n","    Returns\n","    -------\n","    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n","    \"\"\"\n","    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n","\n","    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n","    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n","\n","    iw = np.maximum(iw, 0)\n","    ih = np.maximum(ih, 0)\n","\n","    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n","\n","    ua = np.maximum(ua, np.finfo(float).eps)\n","\n","    intersection = iw * ih\n","\n","    return intersection / ua  \n","    \n","def compute_ap(recall, precision):\n","    \"\"\" Compute the average precision, given the recall and precision curves.\n","    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n","\n","    # Arguments\n","        recall:    The recall curve (list).\n","        precision: The precision curve (list).\n","    # Returns\n","        The average precision as computed in py-faster-rcnn.\n","    \"\"\"\n","    # correct AP calculation\n","    # first append sentinel values at the end\n","    mrec = np.concatenate(([0.], recall, [1.]))\n","    mpre = np.concatenate(([0.], precision, [0.]))\n","\n","    # compute the precision envelope\n","    for i in range(mpre.size - 1, 0, -1):\n","        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","    # to calculate area under PR curve, look for points\n","    # where X axis (recall) changes value\n","    i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","    # and sum (\\Delta recall) * prec\n","    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap     \n","\n","def _softmax(x, axis=-1):\n","    x = x - np.amax(x, axis, keepdims=True)\n","    e_x = np.exp(x)\n","    \n","    return e_x / e_x.sum(axis, keepdims=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xXQWTg_OO-9s"},"source":["# voc.py"]},{"cell_type":"code","metadata":{"id":"z3kCPaKKPBiK"},"source":["import numpy as np\n","import os\n","import xml.etree.ElementTree as ET\n","import pickle\n","\n","def parse_voc_annotation(ann_dir, img_dir, cache_name, labels=[]):\n","    if os.path.exists(cache_name):\n","        with open(cache_name, 'rb') as handle:\n","            cache = pickle.load(handle)\n","        all_insts, seen_labels = cache['all_insts'], cache['seen_labels']\n","    else:\n","        all_insts = []\n","        seen_labels = {}\n","        \n","        for ann in sorted(os.listdir(ann_dir)):\n","            img = {'object':[]}\n","\n","            try:\n","                tree = ET.parse(ann_dir + ann)\n","            except Exception as e:\n","                print(e)\n","                print('Ignore this bad annotation: ' + ann_dir + ann)\n","                continue\n","            \n","            for elem in tree.iter():\n","                if 'filename' in elem.tag:\n","                    img['filename'] = img_dir + elem.text\n","                if 'width' in elem.tag:\n","                    img['width'] = int(elem.text)\n","                if 'height' in elem.tag:\n","                    img['height'] = int(elem.text)\n","                if 'object' in elem.tag or 'part' in elem.tag:\n","                    obj = {}\n","                    \n","                    for attr in list(elem):\n","                        if 'name' in attr.tag:\n","                            obj['name'] = attr.text\n","\n","                            if obj['name'] in seen_labels:\n","                                seen_labels[obj['name']] += 1\n","                            else:\n","                                seen_labels[obj['name']] = 1\n","                            \n","                            if len(labels) > 0 and obj['name'] not in labels:\n","                                break\n","                            else:\n","                                img['object'] += [obj]\n","                                \n","                        if 'bndbox' in attr.tag:\n","                            for dim in list(attr):\n","                                if 'xmin' in dim.tag:\n","                                    obj['xmin'] = int(round(float(dim.text)))\n","                                if 'ymin' in dim.tag:\n","                                    obj['ymin'] = int(round(float(dim.text)))\n","                                if 'xmax' in dim.tag:\n","                                    obj['xmax'] = int(round(float(dim.text)))\n","                                if 'ymax' in dim.tag:\n","                                    obj['ymax'] = int(round(float(dim.text)))\n","\n","            if len(img['object']) > 0:\n","                all_insts += [img]\n","\n","        cache = {'all_insts': all_insts, 'seen_labels': seen_labels}\n","        with open(cache_name, 'wb') as handle:\n","            pickle.dump(cache, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n","                        \n","    return all_insts, seen_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGLOqXFHOhGN"},"source":["# yolo.py"]},{"cell_type":"code","metadata":{"id":"eC7SDunjOgSK","executionInfo":{"status":"ok","timestamp":1602094932981,"user_tz":-120,"elapsed":7423,"user":{"displayName":"ENRIC BONET","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnZRbbgPP9GLTgkDSgeJtYq-mOg5Pp-nCFLVRrRg=s64","userId":"02183648625159651878"}},"outputId":"e37bfd2a-6589-4771-a053-b3e470154297","colab":{"base_uri":"https://localhost:8080/"}},"source":["from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, Lambda\n","from keras.layers.merge import add, concatenate\n","from keras.models import Model\n","from keras.engine.topology import Layer\n","import tensorflow as tf\n","\n","debug = False\n","\n","class YoloLayer(Layer):\n","    def __init__(self, anchors, max_grid, batch_size, warmup_batches, ignore_thresh, \n","                    grid_scale, obj_scale, noobj_scale, xywh_scale, class_scale, \n","                    **kwargs):\n","        # make the model settings persistent\n","        self.ignore_thresh  = ignore_thresh\n","        self.warmup_batches = warmup_batches\n","        self.anchors        = tf.constant(anchors, dtype='float', shape=[1,1,1,3,2])\n","        self.grid_scale     = grid_scale\n","        self.obj_scale      = obj_scale\n","        self.noobj_scale    = noobj_scale\n","        self.xywh_scale     = xywh_scale\n","        self.class_scale    = class_scale        \n","\n","        # make a persistent mesh grid\n","        max_grid_h, max_grid_w = max_grid\n","\n","        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(max_grid_w), [max_grid_h]), (1, max_grid_h, max_grid_w, 1, 1)))\n","        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n","        self.cell_grid = tf.tile(tf.concat([cell_x,cell_y],-1), [batch_size, 1, 1, 3, 1])\n","\n","        super(YoloLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        super(YoloLayer, self).build(input_shape)  # Be sure to call this somewhere!\n","\n","    def call(self, x):\n","        input_image, y_pred, y_true, true_boxes = x\n","\n","        # adjust the shape of the y_predict [batch, grid_h, grid_w, 3, 4+1+nb_class]\n","        y_pred = tf.reshape(y_pred, tf.concat([tf.shape(y_pred)[:3], tf.constant([3, -1])], axis=0))\n","        \n","        # initialize the masks\n","        object_mask     = tf.expand_dims(y_true[..., 4], 4)\n","\n","        # the variable to keep track of number of batches processed\n","        batch_seen = tf.Variable(0.)        \n","\n","        # compute grid factor and net factor\n","        grid_h      = tf.shape(y_true)[1]\n","        grid_w      = tf.shape(y_true)[2]\n","        grid_factor = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1,1,1,1,2])\n","\n","        net_h       = tf.shape(input_image)[1]\n","        net_w       = tf.shape(input_image)[2]            \n","        net_factor  = tf.reshape(tf.cast([net_w, net_h], tf.float32), [1,1,1,1,2])\n","        \n","        \"\"\"\n","        Adjust prediction\n","        \"\"\"\n","        pred_box_xy    = (self.cell_grid[:,:grid_h,:grid_w,:,:] + tf.sigmoid(y_pred[..., :2]))  # sigma(t_xy) + c_xy\n","        pred_box_wh    = y_pred[..., 2:4]                                                       # t_wh\n","        pred_box_conf  = tf.expand_dims(tf.sigmoid(y_pred[..., 4]), 4)                          # adjust confidence\n","        pred_box_class = y_pred[..., 5:]                                                        # adjust class probabilities      \n","\n","        \"\"\"\n","        Adjust ground truth\n","        \"\"\"\n","        true_box_xy    = y_true[..., 0:2] # (sigma(t_xy) + c_xy)\n","        true_box_wh    = y_true[..., 2:4] # t_wh\n","        true_box_conf  = tf.expand_dims(y_true[..., 4], 4)\n","        true_box_class = tf.argmax(y_true[..., 5:], -1)         \n","\n","        \"\"\"\n","        Compare each predicted box to all true boxes\n","        \"\"\"        \n","        # initially, drag all objectness of all boxes to 0\n","        conf_delta  = pred_box_conf - 0 \n","\n","        # then, ignore the boxes which have good overlap with some true box\n","        true_xy = true_boxes[..., 0:2] / grid_factor\n","        true_wh = true_boxes[..., 2:4] / net_factor\n","        \n","        true_wh_half = true_wh / 2.\n","        true_mins    = true_xy - true_wh_half\n","        true_maxes   = true_xy + true_wh_half\n","        \n","        pred_xy = tf.expand_dims(pred_box_xy / grid_factor, 4)\n","        pred_wh = tf.expand_dims(tf.exp(pred_box_wh) * self.anchors / net_factor, 4)\n","        \n","        pred_wh_half = pred_wh / 2.\n","        pred_mins    = pred_xy - pred_wh_half\n","        pred_maxes   = pred_xy + pred_wh_half    \n","\n","        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n","        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n","\n","        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n","        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n","        \n","        true_areas = true_wh[..., 0] * true_wh[..., 1]\n","        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n","\n","        union_areas = pred_areas + true_areas - intersect_areas\n","        iou_scores  = tf.truediv(intersect_areas, union_areas)\n","\n","        best_ious   = tf.reduce_max(iou_scores, axis=4)        \n","        conf_delta *= tf.expand_dims(tf.to_float(best_ious < self.ignore_thresh), 4)\n","\n","        \"\"\"\n","        Compute some online statistics\n","        \"\"\"            \n","        true_xy = true_box_xy / grid_factor\n","        true_wh = tf.exp(true_box_wh) * self.anchors / net_factor\n","\n","        true_wh_half = true_wh / 2.\n","        true_mins    = true_xy - true_wh_half\n","        true_maxes   = true_xy + true_wh_half\n","\n","        pred_xy = pred_box_xy / grid_factor\n","        pred_wh = tf.exp(pred_box_wh) * self.anchors / net_factor \n","        \n","        pred_wh_half = pred_wh / 2.\n","        pred_mins    = pred_xy - pred_wh_half\n","        pred_maxes   = pred_xy + pred_wh_half      \n","\n","        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n","        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n","        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n","        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n","        \n","        true_areas = true_wh[..., 0] * true_wh[..., 1]\n","        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n","\n","        union_areas = pred_areas + true_areas - intersect_areas\n","        iou_scores  = tf.truediv(intersect_areas, union_areas)\n","        iou_scores  = object_mask * tf.expand_dims(iou_scores, 4)\n","        \n","        count       = tf.reduce_sum(object_mask)\n","        count_noobj = tf.reduce_sum(1 - object_mask)\n","        detect_mask = tf.to_float((pred_box_conf*object_mask) >= 0.5)\n","        class_mask  = tf.expand_dims(tf.to_float(tf.equal(tf.argmax(pred_box_class, -1), true_box_class)), 4)\n","        recall50    = tf.reduce_sum(tf.to_float(iou_scores >= 0.5 ) * detect_mask  * class_mask) / (count + 1e-3)\n","        recall75    = tf.reduce_sum(tf.to_float(iou_scores >= 0.75) * detect_mask  * class_mask) / (count + 1e-3)    \n","        avg_iou     = tf.reduce_sum(iou_scores) / (count + 1e-3)\n","        avg_obj     = tf.reduce_sum(pred_box_conf  * object_mask)  / (count + 1e-3)\n","        avg_noobj   = tf.reduce_sum(pred_box_conf  * (1-object_mask))  / (count_noobj + 1e-3)\n","        avg_cat     = tf.reduce_sum(object_mask * class_mask) / (count + 1e-3) \n","\n","        \"\"\"\n","        Warm-up training\n","        \"\"\"\n","        batch_seen = tf.assign_add(batch_seen, 1.)\n","        \n","        true_box_xy, true_box_wh, xywh_mask = tf.cond(tf.less(batch_seen, self.warmup_batches+1), \n","                              lambda: [true_box_xy + (0.5 + self.cell_grid[:,:grid_h,:grid_w,:,:]) * (1-object_mask), \n","                                       true_box_wh + tf.zeros_like(true_box_wh) * (1-object_mask), \n","                                       tf.ones_like(object_mask)],\n","                              lambda: [true_box_xy, \n","                                       true_box_wh,\n","                                       object_mask])\n","\n","        \"\"\"\n","        Compare each true box to all anchor boxes\n","        \"\"\"      \n","        wh_scale = tf.exp(true_box_wh) * self.anchors / net_factor\n","        wh_scale = tf.expand_dims(2 - wh_scale[..., 0] * wh_scale[..., 1], axis=4) # the smaller the box, the bigger the scale\n","\n","        xy_delta    = xywh_mask   * (pred_box_xy-true_box_xy) * wh_scale * self.xywh_scale\n","        wh_delta    = xywh_mask   * (pred_box_wh-true_box_wh) * wh_scale * self.xywh_scale\n","        conf_delta  = object_mask * (pred_box_conf-true_box_conf) * self.obj_scale + (1-object_mask) * conf_delta * self.noobj_scale\n","        class_delta = object_mask * \\\n","                      tf.expand_dims(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class), 4) * \\\n","                      self.class_scale\n","\n","        loss_xy    = tf.reduce_sum(tf.square(xy_delta),       list(range(1,5)))\n","        loss_wh    = tf.reduce_sum(tf.square(wh_delta),       list(range(1,5)))\n","        loss_conf  = tf.reduce_sum(tf.square(conf_delta),     list(range(1,5)))\n","        loss_class = tf.reduce_sum(class_delta,               list(range(1,5)))\n","\n","        loss = loss_xy + loss_wh + loss_conf + loss_class\n","\n","        if debug:\n","            loss = tf.Print(loss, [grid_h, avg_obj], message='avg_obj \\t\\t', summarize=1000)\n","            loss = tf.Print(loss, [grid_h, avg_noobj], message='avg_noobj \\t\\t', summarize=1000)\n","            loss = tf.Print(loss, [grid_h, avg_iou], message='avg_iou \\t\\t', summarize=1000)\n","            loss = tf.Print(loss, [grid_h, avg_cat], message='avg_cat \\t\\t', summarize=1000)\n","            loss = tf.Print(loss, [grid_h, recall50], message='recall50 \\t', summarize=1000)\n","            loss = tf.Print(loss, [grid_h, recall75], message='recall75 \\t', summarize=1000)   \n","            loss = tf.Print(loss, [grid_h, count], message='count \\t', summarize=1000)     \n","            loss = tf.Print(loss, [grid_h, tf.reduce_sum(loss_xy), \n","                                        tf.reduce_sum(loss_wh), \n","                                        tf.reduce_sum(loss_conf), \n","                                        tf.reduce_sum(loss_class)],  message='loss xy, wh, conf, class: \\t',   summarize=1000)   \n","\n","\n","        return loss*self.grid_scale\n","\n","    def compute_output_shape(self, input_shape):\n","        return [(None, 1)]\n","\n","def _conv_block(inp, convs, do_skip=True):\n","    x = inp\n","    count = 0\n","    \n","    for conv in convs:\n","        if count == (len(convs) - 2) and do_skip:\n","            skip_connection = x\n","        count += 1\n","        \n","        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # unlike tensorflow darknet prefer left and top paddings\n","        x = Conv2D(conv['filter'], \n","                   conv['kernel'], \n","                   strides=conv['stride'], \n","                   padding='valid' if conv['stride'] > 1 else 'same', # unlike tensorflow darknet prefer left and top paddings\n","                   name='conv_' + str(conv['layer_idx']), \n","                   use_bias=False if conv['bnorm'] else True)(x)\n","        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n","        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n","\n","    return add([skip_connection, x]) if do_skip else x        \n","\n","def create_yolov3_model(\n","    nb_class, \n","    anchors, \n","    max_box_per_image, \n","    max_grid, \n","    batch_size, \n","    warmup_batches,\n","    ignore_thresh,\n","    grid_scales,\n","    obj_scale,\n","    noobj_scale,\n","    xywh_scale,\n","    class_scale\n","):\n","    input_image = Input(shape=(None, None, 3)) # net_h, net_w, 3\n","    true_boxes  = Input(shape=(1, 1, 1, max_box_per_image, 4))\n","    true_yolo_1 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n","    true_yolo_2 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n","    true_yolo_3 = Input(shape=(None, None, len(anchors)//6, 4+1+nb_class)) # grid_h, grid_w, nb_anchor, 5+nb_class\n","\n","    # Layer  0 => 4\n","    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n","                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n","                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n","                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n","\n","    # Layer  5 => 8\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n","                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n","\n","    # Layer  9 => 11\n","    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n","                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n","\n","    # Layer 12 => 15\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n","                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n","                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n","\n","    # Layer 16 => 36\n","    for i in range(7):\n","        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n","                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n","        \n","    skip_36 = x\n","        \n","    # Layer 37 => 40\n","    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n","\n","    # Layer 41 => 61\n","    for i in range(7):\n","        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n","                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n","        \n","    skip_61 = x\n","        \n","    # Layer 62 => 65\n","    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n","\n","    # Layer 66 => 74\n","    for i in range(3):\n","        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n","                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n","        \n","    # Layer 75 => 79\n","    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n","                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n","                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], do_skip=False)\n","\n","    # Layer 80 => 82\n","    pred_yolo_1 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n","                             {'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], do_skip=False)\n","    loss_yolo_1 = YoloLayer(anchors[12:], \n","                            [1*num for num in max_grid], \n","                            batch_size, \n","                            warmup_batches, \n","                            ignore_thresh, \n","                            grid_scales[0],\n","                            obj_scale,\n","                            noobj_scale,\n","                            xywh_scale,\n","                            class_scale)([input_image, pred_yolo_1, true_yolo_1, true_boxes])\n","\n","    # Layer 83 => 86\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], do_skip=False)\n","    x = UpSampling2D(2)(x)\n","    x = concatenate([x, skip_61])\n","\n","    # Layer 87 => 91\n","    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n","                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n","                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], do_skip=False)\n","\n","    # Layer 92 => 94\n","    pred_yolo_2 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n","                             {'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], do_skip=False)\n","    loss_yolo_2 = YoloLayer(anchors[6:12], \n","                            [2*num for num in max_grid], \n","                            batch_size, \n","                            warmup_batches, \n","                            ignore_thresh, \n","                            grid_scales[1],\n","                            obj_scale,\n","                            noobj_scale,\n","                            xywh_scale,\n","                            class_scale)([input_image, pred_yolo_2, true_yolo_2, true_boxes])\n","\n","    # Layer 95 => 98\n","    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], do_skip=False)\n","    x = UpSampling2D(2)(x)\n","    x = concatenate([x, skip_36])\n","\n","    # Layer 99 => 106\n","    pred_yolo_3 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n","                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n","                             {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n","                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n","                             {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n","                             {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n","                             {'filter': (3*(5+nb_class)), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], do_skip=False)\n","    loss_yolo_3 = YoloLayer(anchors[:6], \n","                            [4*num for num in max_grid], \n","                            batch_size, \n","                            warmup_batches, \n","                            ignore_thresh, \n","                            grid_scales[2],\n","                            obj_scale,\n","                            noobj_scale,\n","                            xywh_scale,\n","                            class_scale)([input_image, pred_yolo_3, true_yolo_3, true_boxes]) \n","\n","    train_model = Model([input_image, true_boxes, true_yolo_1, true_yolo_2, true_yolo_3], [loss_yolo_1, loss_yolo_2, loss_yolo_3])\n","    infer_model = Model(input_image, [pred_yolo_1, pred_yolo_2, pred_yolo_3])\n","\n","    return [train_model, infer_model]\n","\n","def dummy_loss(y_true, y_pred):\n","    return tf.sqrt(tf.reduce_sum(y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9LfzRFhxPVd2"},"source":["# callbacks.py"]},{"cell_type":"code","metadata":{"id":"ni696nG5PU4W"},"source":["from keras.callbacks import TensorBoard, ModelCheckpoint\n","import tensorflow as tf\n","import numpy as np\n","\n","class CustomTensorBoard(TensorBoard):\n","    \"\"\" to log the loss after each batch\n","    \"\"\"    \n","    def __init__(self, log_every=1, **kwargs):\n","        super(CustomTensorBoard, self).__init__(**kwargs)\n","        self.log_every = log_every\n","        self.counter = 0\n","    \n","    def on_batch_end(self, batch, logs=None):\n","        self.counter+=1\n","        if self.counter%self.log_every==0:\n","            for name, value in logs.items():\n","                if name in ['batch', 'size']:\n","                    continue\n","                summary = tf.Summary()\n","                summary_value = summary.value.add()\n","                summary_value.simple_value = value.item()\n","                summary_value.tag = name\n","                self.writer.add_summary(summary, self.counter)\n","            self.writer.flush()\n","        \n","        super(CustomTensorBoard, self).on_batch_end(batch, logs)\n","\n","class CustomModelCheckpoint(ModelCheckpoint):\n","    \"\"\" to save the template model, not the multi-GPU model\n","    \"\"\"\n","    def __init__(self, model_to_save, **kwargs):\n","        super(CustomModelCheckpoint, self).__init__(**kwargs)\n","        self.model_to_save = model_to_save\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        self.epochs_since_last_save += 1\n","        if self.epochs_since_last_save >= self.period:\n","            self.epochs_since_last_save = 0\n","            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n","            if self.save_best_only:\n","                current = logs.get(self.monitor)\n","                if current is None:\n","                    warnings.warn('Can save best model only with %s available, '\n","                                  'skipping.' % (self.monitor), RuntimeWarning)\n","                else:\n","                    if self.monitor_op(current, self.best):\n","                        if self.verbose > 0:\n","                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n","                                  ' saving model to %s'\n","                                  % (epoch + 1, self.monitor, self.best,\n","                                     current, filepath))\n","                        self.best = current\n","                        if self.save_weights_only:\n","                            self.model_to_save.save_weights(filepath, overwrite=True)\n","                        else:\n","                            self.model_to_save.save(filepath, overwrite=True)\n","                    else:\n","                        if self.verbose > 0:\n","                            print('\\nEpoch %05d: %s did not improve from %0.5f' %\n","                                  (epoch + 1, self.monitor, self.best))\n","            else:\n","                if self.verbose > 0:\n","                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n","                if self.save_weights_only:\n","                    self.model_to_save.save_weights(filepath, overwrite=True)\n","                else:\n","                    self.model_to_save.save(filepath, overwrite=True)\n","\n","        super(CustomModelCheckpoint, self).on_batch_end(epoch, logs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ig5EaqqIPeo_"},"source":["# generator.py"]},{"cell_type":"code","metadata":{"id":"UxscO3AEPhxb"},"source":["import cv2\n","import copy\n","import numpy as np\n","from keras.utils import Sequence\n","\n","class BatchGenerator(Sequence):\n","    def __init__(self, \n","        instances, \n","        anchors,   \n","        labels,        \n","        downsample=32, # ratio between network input's size and network output's size, 32 for YOLOv3\n","        max_box_per_image=30,\n","        batch_size=1,\n","        min_net_size=320,\n","        max_net_size=608,    \n","        shuffle=True, \n","        jitter=True, \n","        norm=None\n","    ):\n","        self.instances          = instances\n","        self.batch_size         = batch_size\n","        self.labels             = labels\n","        self.downsample         = downsample\n","        self.max_box_per_image  = max_box_per_image\n","        self.min_net_size       = (min_net_size//self.downsample)*self.downsample\n","        self.max_net_size       = (max_net_size//self.downsample)*self.downsample\n","        self.shuffle            = shuffle\n","        self.jitter             = jitter\n","        self.norm               = norm\n","        self.anchors            = [BoundBox(0, 0, anchors[2*i], anchors[2*i+1]) for i in range(len(anchors)//2)]\n","        self.net_h              = 416  \n","        self.net_w              = 416\n","\n","        if shuffle: np.random.shuffle(self.instances)\n","            \n","    def __len__(self):\n","        return int(np.ceil(float(len(self.instances))/self.batch_size))           \n","\n","    def __getitem__(self, idx):\n","        # get image input size, change every 10 batches\n","        net_h, net_w = self._get_net_size(idx)\n","        base_grid_h, base_grid_w = net_h//self.downsample, net_w//self.downsample\n","\n","        # determine the first and the last indices of the batch\n","        l_bound = idx*self.batch_size\n","        r_bound = (idx+1)*self.batch_size\n","\n","        if r_bound > len(self.instances):\n","            r_bound = len(self.instances)\n","            l_bound = r_bound - self.batch_size\n","\n","        x_batch = np.zeros((r_bound - l_bound, net_h, net_w, 3))             # input images\n","        t_batch = np.zeros((r_bound - l_bound, 1, 1, 1,  self.max_box_per_image, 4))   # list of groundtruth boxes\n","\n","        # initialize the inputs and the outputs\n","        yolo_1 = np.zeros((r_bound - l_bound, 1*base_grid_h,  1*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 1\n","        yolo_2 = np.zeros((r_bound - l_bound, 2*base_grid_h,  2*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 2\n","        yolo_3 = np.zeros((r_bound - l_bound, 4*base_grid_h,  4*base_grid_w, len(self.anchors)//3, 4+1+len(self.labels))) # desired network output 3\n","        yolos = [yolo_3, yolo_2, yolo_1]\n","\n","        dummy_yolo_1 = np.zeros((r_bound - l_bound, 1))\n","        dummy_yolo_2 = np.zeros((r_bound - l_bound, 1))\n","        dummy_yolo_3 = np.zeros((r_bound - l_bound, 1))\n","        \n","        instance_count = 0\n","        true_box_index = 0\n","\n","        # do the logic to fill in the inputs and the output\n","        for train_instance in self.instances[l_bound:r_bound]:\n","            # augment input image and fix object's position and size\n","            img, all_objs = self._aug_image(train_instance, net_h, net_w)\n","            \n","            for obj in all_objs:\n","                # find the best anchor box for this object\n","                max_anchor = None                \n","                max_index  = -1\n","                max_iou    = -1\n","\n","                shifted_box = BoundBox(0, \n","                                       0,\n","                                       obj['xmax']-obj['xmin'],                                                \n","                                       obj['ymax']-obj['ymin'])    \n","                \n","                for i in range(len(self.anchors)):\n","                    anchor = self.anchors[i]\n","                    iou    = bbox_iou(shifted_box, anchor)\n","\n","                    if max_iou < iou:\n","                        max_anchor = anchor\n","                        max_index  = i\n","                        max_iou    = iou                \n","                \n","                # determine the yolo to be responsible for this bounding box\n","                yolo = yolos[max_index//3]\n","                grid_h, grid_w = yolo.shape[1:3]\n","                \n","                # determine the position of the bounding box on the grid\n","                center_x = .5*(obj['xmin'] + obj['xmax'])\n","                center_x = center_x / float(net_w) * grid_w # sigma(t_x) + c_x\n","                center_y = .5*(obj['ymin'] + obj['ymax'])\n","                center_y = center_y / float(net_h) * grid_h # sigma(t_y) + c_y\n","                \n","                # determine the sizes of the bounding box\n","                w = np.log((obj['xmax'] - obj['xmin']) / float(max_anchor.xmax)) # t_w\n","                h = np.log((obj['ymax'] - obj['ymin']) / float(max_anchor.ymax)) # t_h\n","\n","                box = [center_x, center_y, w, h]\n","\n","                # determine the index of the label\n","                obj_indx = self.labels.index(obj['name'])  \n","\n","                # determine the location of the cell responsible for this object\n","                grid_x = int(np.floor(center_x))\n","                grid_y = int(np.floor(center_y))\n","\n","                # assign ground truth x, y, w, h, confidence and class probs to y_batch\n","                yolo[instance_count, grid_y, grid_x, max_index%3]      = 0\n","                yolo[instance_count, grid_y, grid_x, max_index%3, 0:4] = box\n","                yolo[instance_count, grid_y, grid_x, max_index%3, 4  ] = 1.\n","                yolo[instance_count, grid_y, grid_x, max_index%3, 5+obj_indx] = 1\n","\n","                # assign the true box to t_batch\n","                true_box = [center_x, center_y, obj['xmax'] - obj['xmin'], obj['ymax'] - obj['ymin']]\n","                t_batch[instance_count, 0, 0, 0, true_box_index] = true_box\n","\n","                true_box_index += 1\n","                true_box_index  = true_box_index % self.max_box_per_image    \n","\n","            # assign input image to x_batch\n","            if self.norm != None: \n","                x_batch[instance_count] = self.norm(img)\n","            else:\n","                # plot image and bounding boxes for sanity check\n","                for obj in all_objs:\n","                    cv2.rectangle(img, (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n","                    cv2.putText(img, obj['name'], \n","                                (obj['xmin']+2, obj['ymin']+12), \n","                                0, 1.2e-3 * img.shape[0], \n","                                (0,255,0), 2)\n","                \n","                x_batch[instance_count] = img\n","\n","            # increase instance counter in the current batch\n","            instance_count += 1\n","\n","                \n","        return [x_batch, t_batch, yolo_1, yolo_2, yolo_3], [dummy_yolo_1, dummy_yolo_2, dummy_yolo_3]\n","\n","    def _get_net_size(self, idx):\n","        if idx%10 == 0:\n","            net_size = self.downsample*np.random.randint(self.min_net_size/self.downsample, \\\n","                                                         self.max_net_size/self.downsample+1)\n","            print(\"resizing: \", net_size, net_size)\n","            self.net_h, self.net_w = net_size, net_size\n","        return self.net_h, self.net_w\n","    \n","    def _aug_image(self, instance, net_h, net_w):\n","        image_name = instance['filename']\n","        image = cv2.imread(image_name) # RGB image\n","        \n","        if image is None: print('Cannot find ', image_name)\n","        image = image[:,:,::-1] # RGB image\n","            \n","        image_h, image_w, _ = image.shape\n","        \n","        # determine the amount of scaling and cropping\n","        dw = self.jitter * image_w;\n","        dh = self.jitter * image_h;\n","\n","        new_ar = (image_w + np.random.uniform(-dw, dw)) / (image_h + np.random.uniform(-dh, dh));\n","        scale = np.random.uniform(0.25, 2);\n","\n","        if (new_ar < 1):\n","            new_h = int(scale * net_h);\n","            new_w = int(net_h * new_ar);\n","        else:\n","            new_w = int(scale * net_w);\n","            new_h = int(net_w / new_ar);\n","            \n","        dx = int(np.random.uniform(0, net_w - new_w));\n","        dy = int(np.random.uniform(0, net_h - new_h));\n","        \n","        # apply scaling and cropping\n","        im_sized = apply_random_scale_and_crop(image, new_w, new_h, net_w, net_h, dx, dy)\n","        \n","        # randomly distort hsv space\n","        im_sized = random_distort_image(im_sized)\n","        \n","        # randomly flip\n","        flip = np.random.randint(2)\n","        im_sized = random_flip(im_sized, flip)\n","            \n","        # correct the size and pos of bounding boxes\n","        all_objs = correct_bounding_boxes(instance['object'], new_w, new_h, net_w, net_h, dx, dy, flip, image_w, image_h)\n","        \n","        return im_sized, all_objs   \n","\n","    def on_epoch_end(self):\n","        if self.shuffle: np.random.shuffle(self.instances)\n","\n","    def num_classes(self):\n","        return len(self.labels)\n","\n","    def size(self):\n","        return len(self.instances)\n","\n","    def get_anchors(self):\n","        anchors = []\n","\n","        for anchor in self.anchors:\n","            anchors += [anchor.xmax, anchor.ymax]\n","\n","        return anchors\n","\n","    def load_annotation(self, i):\n","        annots = []\n","\n","        for obj in self.instances[i]['object']:\n","            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.labels.index(obj['name'])]\n","            annots += [annot]\n","\n","        if len(annots) == 0: annots = [[]]\n","\n","        return np.array(annots)\n","\n","    def load_image(self, i):\n","        return cv2.imread(self.instances[i]['filename'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgvdr6hjP4nx"},"source":["# train.py"]},{"cell_type":"markdown","metadata":{"id":"qxUcLtxgQOJv"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"uCPLfsafP8Jw"},"source":["import argparse\n","import os\n","import numpy as np\n","import json\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from keras.optimizers import Adam\n","import tensorflow as tf\n","import keras\n","from keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZxVnVLG4QUHc"},"source":["## create_training_instances"]},{"cell_type":"code","metadata":{"id":"DDN5VPe0QZ4k"},"source":["def create_training_instances(\n","    train_annot_folder,\n","    train_image_folder,\n","    train_cache,\n","    valid_annot_folder,\n","    valid_image_folder,\n","    valid_cache,\n","    labels,\n","):\n","    # parse annotations of the training set\n","    train_ints, train_labels = parse_voc_annotation(train_annot_folder, train_image_folder, train_cache, labels)\n","\n","    #Spliting the data\n","    train_valid_split = int(0.8*len(train_ints))\n","    np.random.seed(0)\n","    np.random.shuffle(train_ints)\n","    np.random.seed()\n","\n","    valid_ints = train_ints[train_valid_split:]\n","    train_ints = train_ints[:train_valid_split]\n","\n","    # compare the seen labels with the given labels in config.json\n","    if len(labels) > 0:\n","        overlap_labels = set(labels).intersection(set(train_labels.keys()))\n","\n","        print('Seen labels: \\t'  + str(train_labels) + '\\n')\n","        print('Given labels: \\t' + str(labels))\n","\n","        # return None, None, None if some given label is not in the dataset\n","        if len(overlap_labels) < len(labels):\n","            print('Some labels have no annotations! Please revise the list of labels in the config.json.')\n","            return None, None, None\n","    else:\n","        print('No labels are provided. Train on all seen labels.')\n","        print(train_labels)\n","        labels = train_labels.keys()\n","\n","    max_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n","\n","    return train_ints, valid_ints, sorted(labels), max_box_per_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vq6CRLaPQ_R3"},"source":["## create_callbacks"]},{"cell_type":"code","metadata":{"id":"R6VzPRf5RDMU"},"source":["def create_callbacks(saved_weights_name, tensorboard_logs, model_to_save):\n","    makedirs(tensorboard_logs)\n","    \n","    early_stop = EarlyStopping(\n","        monitor     = 'loss', \n","        min_delta   = 0.01, \n","        patience    = 7, \n","        mode        = 'min', \n","        verbose     = 1\n","    )\n","    checkpoint = CustomModelCheckpoint(\n","        model_to_save   = model_to_save,\n","        filepath        = saved_weights_name,# + '{epoch:02d}.h5', \n","        monitor         = 'loss', \n","        verbose         = 1, \n","        save_best_only  = True, \n","        mode            = 'min', \n","        period          = 1\n","    )\n","    reduce_on_plateau = ReduceLROnPlateau(\n","        monitor  = 'loss',\n","        factor   = 0.1,\n","        patience = 4,\n","        verbose  = 1,\n","        mode     = 'min',\n","        epsilon  = 0.01,\n","        cooldown = 0,\n","        min_lr   = 0\n","    )\n","    tensorboard = CustomTensorBoard(\n","        log_dir                = tensorboard_logs,\n","        write_graph            = True,\n","        write_images           = True,\n","    )    \n","    return [early_stop, checkpoint, reduce_on_plateau, tensorboard]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z3Y6pmLOROpo"},"source":["## create_model"]},{"cell_type":"code","metadata":{"id":"w82AopbJRTBS"},"source":["def create_model(\n","    nb_class, \n","    anchors, \n","    max_box_per_image, \n","    max_grid, batch_size, \n","    warmup_batches, \n","    ignore_thresh, \n","    multi_gpu, \n","    saved_weights_name, \n","    lr,\n","    grid_scales,\n","    obj_scale,\n","    noobj_scale,\n","    xywh_scale,\n","    class_scale  \n","):\n","\n","    template_model, infer_model = create_yolov3_model(\n","        nb_class            = nb_class, \n","        anchors             = anchors, \n","        max_box_per_image   = max_box_per_image, \n","        max_grid            = max_grid, \n","        batch_size          = batch_size, \n","        warmup_batches      = warmup_batches,\n","        ignore_thresh       = ignore_thresh,\n","        grid_scales         = grid_scales,\n","        obj_scale           = obj_scale,\n","        noobj_scale         = noobj_scale,\n","        xywh_scale          = xywh_scale,\n","        class_scale         = class_scale\n","    )  \n","\n","    # load the pretrained weight if exists, otherwise load the backend weight only\n","    if os.path.exists(saved_weights_name): \n","        print(\"\\nLoading pretrained weights.\\n\")\n","        template_model.load_weights(saved_weights_name)\n","    else:\n","        template_model.load_weights(\"/drive/My Drive/GTSDB/backend.h5\", by_name=True)       \n","\n","    train_model = template_model      \n","\n","    optimizer = Adam(lr=lr, clipnorm=0.001)\n","    train_model.compile(loss=dummy_loss, optimizer=optimizer)             \n","\n","    return train_model, infer_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vLFrTZ49SULr"},"source":["## main"]},{"cell_type":"code","metadata":{"id":"2Hm1_97LSWYX","executionInfo":{"status":"ok","timestamp":1602103623793,"user_tz":-120,"elapsed":8698219,"user":{"displayName":"ENRIC BONET","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgnZRbbgPP9GLTgkDSgeJtYq-mOg5Pp-nCFLVRrRg=s64","userId":"02183648625159651878"}},"outputId":"796559b7-45b2-4990-c737-c2ab75533dea","colab":{"base_uri":"https://localhost:8080/"}},"source":["#4x8\n","#YOLO ANCHORS MEJOR\n","\n","\n","config_path = '/drive/My Drive/GTSDB/config3-colab4x8.json'\n","\n","with open(config_path) as config_buffer:    \n","    config = json.loads(config_buffer.read())\n","\n","###############################\n","#   Parse the annotations \n","###############################\n","train_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n","    config['train']['train_annot_folder'],\n","    config['train']['train_image_folder'],\n","    config['train']['cache_name'],\n","    config['valid']['valid_annot_folder'],\n","    config['valid']['valid_image_folder'],\n","    config['valid']['cache_name'],\n","    config['model']['labels']\n",")\n","\n","\n","\n","print('\\nTraining on: \\t' + str(labels) + '\\n')\n","\n","###############################\n","#   Create the generators \n","###############################    \n","train_generator = BatchGenerator(\n","    instances           = train_ints, \n","    anchors             = config['model']['anchors'],   \n","    labels              = labels,        \n","    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n","    max_box_per_image   = max_box_per_image,\n","    batch_size          = config['train']['batch_size'],\n","    min_net_size        = config['model']['min_input_size'],\n","    max_net_size        = config['model']['max_input_size'],   \n","    shuffle             = True, \n","    jitter              = 0.3, \n","    norm                = normalize\n",")\n","\n","valid_generator = BatchGenerator(\n","    instances           = valid_ints, \n","    anchors             = config['model']['anchors'],   \n","    labels              = labels,        \n","    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n","    max_box_per_image   = max_box_per_image,\n","    batch_size          = config['train']['batch_size'],\n","    min_net_size        = config['model']['min_input_size'],\n","    max_net_size        = config['model']['max_input_size'],   \n","    shuffle             = True, \n","    jitter              = 0.0, \n","    norm                = normalize\n",")\n","\n","###############################\n","#   Create the model \n","###############################\n","if os.path.exists(config['train']['saved_weights_name']): \n","    config['train']['warmup_epochs'] = 0\n","warmup_batches = config['train']['warmup_epochs'] * (config['train']['train_times']*len(train_generator)) \n","\n","multi_gpu = len(config['train']['gpus'].split(','))\n","\n","train_model, infer_model = create_model(\n","    nb_class            = len(labels), \n","    anchors             = config['model']['anchors'], \n","    max_box_per_image   = max_box_per_image, \n","    max_grid            = [config['model']['max_input_size'], config['model']['max_input_size']], \n","    batch_size          = config['train']['batch_size'], \n","    warmup_batches      = warmup_batches,\n","    ignore_thresh       = config['train']['ignore_thresh'],\n","    multi_gpu           = multi_gpu,\n","    saved_weights_name  = config['train']['saved_weights_name'],\n","    lr                  = config['train']['learning_rate'],\n","    grid_scales         = config['train']['grid_scales'],\n","    obj_scale           = config['train']['obj_scale'],\n","    noobj_scale         = config['train']['noobj_scale'],\n","    xywh_scale          = config['train']['xywh_scale'],\n","    class_scale         = config['train']['class_scale'],\n",")\n","\n","train_model.summary()\n","\n","###############################\n","#   Kick off the training\n","###############################\n","callbacks = create_callbacks(config['train']['saved_weights_name'], config['train']['tensorboard_dir'], infer_model)\n","\n","train_model.fit_generator(\n","    generator        = train_generator, \n","    steps_per_epoch  = len(train_generator) * config['train']['train_times'], \n","    epochs           = config['train']['nb_epochs'] + config['train']['warmup_epochs'], \n","    verbose          = 1,\n","    callbacks        = callbacks\n",")\n","\n","###############################\n","#   Run the evaluation\n","###############################   \n","# compute mAP for all the classes\n","average_precisions = evaluate(infer_model, valid_generator)\n","\n","# print the score\n","for label, average_precision in average_precisions.items():\n","    print(labels[label] + ': {:.4f}'.format(average_precision))\n","print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Seen labels: \t{'danger': 156, 'mandatory': 114, 'other': 186, 'prohibitory': 396}\n","\n","Given labels: \t['prohibitory', 'mandatory', 'danger', 'other']\n","\n","Training on: \t['danger', 'mandatory', 'other', 'prohibitory']\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From <ipython-input-8-b1eb12480ac5>:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","conv_0 (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_0 (BatchNormalization)    (None, None, None, 3 128         conv_0[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_0 (LeakyReLU)             (None, None, None, 3 0           bnorm_0[0][0]                    \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_0[0][0]                    \n","__________________________________________________________________________________________________\n","conv_1 (Conv2D)                 (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","bnorm_1 (BatchNormalization)    (None, None, None, 6 256         conv_1[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_1 (LeakyReLU)             (None, None, None, 6 0           bnorm_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv_2 (Conv2D)                 (None, None, None, 3 2048        leaky_1[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_2 (BatchNormalization)    (None, None, None, 3 128         conv_2[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_2 (LeakyReLU)             (None, None, None, 3 0           bnorm_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv_3 (Conv2D)                 (None, None, None, 6 18432       leaky_2[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_3 (BatchNormalization)    (None, None, None, 6 256         conv_3[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_3 (LeakyReLU)             (None, None, None, 6 0           bnorm_3[0][0]                    \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, None, None, 6 0           leaky_1[0][0]                    \n","                                                                 leaky_3[0][0]                    \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv_5 (Conv2D)                 (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","bnorm_5 (BatchNormalization)    (None, None, None, 1 512         conv_5[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_5 (LeakyReLU)             (None, None, None, 1 0           bnorm_5[0][0]                    \n","__________________________________________________________________________________________________\n","conv_6 (Conv2D)                 (None, None, None, 6 8192        leaky_5[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_6 (BatchNormalization)    (None, None, None, 6 256         conv_6[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_6 (LeakyReLU)             (None, None, None, 6 0           bnorm_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv_7 (Conv2D)                 (None, None, None, 1 73728       leaky_6[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_7 (BatchNormalization)    (None, None, None, 1 512         conv_7[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_7 (LeakyReLU)             (None, None, None, 1 0           bnorm_7[0][0]                    \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, None, None, 1 0           leaky_5[0][0]                    \n","                                                                 leaky_7[0][0]                    \n","__________________________________________________________________________________________________\n","conv_9 (Conv2D)                 (None, None, None, 6 8192        add_2[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_9 (BatchNormalization)    (None, None, None, 6 256         conv_9[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_9 (LeakyReLU)             (None, None, None, 6 0           bnorm_9[0][0]                    \n","__________________________________________________________________________________________________\n","conv_10 (Conv2D)                (None, None, None, 1 73728       leaky_9[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_10 (BatchNormalization)   (None, None, None, 1 512         conv_10[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_10 (LeakyReLU)            (None, None, None, 1 0           bnorm_10[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n","                                                                 leaky_10[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv_12 (Conv2D)                (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","bnorm_12 (BatchNormalization)   (None, None, None, 2 1024        conv_12[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_12 (LeakyReLU)            (None, None, None, 2 0           bnorm_12[0][0]                   \n","__________________________________________________________________________________________________\n","conv_13 (Conv2D)                (None, None, None, 1 32768       leaky_12[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_13 (BatchNormalization)   (None, None, None, 1 512         conv_13[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_13 (LeakyReLU)            (None, None, None, 1 0           bnorm_13[0][0]                   \n","__________________________________________________________________________________________________\n","conv_14 (Conv2D)                (None, None, None, 2 294912      leaky_13[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_14 (BatchNormalization)   (None, None, None, 2 1024        conv_14[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_14 (LeakyReLU)            (None, None, None, 2 0           bnorm_14[0][0]                   \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, None, None, 2 0           leaky_12[0][0]                   \n","                                                                 leaky_14[0][0]                   \n","__________________________________________________________________________________________________\n","conv_16 (Conv2D)                (None, None, None, 1 32768       add_4[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_16 (BatchNormalization)   (None, None, None, 1 512         conv_16[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_16 (LeakyReLU)            (None, None, None, 1 0           bnorm_16[0][0]                   \n","__________________________________________________________________________________________________\n","conv_17 (Conv2D)                (None, None, None, 2 294912      leaky_16[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_17 (BatchNormalization)   (None, None, None, 2 1024        conv_17[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_17 (LeakyReLU)            (None, None, None, 2 0           bnorm_17[0][0]                   \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n","                                                                 leaky_17[0][0]                   \n","__________________________________________________________________________________________________\n","conv_19 (Conv2D)                (None, None, None, 1 32768       add_5[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_19 (BatchNormalization)   (None, None, None, 1 512         conv_19[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_19 (LeakyReLU)            (None, None, None, 1 0           bnorm_19[0][0]                   \n","__________________________________________________________________________________________________\n","conv_20 (Conv2D)                (None, None, None, 2 294912      leaky_19[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_20 (BatchNormalization)   (None, None, None, 2 1024        conv_20[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_20 (LeakyReLU)            (None, None, None, 2 0           bnorm_20[0][0]                   \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n","                                                                 leaky_20[0][0]                   \n","__________________________________________________________________________________________________\n","conv_22 (Conv2D)                (None, None, None, 1 32768       add_6[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_22 (BatchNormalization)   (None, None, None, 1 512         conv_22[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_22 (LeakyReLU)            (None, None, None, 1 0           bnorm_22[0][0]                   \n","__________________________________________________________________________________________________\n","conv_23 (Conv2D)                (None, None, None, 2 294912      leaky_22[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_23 (BatchNormalization)   (None, None, None, 2 1024        conv_23[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_23 (LeakyReLU)            (None, None, None, 2 0           bnorm_23[0][0]                   \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n","                                                                 leaky_23[0][0]                   \n","__________________________________________________________________________________________________\n","conv_25 (Conv2D)                (None, None, None, 1 32768       add_7[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_25 (BatchNormalization)   (None, None, None, 1 512         conv_25[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_25 (LeakyReLU)            (None, None, None, 1 0           bnorm_25[0][0]                   \n","__________________________________________________________________________________________________\n","conv_26 (Conv2D)                (None, None, None, 2 294912      leaky_25[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_26 (BatchNormalization)   (None, None, None, 2 1024        conv_26[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_26 (LeakyReLU)            (None, None, None, 2 0           bnorm_26[0][0]                   \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n","                                                                 leaky_26[0][0]                   \n","__________________________________________________________________________________________________\n","conv_28 (Conv2D)                (None, None, None, 1 32768       add_8[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_28 (BatchNormalization)   (None, None, None, 1 512         conv_28[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_28 (LeakyReLU)            (None, None, None, 1 0           bnorm_28[0][0]                   \n","__________________________________________________________________________________________________\n","conv_29 (Conv2D)                (None, None, None, 2 294912      leaky_28[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_29 (BatchNormalization)   (None, None, None, 2 1024        conv_29[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_29 (LeakyReLU)            (None, None, None, 2 0           bnorm_29[0][0]                   \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n","                                                                 leaky_29[0][0]                   \n","__________________________________________________________________________________________________\n","conv_31 (Conv2D)                (None, None, None, 1 32768       add_9[0][0]                      \n","__________________________________________________________________________________________________\n","bnorm_31 (BatchNormalization)   (None, None, None, 1 512         conv_31[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_31 (LeakyReLU)            (None, None, None, 1 0           bnorm_31[0][0]                   \n","__________________________________________________________________________________________________\n","conv_32 (Conv2D)                (None, None, None, 2 294912      leaky_31[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_32 (BatchNormalization)   (None, None, None, 2 1024        conv_32[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_32 (LeakyReLU)            (None, None, None, 2 0           bnorm_32[0][0]                   \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n","                                                                 leaky_32[0][0]                   \n","__________________________________________________________________________________________________\n","conv_34 (Conv2D)                (None, None, None, 1 32768       add_10[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_34 (BatchNormalization)   (None, None, None, 1 512         conv_34[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_34 (LeakyReLU)            (None, None, None, 1 0           bnorm_34[0][0]                   \n","__________________________________________________________________________________________________\n","conv_35 (Conv2D)                (None, None, None, 2 294912      leaky_34[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_35 (BatchNormalization)   (None, None, None, 2 1024        conv_35[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_35 (LeakyReLU)            (None, None, None, 2 0           bnorm_35[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n","                                                                 leaky_35[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv_37 (Conv2D)                (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","bnorm_37 (BatchNormalization)   (None, None, None, 5 2048        conv_37[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_37 (LeakyReLU)            (None, None, None, 5 0           bnorm_37[0][0]                   \n","__________________________________________________________________________________________________\n","conv_38 (Conv2D)                (None, None, None, 2 131072      leaky_37[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_38 (BatchNormalization)   (None, None, None, 2 1024        conv_38[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_38 (LeakyReLU)            (None, None, None, 2 0           bnorm_38[0][0]                   \n","__________________________________________________________________________________________________\n","conv_39 (Conv2D)                (None, None, None, 5 1179648     leaky_38[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_39 (BatchNormalization)   (None, None, None, 5 2048        conv_39[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_39 (LeakyReLU)            (None, None, None, 5 0           bnorm_39[0][0]                   \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, None, None, 5 0           leaky_37[0][0]                   \n","                                                                 leaky_39[0][0]                   \n","__________________________________________________________________________________________________\n","conv_41 (Conv2D)                (None, None, None, 2 131072      add_12[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_41 (BatchNormalization)   (None, None, None, 2 1024        conv_41[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_41 (LeakyReLU)            (None, None, None, 2 0           bnorm_41[0][0]                   \n","__________________________________________________________________________________________________\n","conv_42 (Conv2D)                (None, None, None, 5 1179648     leaky_41[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_42 (BatchNormalization)   (None, None, None, 5 2048        conv_42[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_42 (LeakyReLU)            (None, None, None, 5 0           bnorm_42[0][0]                   \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n","                                                                 leaky_42[0][0]                   \n","__________________________________________________________________________________________________\n","conv_44 (Conv2D)                (None, None, None, 2 131072      add_13[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_44 (BatchNormalization)   (None, None, None, 2 1024        conv_44[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_44 (LeakyReLU)            (None, None, None, 2 0           bnorm_44[0][0]                   \n","__________________________________________________________________________________________________\n","conv_45 (Conv2D)                (None, None, None, 5 1179648     leaky_44[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_45 (BatchNormalization)   (None, None, None, 5 2048        conv_45[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_45 (LeakyReLU)            (None, None, None, 5 0           bnorm_45[0][0]                   \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n","                                                                 leaky_45[0][0]                   \n","__________________________________________________________________________________________________\n","conv_47 (Conv2D)                (None, None, None, 2 131072      add_14[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_47 (BatchNormalization)   (None, None, None, 2 1024        conv_47[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_47 (LeakyReLU)            (None, None, None, 2 0           bnorm_47[0][0]                   \n","__________________________________________________________________________________________________\n","conv_48 (Conv2D)                (None, None, None, 5 1179648     leaky_47[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_48 (BatchNormalization)   (None, None, None, 5 2048        conv_48[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_48 (LeakyReLU)            (None, None, None, 5 0           bnorm_48[0][0]                   \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n","                                                                 leaky_48[0][0]                   \n","__________________________________________________________________________________________________\n","conv_50 (Conv2D)                (None, None, None, 2 131072      add_15[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_50 (BatchNormalization)   (None, None, None, 2 1024        conv_50[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_50 (LeakyReLU)            (None, None, None, 2 0           bnorm_50[0][0]                   \n","__________________________________________________________________________________________________\n","conv_51 (Conv2D)                (None, None, None, 5 1179648     leaky_50[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_51 (BatchNormalization)   (None, None, None, 5 2048        conv_51[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_51 (LeakyReLU)            (None, None, None, 5 0           bnorm_51[0][0]                   \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n","                                                                 leaky_51[0][0]                   \n","__________________________________________________________________________________________________\n","conv_53 (Conv2D)                (None, None, None, 2 131072      add_16[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_53 (BatchNormalization)   (None, None, None, 2 1024        conv_53[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_53 (LeakyReLU)            (None, None, None, 2 0           bnorm_53[0][0]                   \n","__________________________________________________________________________________________________\n","conv_54 (Conv2D)                (None, None, None, 5 1179648     leaky_53[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_54 (BatchNormalization)   (None, None, None, 5 2048        conv_54[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_54 (LeakyReLU)            (None, None, None, 5 0           bnorm_54[0][0]                   \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n","                                                                 leaky_54[0][0]                   \n","__________________________________________________________________________________________________\n","conv_56 (Conv2D)                (None, None, None, 2 131072      add_17[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_56 (BatchNormalization)   (None, None, None, 2 1024        conv_56[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_56 (LeakyReLU)            (None, None, None, 2 0           bnorm_56[0][0]                   \n","__________________________________________________________________________________________________\n","conv_57 (Conv2D)                (None, None, None, 5 1179648     leaky_56[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_57 (BatchNormalization)   (None, None, None, 5 2048        conv_57[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_57 (LeakyReLU)            (None, None, None, 5 0           bnorm_57[0][0]                   \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n","                                                                 leaky_57[0][0]                   \n","__________________________________________________________________________________________________\n","conv_59 (Conv2D)                (None, None, None, 2 131072      add_18[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_59 (BatchNormalization)   (None, None, None, 2 1024        conv_59[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_59 (LeakyReLU)            (None, None, None, 2 0           bnorm_59[0][0]                   \n","__________________________________________________________________________________________________\n","conv_60 (Conv2D)                (None, None, None, 5 1179648     leaky_59[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_60 (BatchNormalization)   (None, None, None, 5 2048        conv_60[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_60 (LeakyReLU)            (None, None, None, 5 0           bnorm_60[0][0]                   \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n","                                                                 leaky_60[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv_62 (Conv2D)                (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","bnorm_62 (BatchNormalization)   (None, None, None, 1 4096        conv_62[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_62 (LeakyReLU)            (None, None, None, 1 0           bnorm_62[0][0]                   \n","__________________________________________________________________________________________________\n","conv_63 (Conv2D)                (None, None, None, 5 524288      leaky_62[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_63 (BatchNormalization)   (None, None, None, 5 2048        conv_63[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_63 (LeakyReLU)            (None, None, None, 5 0           bnorm_63[0][0]                   \n","__________________________________________________________________________________________________\n","conv_64 (Conv2D)                (None, None, None, 1 4718592     leaky_63[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_64 (BatchNormalization)   (None, None, None, 1 4096        conv_64[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_64 (LeakyReLU)            (None, None, None, 1 0           bnorm_64[0][0]                   \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, None, None, 1 0           leaky_62[0][0]                   \n","                                                                 leaky_64[0][0]                   \n","__________________________________________________________________________________________________\n","conv_66 (Conv2D)                (None, None, None, 5 524288      add_20[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_66 (BatchNormalization)   (None, None, None, 5 2048        conv_66[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_66 (LeakyReLU)            (None, None, None, 5 0           bnorm_66[0][0]                   \n","__________________________________________________________________________________________________\n","conv_67 (Conv2D)                (None, None, None, 1 4718592     leaky_66[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_67 (BatchNormalization)   (None, None, None, 1 4096        conv_67[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_67 (LeakyReLU)            (None, None, None, 1 0           bnorm_67[0][0]                   \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n","                                                                 leaky_67[0][0]                   \n","__________________________________________________________________________________________________\n","conv_69 (Conv2D)                (None, None, None, 5 524288      add_21[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_69 (BatchNormalization)   (None, None, None, 5 2048        conv_69[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_69 (LeakyReLU)            (None, None, None, 5 0           bnorm_69[0][0]                   \n","__________________________________________________________________________________________________\n","conv_70 (Conv2D)                (None, None, None, 1 4718592     leaky_69[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_70 (BatchNormalization)   (None, None, None, 1 4096        conv_70[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_70 (LeakyReLU)            (None, None, None, 1 0           bnorm_70[0][0]                   \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n","                                                                 leaky_70[0][0]                   \n","__________________________________________________________________________________________________\n","conv_72 (Conv2D)                (None, None, None, 5 524288      add_22[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_72 (BatchNormalization)   (None, None, None, 5 2048        conv_72[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_72 (LeakyReLU)            (None, None, None, 5 0           bnorm_72[0][0]                   \n","__________________________________________________________________________________________________\n","conv_73 (Conv2D)                (None, None, None, 1 4718592     leaky_72[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_73 (BatchNormalization)   (None, None, None, 1 4096        conv_73[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_73 (LeakyReLU)            (None, None, None, 1 0           bnorm_73[0][0]                   \n","__________________________________________________________________________________________________\n","add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n","                                                                 leaky_73[0][0]                   \n","__________________________________________________________________________________________________\n","conv_75 (Conv2D)                (None, None, None, 5 524288      add_23[0][0]                     \n","__________________________________________________________________________________________________\n","bnorm_75 (BatchNormalization)   (None, None, None, 5 2048        conv_75[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_75 (LeakyReLU)            (None, None, None, 5 0           bnorm_75[0][0]                   \n","__________________________________________________________________________________________________\n","conv_76 (Conv2D)                (None, None, None, 1 4718592     leaky_75[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_76 (BatchNormalization)   (None, None, None, 1 4096        conv_76[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_76 (LeakyReLU)            (None, None, None, 1 0           bnorm_76[0][0]                   \n","__________________________________________________________________________________________________\n","conv_77 (Conv2D)                (None, None, None, 5 524288      leaky_76[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_77 (BatchNormalization)   (None, None, None, 5 2048        conv_77[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_77 (LeakyReLU)            (None, None, None, 5 0           bnorm_77[0][0]                   \n","__________________________________________________________________________________________________\n","conv_78 (Conv2D)                (None, None, None, 1 4718592     leaky_77[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_78 (BatchNormalization)   (None, None, None, 1 4096        conv_78[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_78 (LeakyReLU)            (None, None, None, 1 0           bnorm_78[0][0]                   \n","__________________________________________________________________________________________________\n","conv_79 (Conv2D)                (None, None, None, 5 524288      leaky_78[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_79 (BatchNormalization)   (None, None, None, 5 2048        conv_79[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_79 (LeakyReLU)            (None, None, None, 5 0           bnorm_79[0][0]                   \n","__________________________________________________________________________________________________\n","conv_84 (Conv2D)                (None, None, None, 2 131072      leaky_79[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_84 (BatchNormalization)   (None, None, None, 2 1024        conv_84[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_84 (LeakyReLU)            (None, None, None, 2 0           bnorm_84[0][0]                   \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_84[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n","                                                                 add_19[0][0]                     \n","__________________________________________________________________________________________________\n","conv_87 (Conv2D)                (None, None, None, 2 196608      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","bnorm_87 (BatchNormalization)   (None, None, None, 2 1024        conv_87[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_87 (LeakyReLU)            (None, None, None, 2 0           bnorm_87[0][0]                   \n","__________________________________________________________________________________________________\n","conv_88 (Conv2D)                (None, None, None, 5 1179648     leaky_87[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_88 (BatchNormalization)   (None, None, None, 5 2048        conv_88[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_88 (LeakyReLU)            (None, None, None, 5 0           bnorm_88[0][0]                   \n","__________________________________________________________________________________________________\n","conv_89 (Conv2D)                (None, None, None, 2 131072      leaky_88[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_89 (BatchNormalization)   (None, None, None, 2 1024        conv_89[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_89 (LeakyReLU)            (None, None, None, 2 0           bnorm_89[0][0]                   \n","__________________________________________________________________________________________________\n","conv_90 (Conv2D)                (None, None, None, 5 1179648     leaky_89[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_90 (BatchNormalization)   (None, None, None, 5 2048        conv_90[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_90 (LeakyReLU)            (None, None, None, 5 0           bnorm_90[0][0]                   \n","__________________________________________________________________________________________________\n","conv_91 (Conv2D)                (None, None, None, 2 131072      leaky_90[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_91 (BatchNormalization)   (None, None, None, 2 1024        conv_91[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_91 (LeakyReLU)            (None, None, None, 2 0           bnorm_91[0][0]                   \n","__________________________________________________________________________________________________\n","conv_96 (Conv2D)                (None, None, None, 1 32768       leaky_91[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_96 (BatchNormalization)   (None, None, None, 1 512         conv_96[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_96 (LeakyReLU)            (None, None, None, 1 0           bnorm_96[0][0]                   \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_96[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n","                                                                 add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv_99 (Conv2D)                (None, None, None, 1 49152       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","bnorm_99 (BatchNormalization)   (None, None, None, 1 512         conv_99[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_99 (LeakyReLU)            (None, None, None, 1 0           bnorm_99[0][0]                   \n","__________________________________________________________________________________________________\n","conv_100 (Conv2D)               (None, None, None, 2 294912      leaky_99[0][0]                   \n","__________________________________________________________________________________________________\n","bnorm_100 (BatchNormalization)  (None, None, None, 2 1024        conv_100[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_100 (LeakyReLU)           (None, None, None, 2 0           bnorm_100[0][0]                  \n","__________________________________________________________________________________________________\n","conv_101 (Conv2D)               (None, None, None, 1 32768       leaky_100[0][0]                  \n","__________________________________________________________________________________________________\n","bnorm_101 (BatchNormalization)  (None, None, None, 1 512         conv_101[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_101 (LeakyReLU)           (None, None, None, 1 0           bnorm_101[0][0]                  \n","__________________________________________________________________________________________________\n","conv_102 (Conv2D)               (None, None, None, 2 294912      leaky_101[0][0]                  \n","__________________________________________________________________________________________________\n","bnorm_102 (BatchNormalization)  (None, None, None, 2 1024        conv_102[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_102 (LeakyReLU)           (None, None, None, 2 0           bnorm_102[0][0]                  \n","__________________________________________________________________________________________________\n","conv_103 (Conv2D)               (None, None, None, 1 32768       leaky_102[0][0]                  \n","__________________________________________________________________________________________________\n","bnorm_103 (BatchNormalization)  (None, None, None, 1 512         conv_103[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_103 (LeakyReLU)           (None, None, None, 1 0           bnorm_103[0][0]                  \n","__________________________________________________________________________________________________\n","conv_80 (Conv2D)                (None, None, None, 1 4718592     leaky_79[0][0]                   \n","__________________________________________________________________________________________________\n","conv_92 (Conv2D)                (None, None, None, 5 1179648     leaky_91[0][0]                   \n","__________________________________________________________________________________________________\n","conv_104 (Conv2D)               (None, None, None, 2 294912      leaky_103[0][0]                  \n","__________________________________________________________________________________________________\n","bnorm_80 (BatchNormalization)   (None, None, None, 1 4096        conv_80[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_92 (BatchNormalization)   (None, None, None, 5 2048        conv_92[0][0]                    \n","__________________________________________________________________________________________________\n","bnorm_104 (BatchNormalization)  (None, None, None, 2 1024        conv_104[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_80 (LeakyReLU)            (None, None, None, 1 0           bnorm_80[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_92 (LeakyReLU)            (None, None, None, 5 0           bnorm_92[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_104 (LeakyReLU)           (None, None, None, 2 0           bnorm_104[0][0]                  \n","__________________________________________________________________________________________________\n","conv_81 (Conv2D)                (None, None, None, 2 27675       leaky_80[0][0]                   \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 1, 1, 1, 6, 4 0                                            \n","__________________________________________________________________________________________________\n","conv_93 (Conv2D)                (None, None, None, 2 13851       leaky_92[0][0]                   \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","conv_105 (Conv2D)               (None, None, None, 2 6939        leaky_104[0][0]                  \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            (None, None, None, 3 0                                            \n","__________________________________________________________________________________________________\n","yolo_layer_1 (YoloLayer)        (None, 1)            0           input_1[0][0]                    \n","                                                                 conv_81[0][0]                    \n","                                                                 input_3[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","yolo_layer_2 (YoloLayer)        (None, 1)            0           input_1[0][0]                    \n","                                                                 conv_93[0][0]                    \n","                                                                 input_4[0][0]                    \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","yolo_layer_3 (YoloLayer)        (None, 1)            0           input_1[0][0]                    \n","                                                                 conv_105[0][0]                   \n","                                                                 input_5[0][0]                    \n","                                                                 input_2[0][0]                    \n","==================================================================================================\n","Total params: 61,592,497\n","Trainable params: 61,539,889\n","Non-trainable params: 52,608\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/103\n","  8/204 [>.............................] - ETA: 29:04 - loss: 1566.8191 - yolo_layer_1_loss: 177.5415 - yolo_layer_2_loss: 475.0298 - yolo_layer_3_loss: 914.2478resizing:  384 384\n"," 28/204 [===>..........................] - ETA: 24:26 - loss: 1136.9194 - yolo_layer_1_loss: 127.9451 - yolo_layer_2_loss: 343.0165 - yolo_layer_3_loss: 665.9577resizing:  352 352\n"," 37/204 [====>.........................] - ETA: 22:24 - loss: 1000.2974 - yolo_layer_1_loss: 112.8482 - yolo_layer_2_loss: 299.0389 - yolo_layer_3_loss: 588.4102resizing:  448 448\n"," 42/204 [=====>........................] - ETA: 21:52 - loss: 948.4351 - yolo_layer_1_loss: 108.1381 - yolo_layer_2_loss: 281.6844 - yolo_layer_3_loss: 558.6124resizing:  448 448\n"," 44/204 [=====>........................] - ETA: 21:32 - loss: 929.0245 - yolo_layer_1_loss: 106.3298 - yolo_layer_2_loss: 275.1704 - yolo_layer_3_loss: 547.5241resizing:  448 448\n"," 46/204 [=====>........................] - ETA: 21:23 - loss: 909.5347 - yolo_layer_1_loss: 104.4181 - yolo_layer_2_loss: 268.7244 - yolo_layer_3_loss: 536.3920resizing:  352 352\n"," 51/204 [======>.......................] - ETA: 20:21 - loss: 857.3956 - yolo_layer_1_loss: 98.8501 - yolo_layer_2_loss: 252.2414 - yolo_layer_3_loss: 506.3039resizing:  448 448\n"," 55/204 [=======>......................] - ETA: 18:29 - loss: 821.3018 - yolo_layer_1_loss: 95.0316 - yolo_layer_2_loss: 240.8433 - yolo_layer_3_loss: 485.4267resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 18:03 - loss: 813.5273 - yolo_layer_1_loss: 94.2852 - yolo_layer_2_loss: 238.3606 - yolo_layer_3_loss: 480.8814resizing:  448 448\n"," 72/204 [=========>....................] - ETA: 12:51 - loss: 699.3692 - yolo_layer_1_loss: 81.6411 - yolo_layer_2_loss: 202.4343 - yolo_layer_3_loss: 415.2937resizing:  384 384\n"," 74/204 [=========>....................] - ETA: 12:21 - loss: 687.3811 - yolo_layer_1_loss: 80.2545 - yolo_layer_2_loss: 198.6919 - yolo_layer_3_loss: 408.4346resizing:  384 384\n"," 79/204 [==========>...................] - ETA: 11:13 - loss: 658.9340 - yolo_layer_1_loss: 76.9381 - yolo_layer_2_loss: 189.8590 - yolo_layer_3_loss: 392.1369resizing:  384 384\n","103/204 [==============>...............] - ETA: 7:10 - loss: 548.2537 - yolo_layer_1_loss: 64.1546 - yolo_layer_2_loss: 156.0962 - yolo_layer_3_loss: 328.0028resizing:  352 352\n","108/204 [==============>...............] - ETA: 6:32 - loss: 529.7173 - yolo_layer_1_loss: 62.0194 - yolo_layer_2_loss: 150.4591 - yolo_layer_3_loss: 317.2386resizing:  416 416\n","112/204 [===============>..............] - ETA: 6:04 - loss: 515.6076 - yolo_layer_1_loss: 60.3548 - yolo_layer_2_loss: 146.2188 - yolo_layer_3_loss: 309.0340resizing:  384 384\n","resizing:  384 384\n","130/204 [==================>...........] - ETA: 4:18 - loss: 462.8075 - yolo_layer_1_loss: 54.0932 - yolo_layer_2_loss: 130.3649 - yolo_layer_3_loss: 278.3494resizing:  384 384\n","132/204 [==================>...........] - ETA: 4:08 - loss: 457.5838 - yolo_layer_1_loss: 53.4557 - yolo_layer_2_loss: 128.8018 - yolo_layer_3_loss: 275.3264resizing:  384 384\n","161/204 [======================>.......] - ETA: 2:05 - loss: 394.9381 - yolo_layer_1_loss: 46.0884 - yolo_layer_2_loss: 110.1843 - yolo_layer_3_loss: 238.6654resizing:  416 416\n","163/204 [======================>.......] - ETA: 1:58 - loss: 391.2522 - yolo_layer_1_loss: 45.6628 - yolo_layer_2_loss: 109.0892 - yolo_layer_3_loss: 236.5002resizing:  416 416\n","166/204 [=======================>......] - ETA: 1:48 - loss: 385.8745 - yolo_layer_1_loss: 45.0472 - yolo_layer_2_loss: 107.4906 - yolo_layer_3_loss: 233.3366resizing:  448 448\n","173/204 [========================>.....] - ETA: 1:25 - loss: 374.0747 - yolo_layer_1_loss: 43.6715 - yolo_layer_2_loss: 104.0009 - yolo_layer_3_loss: 226.4024resizing:  352 352\n","176/204 [========================>.....] - ETA: 1:16 - loss: 369.2745 - yolo_layer_1_loss: 43.1272 - yolo_layer_2_loss: 102.5782 - yolo_layer_3_loss: 223.5691resizing:  416 416\n","177/204 [=========================>....] - ETA: 1:13 - loss: 367.7122 - yolo_layer_1_loss: 42.9502 - yolo_layer_2_loss: 102.1152 - yolo_layer_3_loss: 222.6468resizing:  416 416\n","204/204 [==============================] - 497s 2s/step - loss: 330.5299 - yolo_layer_1_loss: 38.7477 - yolo_layer_2_loss: 91.1543 - yolo_layer_3_loss: 200.6279\n","\n","Epoch 00001: loss improved from inf to 330.52985, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","resizing:  384 384\n","resizing:  448 448\n","resizing:  384 384\n","Epoch 2/103\n"," 14/204 [=>............................] - ETA: 1:53 - loss: 74.9815 - yolo_layer_1_loss: 10.0888 - yolo_layer_2_loss: 16.3357 - yolo_layer_3_loss: 48.5570resizing:  384 384\n"," 15/204 [=>............................] - ETA: 1:52 - loss: 74.4688 - yolo_layer_1_loss: 10.0196 - yolo_layer_2_loss: 16.2240 - yolo_layer_3_loss: 48.2252resizing:  352 352\n"," 33/204 [===>..........................] - ETA: 1:35 - loss: 70.5860 - yolo_layer_1_loss: 9.5195 - yolo_layer_2_loss: 15.3974 - yolo_layer_3_loss: 45.6690resizing:  384 384\n"," 52/204 [======>.......................] - ETA: 1:22 - loss: 67.7348 - yolo_layer_1_loss: 9.1293 - yolo_layer_2_loss: 14.9532 - yolo_layer_3_loss: 43.6523resizing:  352 352\n"," 54/204 [======>.......................] - ETA: 1:21 - loss: 67.4950 - yolo_layer_1_loss: 9.0968 - yolo_layer_2_loss: 14.8981 - yolo_layer_3_loss: 43.5002resizing:  448 448\n"," 60/204 [=======>......................] - ETA: 1:17 - loss: 66.5883 - yolo_layer_1_loss: 8.9253 - yolo_layer_2_loss: 14.6650 - yolo_layer_3_loss: 42.9980resizing:  448 448\n"," 81/204 [==========>...................] - ETA: 1:11 - loss: 66.4095 - yolo_layer_1_loss: 9.1235 - yolo_layer_2_loss: 14.6722 - yolo_layer_3_loss: 42.6138resizing:  352 352\n"," 83/204 [===========>..................] - ETA: 1:10 - loss: 66.3594 - yolo_layer_1_loss: 9.1446 - yolo_layer_2_loss: 14.6673 - yolo_layer_3_loss: 42.5475resizing:  416 416\n"," 85/204 [===========>..................] - ETA: 1:09 - loss: 66.2929 - yolo_layer_1_loss: 9.1722 - yolo_layer_2_loss: 14.6525 - yolo_layer_3_loss: 42.4682resizing:  352 352\n","102/204 [==============>...............] - ETA: 59s - loss: 64.7992 - yolo_layer_1_loss: 9.0407 - yolo_layer_2_loss: 14.2964 - yolo_layer_3_loss: 41.4620 resizing:  448 448\n","103/204 [==============>...............] - ETA: 59s - loss: 64.6602 - yolo_layer_1_loss: 9.0187 - yolo_layer_2_loss: 14.2551 - yolo_layer_3_loss: 41.3865resizing:  416 416\n","105/204 [==============>...............] - ETA: 57s - loss: 64.3713 - yolo_layer_1_loss: 8.9698 - yolo_layer_2_loss: 14.1815 - yolo_layer_3_loss: 41.2200resizing:  416 416\n","resizing:  448 448\n","110/204 [===============>..............] - ETA: 55s - loss: 64.1043 - yolo_layer_1_loss: 8.9259 - yolo_layer_2_loss: 14.1287 - yolo_layer_3_loss: 41.0497resizing:  448 448\n","115/204 [===============>..............] - ETA: 52s - loss: 63.7969 - yolo_layer_1_loss: 8.9011 - yolo_layer_2_loss: 14.0576 - yolo_layer_3_loss: 40.8382resizing:  416 416\n","155/204 [=====================>........] - ETA: 29s - loss: 61.0508 - yolo_layer_1_loss: 8.5873 - yolo_layer_2_loss: 13.4622 - yolo_layer_3_loss: 39.0013resizing:  384 384\n","171/204 [========================>.....] - ETA: 19s - loss: 59.7571 - yolo_layer_1_loss: 8.3839 - yolo_layer_2_loss: 13.1874 - yolo_layer_3_loss: 38.1857resizing:  416 416\n","172/204 [========================>.....] - ETA: 19s - loss: 59.6868 - yolo_layer_1_loss: 8.3731 - yolo_layer_2_loss: 13.1651 - yolo_layer_3_loss: 38.1486resizing:  448 448\n","174/204 [========================>.....] - ETA: 18s - loss: 59.5807 - yolo_layer_1_loss: 8.3447 - yolo_layer_2_loss: 13.1332 - yolo_layer_3_loss: 38.1028resizing:  352 352\n","186/204 [==========================>...] - ETA: 10s - loss: 58.7660 - yolo_layer_1_loss: 8.1934 - yolo_layer_2_loss: 12.9348 - yolo_layer_3_loss: 37.6378resizing:  416 416\n","188/204 [==========================>...] - ETA: 9s - loss: 58.6501 - yolo_layer_1_loss: 8.1680 - yolo_layer_2_loss: 12.9078 - yolo_layer_3_loss: 37.5743 resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 57.6760 - yolo_layer_1_loss: 7.9825 - yolo_layer_2_loss: 12.6534 - yolo_layer_3_loss: 37.0402resizing:  416 416\n","204/204 [==============================] - 121s 594ms/step - loss: 57.6208 - yolo_layer_1_loss: 7.9724 - yolo_layer_2_loss: 12.6357 - yolo_layer_3_loss: 37.0127\n","\n","Epoch 00002: loss improved from 330.52985 to 57.62083, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 3/103\n","  4/204 [..............................] - ETA: 2:10 - loss: 44.8100 - yolo_layer_1_loss: 6.0432 - yolo_layer_2_loss: 9.8281 - yolo_layer_3_loss: 28.9386 resizing:  448 448\n"," 12/204 [>.............................] - ETA: 2:06 - loss: 45.7357 - yolo_layer_1_loss: 6.0455 - yolo_layer_2_loss: 10.0546 - yolo_layer_3_loss: 29.6356resizing:  448 448\n"," 30/204 [===>..........................] - ETA: 1:59 - loss: 46.9105 - yolo_layer_1_loss: 6.4020 - yolo_layer_2_loss: 10.3897 - yolo_layer_3_loss: 30.1189resizing:  416 416\n"," 37/204 [====>.........................] - ETA: 1:54 - loss: 47.3712 - yolo_layer_1_loss: 6.5270 - yolo_layer_2_loss: 10.6206 - yolo_layer_3_loss: 30.2236resizing:  448 448\n"," 38/204 [====>.........................] - ETA: 1:54 - loss: 47.4618 - yolo_layer_1_loss: 6.5712 - yolo_layer_2_loss: 10.6099 - yolo_layer_3_loss: 30.2807resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:32 - loss: 45.9979 - yolo_layer_1_loss: 6.4537 - yolo_layer_2_loss: 10.0493 - yolo_layer_3_loss: 29.4949resizing:  352 352\n"," 75/204 [==========>...................] - ETA: 1:21 - loss: 45.0580 - yolo_layer_1_loss: 6.4035 - yolo_layer_2_loss: 9.6558 - yolo_layer_3_loss: 28.9988resizing:  448 448\n"," 78/204 [==========>...................] - ETA: 1:18 - loss: 44.8530 - yolo_layer_1_loss: 6.3655 - yolo_layer_2_loss: 9.5835 - yolo_layer_3_loss: 28.9040resizing:  352 352\n"," 81/204 [==========>...................] - ETA: 1:16 - loss: 44.7136 - yolo_layer_1_loss: 6.3544 - yolo_layer_2_loss: 9.5402 - yolo_layer_3_loss: 28.8190resizing:  416 416\n"," 82/204 [===========>..................] - ETA: 1:15 - loss: 44.6546 - yolo_layer_1_loss: 6.3448 - yolo_layer_2_loss: 9.5250 - yolo_layer_3_loss: 28.7849resizing:  384 384\n"," 87/204 [===========>..................] - ETA: 1:11 - loss: 44.5723 - yolo_layer_1_loss: 6.3056 - yolo_layer_2_loss: 9.4713 - yolo_layer_3_loss: 28.7953resizing:  384 384\n","102/204 [==============>...............] - ETA: 1:01 - loss: 44.2239 - yolo_layer_1_loss: 6.1922 - yolo_layer_2_loss: 9.3932 - yolo_layer_3_loss: 28.6384resizing:  416 416\n","119/204 [================>.............] - ETA: 51s - loss: 43.6035 - yolo_layer_1_loss: 6.0679 - yolo_layer_2_loss: 9.2935 - yolo_layer_3_loss: 28.2421resizing:  416 416\n","121/204 [================>.............] - ETA: 50s - loss: 43.5187 - yolo_layer_1_loss: 6.0413 - yolo_layer_2_loss: 9.2806 - yolo_layer_3_loss: 28.1967resizing:  384 384\n","127/204 [=================>............] - ETA: 46s - loss: 43.2980 - yolo_layer_1_loss: 5.9893 - yolo_layer_2_loss: 9.2338 - yolo_layer_3_loss: 28.0750resizing:  448 448\n","136/204 [===================>..........] - ETA: 41s - loss: 43.1322 - yolo_layer_1_loss: 5.9605 - yolo_layer_2_loss: 9.2328 - yolo_layer_3_loss: 27.9389resizing:  352 352\n","141/204 [===================>..........] - ETA: 38s - loss: 43.0738 - yolo_layer_1_loss: 5.9741 - yolo_layer_2_loss: 9.2387 - yolo_layer_3_loss: 27.8611resizing:  384 384\n","154/204 [=====================>........] - ETA: 30s - loss: 42.8588 - yolo_layer_1_loss: 5.9748 - yolo_layer_2_loss: 9.1601 - yolo_layer_3_loss: 27.7239resizing:  352 352\n","157/204 [======================>.......] - ETA: 28s - loss: 42.7918 - yolo_layer_1_loss: 5.9831 - yolo_layer_2_loss: 9.1382 - yolo_layer_3_loss: 27.6705resizing:  416 416\n","165/204 [=======================>......] - ETA: 23s - loss: 42.6398 - yolo_layer_1_loss: 5.9944 - yolo_layer_2_loss: 9.0652 - yolo_layer_3_loss: 27.5802resizing:  384 384\n","172/204 [========================>.....] - ETA: 19s - loss: 42.6192 - yolo_layer_1_loss: 6.0461 - yolo_layer_2_loss: 9.0424 - yolo_layer_3_loss: 27.5307resizing:  384 384\n","179/204 [=========================>....] - ETA: 15s - loss: 42.4340 - yolo_layer_1_loss: 6.0166 - yolo_layer_2_loss: 8.9672 - yolo_layer_3_loss: 27.4502resizing:  384 384\n","186/204 [==========================>...] - ETA: 10s - loss: 42.2743 - yolo_layer_1_loss: 6.0081 - yolo_layer_2_loss: 8.9078 - yolo_layer_3_loss: 27.3585resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 41.8362 - yolo_layer_1_loss: 6.0475 - yolo_layer_2_loss: 8.7284 - yolo_layer_3_loss: 27.0602resizing:  448 448\n","204/204 [==============================] - 121s 593ms/step - loss: 41.8316 - yolo_layer_1_loss: 6.0603 - yolo_layer_2_loss: 8.7240 - yolo_layer_3_loss: 27.0473\n","\n","Epoch 00003: loss improved from 57.62083 to 41.83156, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","resizing:  384 384\n","Epoch 4/103\n","  1/204 [..............................] - ETA: 2:01 - loss: 25.2205 - yolo_layer_1_loss: 1.0354 - yolo_layer_2_loss: 2.1040 - yolo_layer_3_loss: 22.0810resizing:  352 352\n","  2/204 [..............................] - ETA: 2:10 - loss: 26.4824 - yolo_layer_1_loss: 1.2147 - yolo_layer_2_loss: 3.9971 - yolo_layer_3_loss: 21.2705resizing:  416 416\n","  6/204 [..............................] - ETA: 1:59 - loss: 23.2580 - yolo_layer_1_loss: 0.9503 - yolo_layer_2_loss: 2.6636 - yolo_layer_3_loss: 19.6441resizing:  448 448\n"," 33/204 [===>..........................] - ETA: 1:52 - loss: 18.3499 - yolo_layer_1_loss: 0.2820 - yolo_layer_2_loss: 1.5025 - yolo_layer_3_loss: 16.5654resizing:  416 416\n"," 52/204 [======>.......................] - ETA: 1:40 - loss: 16.3853 - yolo_layer_1_loss: 0.1853 - yolo_layer_2_loss: 1.4309 - yolo_layer_3_loss: 14.7691resizing:  448 448\n"," 53/204 [======>.......................] - ETA: 1:39 - loss: 16.2941 - yolo_layer_1_loss: 0.1821 - yolo_layer_2_loss: 1.4050 - yolo_layer_3_loss: 14.7071resizing:  352 352\n"," 54/204 [======>.......................] - ETA: 1:39 - loss: 16.2697 - yolo_layer_1_loss: 0.1789 - yolo_layer_2_loss: 1.4781 - yolo_layer_3_loss: 14.6126resizing:  448 448\n"," 59/204 [=======>......................] - ETA: 1:35 - loss: 15.8813 - yolo_layer_1_loss: 0.1649 - yolo_layer_2_loss: 1.4468 - yolo_layer_3_loss: 14.2696resizing:  384 384\n"," 67/204 [========>.....................] - ETA: 1:30 - loss: 15.2558 - yolo_layer_1_loss: 0.1467 - yolo_layer_2_loss: 1.3571 - yolo_layer_3_loss: 13.7520resizing:  384 384\n"," 90/204 [============>.................] - ETA: 1:12 - loss: 14.0807 - yolo_layer_1_loss: 0.1118 - yolo_layer_2_loss: 1.1985 - yolo_layer_3_loss: 12.7704resizing:  352 352\n","108/204 [==============>...............] - ETA: 58s - loss: 13.4811 - yolo_layer_1_loss: 0.0946 - yolo_layer_2_loss: 1.0541 - yolo_layer_3_loss: 12.3323resizing:  384 384\n","111/204 [===============>..............] - ETA: 56s - loss: 13.3532 - yolo_layer_1_loss: 0.0923 - yolo_layer_2_loss: 1.0266 - yolo_layer_3_loss: 12.2343resizing:  416 416\n","115/204 [===============>..............] - ETA: 53s - loss: 13.2191 - yolo_layer_1_loss: 0.0894 - yolo_layer_2_loss: 0.9922 - yolo_layer_3_loss: 12.1375resizing:  384 384\n","128/204 [=================>............] - ETA: 45s - loss: 12.9813 - yolo_layer_1_loss: 0.0813 - yolo_layer_2_loss: 0.9952 - yolo_layer_3_loss: 11.9048resizing:  416 416\n","132/204 [==================>...........] - ETA: 43s - loss: 12.9410 - yolo_layer_1_loss: 0.0791 - yolo_layer_2_loss: 1.0059 - yolo_layer_3_loss: 11.8560resizing:  448 448\n","134/204 [==================>...........] - ETA: 42s - loss: 12.8922 - yolo_layer_1_loss: 0.0781 - yolo_layer_2_loss: 0.9915 - yolo_layer_3_loss: 11.8227resizing:  448 448\n","152/204 [=====================>........] - ETA: 31s - loss: 12.5473 - yolo_layer_1_loss: 0.0702 - yolo_layer_2_loss: 1.0499 - yolo_layer_3_loss: 11.4271resizing:  384 384\n","159/204 [======================>.......] - ETA: 27s - loss: 12.3519 - yolo_layer_1_loss: 0.0675 - yolo_layer_2_loss: 1.0055 - yolo_layer_3_loss: 11.2789resizing:  448 448\n","160/204 [======================>.......] - ETA: 26s - loss: 12.3314 - yolo_layer_1_loss: 0.0672 - yolo_layer_2_loss: 0.9994 - yolo_layer_3_loss: 11.2648resizing:  384 384\n","164/204 [=======================>......] - ETA: 24s - loss: 12.2215 - yolo_layer_1_loss: 0.0657 - yolo_layer_2_loss: 0.9760 - yolo_layer_3_loss: 11.1798resizing:  448 448\n","168/204 [=======================>......] - ETA: 21s - loss: 12.1298 - yolo_layer_1_loss: 0.0644 - yolo_layer_2_loss: 0.9536 - yolo_layer_3_loss: 11.1118resizing:  448 448\n","175/204 [========================>.....] - ETA: 17s - loss: 12.0900 - yolo_layer_1_loss: 0.0622 - yolo_layer_2_loss: 0.9775 - yolo_layer_3_loss: 11.0504resizing:  352 352\n","204/204 [==============================] - 121s 594ms/step - loss: 11.7475 - yolo_layer_1_loss: 0.0546 - yolo_layer_2_loss: 0.9705 - yolo_layer_3_loss: 10.7224\n","\n","Epoch 00004: loss improved from 41.83156 to 11.74752, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 5/103\n","  1/204 [..............................] - ETA: 1:46 - loss: 10.5108 - yolo_layer_1_loss: 0.0074 - yolo_layer_2_loss: 0.0305 - yolo_layer_3_loss: 10.4729resizing:  448 448\n"," 11/204 [>.............................] - ETA: 1:52 - loss: 9.0175 - yolo_layer_1_loss: 0.0091 - yolo_layer_2_loss: 0.7306 - yolo_layer_3_loss: 8.2779resizing:  416 416\n"," 23/204 [==>...........................] - ETA: 1:56 - loss: 9.1621 - yolo_layer_1_loss: 0.0096 - yolo_layer_2_loss: 0.8389 - yolo_layer_3_loss: 8.3136resizing:  384 384\n"," 28/204 [===>..........................] - ETA: 1:53 - loss: 8.9976 - yolo_layer_1_loss: 0.0093 - yolo_layer_2_loss: 0.8813 - yolo_layer_3_loss: 8.1070resizing:  448 448\n"," 36/204 [====>.........................] - ETA: 1:47 - loss: 9.2843 - yolo_layer_1_loss: 0.0090 - yolo_layer_2_loss: 1.1230 - yolo_layer_3_loss: 8.1522resizing:  352 352\n"," 39/204 [====>.........................] - ETA: 1:44 - loss: 9.0745 - yolo_layer_1_loss: 0.0089 - yolo_layer_2_loss: 1.0391 - yolo_layer_3_loss: 8.0265resizing:  448 448\n"," 56/204 [=======>......................] - ETA: 1:34 - loss: 9.0129 - yolo_layer_1_loss: 0.0090 - yolo_layer_2_loss: 1.0164 - yolo_layer_3_loss: 7.9875resizing:  384 384\n"," 61/204 [=======>......................] - ETA: 1:32 - loss: 9.0510 - yolo_layer_1_loss: 0.0090 - yolo_layer_2_loss: 1.0229 - yolo_layer_3_loss: 8.0192resizing:  448 448\n"," 71/204 [=========>....................] - ETA: 1:25 - loss: 9.2160 - yolo_layer_1_loss: 0.0087 - yolo_layer_2_loss: 1.0355 - yolo_layer_3_loss: 8.1719resizing:  384 384\n"," 78/204 [==========>...................] - ETA: 1:21 - loss: 9.2440 - yolo_layer_1_loss: 0.0086 - yolo_layer_2_loss: 1.0782 - yolo_layer_3_loss: 8.1572resizing:  352 352\n"," 79/204 [==========>...................] - ETA: 1:20 - loss: 9.2223 - yolo_layer_1_loss: 0.0086 - yolo_layer_2_loss: 1.0650 - yolo_layer_3_loss: 8.1488resizing:  352 352\n"," 80/204 [==========>...................] - ETA: 1:19 - loss: 9.2139 - yolo_layer_1_loss: 0.0085 - yolo_layer_2_loss: 1.0521 - yolo_layer_3_loss: 8.1532resizing:  384 384\n","101/204 [=============>................] - ETA: 1:04 - loss: 9.1046 - yolo_layer_1_loss: 0.0080 - yolo_layer_2_loss: 1.0510 - yolo_layer_3_loss: 8.0456resizing:  384 384\n","110/204 [===============>..............] - ETA: 58s - loss: 9.1317 - yolo_layer_1_loss: 0.0078 - yolo_layer_2_loss: 1.0141 - yolo_layer_3_loss: 8.1097resizing:  416 416\n","resizing:  384 384\n","125/204 [=================>............] - ETA: 48s - loss: 9.0193 - yolo_layer_1_loss: 0.0076 - yolo_layer_2_loss: 0.9383 - yolo_layer_3_loss: 8.0734resizing:  416 416\n","130/204 [==================>...........] - ETA: 44s - loss: 9.0527 - yolo_layer_1_loss: 0.0075 - yolo_layer_2_loss: 0.9032 - yolo_layer_3_loss: 8.1421resizing:  448 448\n","140/204 [===================>..........] - ETA: 38s - loss: 8.9800 - yolo_layer_1_loss: 0.0073 - yolo_layer_2_loss: 0.8783 - yolo_layer_3_loss: 8.0943resizing:  448 448\n","152/204 [=====================>........] - ETA: 31s - loss: 8.9534 - yolo_layer_1_loss: 0.0074 - yolo_layer_2_loss: 0.9151 - yolo_layer_3_loss: 8.0310resizing:  416 416\n","158/204 [======================>.......] - ETA: 28s - loss: 8.8963 - yolo_layer_1_loss: 0.0073 - yolo_layer_2_loss: 0.8815 - yolo_layer_3_loss: 8.0075resizing:  448 448\n","167/204 [=======================>......] - ETA: 22s - loss: 8.8564 - yolo_layer_1_loss: 0.0072 - yolo_layer_2_loss: 0.8973 - yolo_layer_3_loss: 7.9518resizing:  384 384\n","172/204 [========================>.....] - ETA: 19s - loss: 8.8285 - yolo_layer_1_loss: 0.0072 - yolo_layer_2_loss: 0.8721 - yolo_layer_3_loss: 7.9492resizing:  384 384\n","176/204 [========================>.....] - ETA: 17s - loss: 8.8100 - yolo_layer_1_loss: 0.0072 - yolo_layer_2_loss: 0.8821 - yolo_layer_3_loss: 7.9206resizing:  448 448\n","178/204 [=========================>....] - ETA: 16s - loss: 8.8502 - yolo_layer_1_loss: 0.0072 - yolo_layer_2_loss: 0.9020 - yolo_layer_3_loss: 7.9410resizing:  352 352\n","204/204 [==============================] - 124s 606ms/step - loss: 8.7966 - yolo_layer_1_loss: 0.0069 - yolo_layer_2_loss: 0.8419 - yolo_layer_3_loss: 7.9478\n","\n","Epoch 00005: loss improved from 11.74752 to 8.79661, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 6/103\n","  8/204 [>.............................] - ETA: 1:37 - loss: 9.0829 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.7071 - yolo_layer_3_loss: 8.3711resizing:  352 352\n"," 16/204 [=>............................] - ETA: 1:33 - loss: 8.5673 - yolo_layer_1_loss: 0.0046 - yolo_layer_2_loss: 0.3634 - yolo_layer_3_loss: 8.1993resizing:  448 448\n"," 19/204 [=>............................] - ETA: 1:31 - loss: 8.0463 - yolo_layer_1_loss: 0.0046 - yolo_layer_2_loss: 0.3092 - yolo_layer_3_loss: 7.7325resizing:  384 384\n"," 25/204 [==>...........................] - ETA: 1:28 - loss: 7.9949 - yolo_layer_1_loss: 0.0045 - yolo_layer_2_loss: 0.2396 - yolo_layer_3_loss: 7.7509resizing:  384 384\n"," 29/204 [===>..........................] - ETA: 1:29 - loss: 7.7481 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.2101 - yolo_layer_3_loss: 7.5333resizing:  384 384\n"," 37/204 [====>.........................] - ETA: 1:27 - loss: 7.6203 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.1699 - yolo_layer_3_loss: 7.4457resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:20 - loss: 7.4453 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.2334 - yolo_layer_3_loss: 7.2072resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:18 - loss: 7.4259 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.2216 - yolo_layer_3_loss: 7.1995resizing:  448 448\n"," 59/204 [=======>......................] - ETA: 1:18 - loss: 7.5004 - yolo_layer_1_loss: 0.0049 - yolo_layer_2_loss: 0.2960 - yolo_layer_3_loss: 7.1995resizing:  384 384\n"," 66/204 [========>.....................] - ETA: 1:16 - loss: 7.7553 - yolo_layer_1_loss: 0.0051 - yolo_layer_2_loss: 0.6263 - yolo_layer_3_loss: 7.1240resizing:  416 416\n"," 70/204 [=========>....................] - ETA: 1:15 - loss: 7.8240 - yolo_layer_1_loss: 0.0052 - yolo_layer_2_loss: 0.6674 - yolo_layer_3_loss: 7.1514resizing:  352 352\n"," 72/204 [=========>....................] - ETA: 1:14 - loss: 7.8202 - yolo_layer_1_loss: 0.0052 - yolo_layer_2_loss: 0.6494 - yolo_layer_3_loss: 7.1657resizing:  416 416\n","101/204 [=============>................] - ETA: 59s - loss: 7.8079 - yolo_layer_1_loss: 0.0050 - yolo_layer_2_loss: 0.6323 - yolo_layer_3_loss: 7.1705 resizing:  416 416\n","102/204 [==============>...............] - ETA: 59s - loss: 7.8154 - yolo_layer_1_loss: 0.0050 - yolo_layer_2_loss: 0.6264 - yolo_layer_3_loss: 7.1840resizing:  416 416\n","103/204 [==============>...............] - ETA: 58s - loss: 7.8126 - yolo_layer_1_loss: 0.0050 - yolo_layer_2_loss: 0.6205 - yolo_layer_3_loss: 7.1870resizing:  448 448\n","108/204 [==============>...............] - ETA: 56s - loss: 7.8334 - yolo_layer_1_loss: 0.0050 - yolo_layer_2_loss: 0.6450 - yolo_layer_3_loss: 7.1833resizing:  416 416\n","121/204 [================>.............] - ETA: 49s - loss: 8.0098 - yolo_layer_1_loss: 0.0051 - yolo_layer_2_loss: 0.7941 - yolo_layer_3_loss: 7.2106resizing:  384 384\n","136/204 [===================>..........] - ETA: 40s - loss: 8.0145 - yolo_layer_1_loss: 0.0050 - yolo_layer_2_loss: 0.8251 - yolo_layer_3_loss: 7.1844resizing:  384 384\n","159/204 [======================>.......] - ETA: 26s - loss: 7.9485 - yolo_layer_1_loss: 0.0048 - yolo_layer_2_loss: 0.7406 - yolo_layer_3_loss: 7.2031resizing:  416 416\n","169/204 [=======================>......] - ETA: 20s - loss: 7.9313 - yolo_layer_1_loss: 0.0048 - yolo_layer_2_loss: 0.7589 - yolo_layer_3_loss: 7.1677resizing:  416 416\n","174/204 [========================>.....] - ETA: 17s - loss: 7.9340 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.7376 - yolo_layer_3_loss: 7.1916resizing:  416 416\n","179/204 [=========================>....] - ETA: 14s - loss: 7.9785 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.7745 - yolo_layer_3_loss: 7.1993resizing:  352 352\n","185/204 [==========================>...] - ETA: 11s - loss: 7.9399 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.7783 - yolo_layer_3_loss: 7.1569resizing:  384 384\n","189/204 [==========================>...] - ETA: 8s - loss: 7.9647 - yolo_layer_1_loss: 0.0047 - yolo_layer_2_loss: 0.8164 - yolo_layer_3_loss: 7.1435resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 7.8805 - yolo_layer_1_loss: 0.0046 - yolo_layer_2_loss: 0.7613 - yolo_layer_3_loss: 7.1145resizing:  352 352\n","204/204 [==============================] - 120s 587ms/step - loss: 7.8773 - yolo_layer_1_loss: 0.0046 - yolo_layer_2_loss: 0.7577 - yolo_layer_3_loss: 7.1150\n","\n","Epoch 00006: loss improved from 8.79661 to 7.87725, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 7/103\n","  2/204 [..............................] - ETA: 1:48 - loss: 8.0585 - yolo_layer_1_loss: 0.0033 - yolo_layer_2_loss: 0.0172 - yolo_layer_3_loss: 8.0381resizing:  448 448\n","  4/204 [..............................] - ETA: 1:44 - loss: 7.6754 - yolo_layer_1_loss: 0.0033 - yolo_layer_2_loss: 0.0196 - yolo_layer_3_loss: 7.6525resizing:  352 352\n"," 16/204 [=>............................] - ETA: 1:43 - loss: 7.3992 - yolo_layer_1_loss: 0.0036 - yolo_layer_2_loss: 0.0189 - yolo_layer_3_loss: 7.3767resizing:  416 416\n"," 21/204 [==>...........................] - ETA: 1:38 - loss: 7.6181 - yolo_layer_1_loss: 0.0036 - yolo_layer_2_loss: 0.2574 - yolo_layer_3_loss: 7.3572resizing:  352 352\n"," 39/204 [====>.........................] - ETA: 1:28 - loss: 7.5093 - yolo_layer_1_loss: 0.0035 - yolo_layer_2_loss: 0.1479 - yolo_layer_3_loss: 7.3579resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:20 - loss: 7.4021 - yolo_layer_1_loss: 0.0033 - yolo_layer_2_loss: 0.1166 - yolo_layer_3_loss: 7.2821resizing:  384 384\n"," 53/204 [======>.......................] - ETA: 1:20 - loss: 7.3053 - yolo_layer_1_loss: 0.0034 - yolo_layer_2_loss: 0.1128 - yolo_layer_3_loss: 7.1891resizing:  352 352\n"," 56/204 [=======>......................] - ETA: 1:19 - loss: 7.3339 - yolo_layer_1_loss: 0.0034 - yolo_layer_2_loss: 0.1079 - yolo_layer_3_loss: 7.2226resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:18 - loss: 7.3032 - yolo_layer_1_loss: 0.0034 - yolo_layer_2_loss: 0.1063 - yolo_layer_3_loss: 7.1936resizing:  352 352\n"," 58/204 [=======>......................] - ETA: 1:18 - loss: 7.3209 - yolo_layer_1_loss: 0.0034 - yolo_layer_2_loss: 0.1048 - yolo_layer_3_loss: 7.2128resizing:  352 352\n"," 75/204 [==========>...................] - ETA: 1:07 - loss: 7.4840 - yolo_layer_1_loss: 0.0033 - yolo_layer_2_loss: 0.0841 - yolo_layer_3_loss: 7.3966resizing:  352 352\n","104/204 [==============>...............] - ETA: 51s - loss: 7.2560 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.1138 - yolo_layer_3_loss: 7.1391resizing:  352 352\n","115/204 [===============>..............] - ETA: 45s - loss: 7.2286 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.1041 - yolo_layer_3_loss: 7.1213resizing:  384 384\n","116/204 [================>.............] - ETA: 45s - loss: 7.2835 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.1495 - yolo_layer_3_loss: 7.1309resizing:  448 448\n","119/204 [================>.............] - ETA: 43s - loss: 7.3314 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.1460 - yolo_layer_3_loss: 7.1823resizing:  352 352\n","136/204 [===================>..........] - ETA: 34s - loss: 7.3487 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2223 - yolo_layer_3_loss: 7.1233resizing:  352 352\n","137/204 [===================>..........] - ETA: 34s - loss: 7.3620 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2207 - yolo_layer_3_loss: 7.1381resizing:  416 416\n","153/204 [=====================>........] - ETA: 26s - loss: 7.3147 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2329 - yolo_layer_3_loss: 7.0787resizing:  384 384\n","resizing:  384 384\n","158/204 [======================>.......] - ETA: 23s - loss: 7.2868 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2262 - yolo_layer_3_loss: 7.0575resizing:  416 416\n","170/204 [========================>.....] - ETA: 17s - loss: 7.2417 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2112 - yolo_layer_3_loss: 7.0273resizing:  416 416\n","186/204 [==========================>...] - ETA: 9s - loss: 7.2138 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2215 - yolo_layer_3_loss: 6.9891 resizing:  352 352\n","188/204 [==========================>...] - ETA: 8s - loss: 7.2014 - yolo_layer_1_loss: 0.0031 - yolo_layer_2_loss: 0.2193 - yolo_layer_3_loss: 6.9790resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 7.1468 - yolo_layer_1_loss: 0.0032 - yolo_layer_2_loss: 0.2300 - yolo_layer_3_loss: 6.9136resizing:  384 384\n","204/204 [==============================] - 110s 541ms/step - loss: 7.1519 - yolo_layer_1_loss: 0.0032 - yolo_layer_2_loss: 0.2290 - yolo_layer_3_loss: 6.9197\n","\n","Epoch 00007: loss improved from 7.87725 to 7.15187, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 8/103\n","  6/204 [..............................] - ETA: 1:48 - loss: 7.0878 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.0141 - yolo_layer_3_loss: 7.0709resizing:  384 384\n"," 13/204 [>.............................] - ETA: 1:43 - loss: 6.2366 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.0128 - yolo_layer_3_loss: 6.2211resizing:  352 352\n"," 17/204 [=>............................] - ETA: 1:41 - loss: 6.0116 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.0129 - yolo_layer_3_loss: 5.9959resizing:  352 352\n"," 21/204 [==>...........................] - ETA: 1:39 - loss: 6.3255 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2594 - yolo_layer_3_loss: 6.0633resizing:  352 352\n"," 27/204 [==>...........................] - ETA: 1:35 - loss: 6.2824 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2044 - yolo_layer_3_loss: 6.0752resizing:  384 384\n"," 50/204 [======>.......................] - ETA: 1:21 - loss: 6.6754 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.3249 - yolo_layer_3_loss: 6.3477resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:19 - loss: 6.6845 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.3020 - yolo_layer_3_loss: 6.3796resizing:  352 352\n"," 68/204 [=========>....................] - ETA: 1:14 - loss: 6.4982 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2427 - yolo_layer_3_loss: 6.2525resizing:  352 352\n"," 78/204 [==========>...................] - ETA: 1:07 - loss: 6.4625 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2129 - yolo_layer_3_loss: 6.2467resizing:  416 416\n"," 83/204 [===========>..................] - ETA: 1:04 - loss: 6.5144 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2008 - yolo_layer_3_loss: 6.3107resizing:  448 448\n"," 85/204 [===========>..................] - ETA: 1:03 - loss: 6.5051 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.1963 - yolo_layer_3_loss: 6.3059resizing:  416 416\n","103/204 [==============>...............] - ETA: 55s - loss: 6.4766 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2633 - yolo_layer_3_loss: 6.2104resizing:  384 384\n","105/204 [==============>...............] - ETA: 54s - loss: 6.4443 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2585 - yolo_layer_3_loss: 6.1829resizing:  384 384\n","107/204 [==============>...............] - ETA: 53s - loss: 6.4659 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2539 - yolo_layer_3_loss: 6.2091resizing:  448 448\n","120/204 [================>.............] - ETA: 46s - loss: 6.5445 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.2702 - yolo_layer_3_loss: 6.2714resizing:  352 352\n","135/204 [==================>...........] - ETA: 38s - loss: 6.5607 - yolo_layer_1_loss: 0.0030 - yolo_layer_2_loss: 0.3197 - yolo_layer_3_loss: 6.2381resizing:  384 384\n","138/204 [===================>..........] - ETA: 37s - loss: 6.5514 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.3130 - yolo_layer_3_loss: 6.2355resizing:  416 416\n","154/204 [=====================>........] - ETA: 27s - loss: 6.5717 - yolo_layer_1_loss: 0.0029 - yolo_layer_2_loss: 0.3490 - yolo_layer_3_loss: 6.2198resizing:  352 352\n","174/204 [========================>.....] - ETA: 16s - loss: 6.6108 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.3101 - yolo_layer_3_loss: 6.2978resizing:  384 384\n","176/204 [========================>.....] - ETA: 15s - loss: 6.5900 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.3067 - yolo_layer_3_loss: 6.2805resizing:  416 416\n","184/204 [==========================>...] - ETA: 11s - loss: 6.6429 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2938 - yolo_layer_3_loss: 6.3463resizing:  352 352\n","188/204 [==========================>...] - ETA: 8s - loss: 6.6262 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2880 - yolo_layer_3_loss: 6.3354resizing:  416 416\n","192/204 [===========================>..] - ETA: 6s - loss: 6.6272 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2822 - yolo_layer_3_loss: 6.3422resizing:  352 352\n","204/204 [==============================] - 113s 556ms/step - loss: 6.5836 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.2914 - yolo_layer_3_loss: 6.2894\n","\n","Epoch 00008: loss improved from 7.15187 to 6.58361, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 9/103\n","  8/204 [>.............................] - ETA: 1:37 - loss: 7.0609 - yolo_layer_1_loss: 0.0021 - yolo_layer_2_loss: 0.7441 - yolo_layer_3_loss: 6.3147resizing:  384 384\n","  9/204 [>.............................] - ETA: 1:36 - loss: 6.9497 - yolo_layer_1_loss: 0.0022 - yolo_layer_2_loss: 0.6637 - yolo_layer_3_loss: 6.2838resizing:  384 384\n"," 18/204 [=>............................] - ETA: 1:31 - loss: 6.9501 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.3376 - yolo_layer_3_loss: 6.6102resizing:  352 352\n"," 23/204 [==>...........................] - ETA: 1:30 - loss: 6.8672 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.2664 - yolo_layer_3_loss: 6.5985resizing:  416 416\n"," 32/204 [===>..........................] - ETA: 1:27 - loss: 6.5463 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.1941 - yolo_layer_3_loss: 6.3499resizing:  448 448\n"," 38/204 [====>.........................] - ETA: 1:26 - loss: 6.5126 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.1650 - yolo_layer_3_loss: 6.3453resizing:  448 448\n"," 56/204 [=======>......................] - ETA: 1:24 - loss: 6.8177 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.4904 - yolo_layer_3_loss: 6.3246resizing:  416 416\n"," 71/204 [=========>....................] - ETA: 1:19 - loss: 6.8761 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.6133 - yolo_layer_3_loss: 6.2600resizing:  416 416\n"," 73/204 [=========>....................] - ETA: 1:18 - loss: 6.8956 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.5968 - yolo_layer_3_loss: 6.2960resizing:  384 384\n"," 86/204 [===========>..................] - ETA: 1:11 - loss: 6.7922 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.5776 - yolo_layer_3_loss: 6.2118resizing:  384 384\n"," 87/204 [===========>..................] - ETA: 1:10 - loss: 6.8014 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.5710 - yolo_layer_3_loss: 6.2276resizing:  416 416\n"," 89/204 [============>.................] - ETA: 1:08 - loss: 6.7622 - yolo_layer_1_loss: 0.0028 - yolo_layer_2_loss: 0.5584 - yolo_layer_3_loss: 6.2010resizing:  448 448\n","107/204 [==============>...............] - ETA: 58s - loss: 7.0840 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8554 - yolo_layer_3_loss: 6.2258resizing:  384 384\n","110/204 [===============>..............] - ETA: 56s - loss: 7.0504 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8324 - yolo_layer_3_loss: 6.2152resizing:  448 448\n","118/204 [================>.............] - ETA: 52s - loss: 6.9543 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.7770 - yolo_layer_3_loss: 6.1746resizing:  448 448\n","126/204 [=================>............] - ETA: 47s - loss: 7.0044 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8282 - yolo_layer_3_loss: 6.1735resizing:  416 416\n","136/204 [===================>..........] - ETA: 41s - loss: 6.9760 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8229 - yolo_layer_3_loss: 6.1504resizing:  416 416\n","140/204 [===================>..........] - ETA: 39s - loss: 7.0156 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8375 - yolo_layer_3_loss: 6.1753resizing:  448 448\n","152/204 [=====================>........] - ETA: 32s - loss: 6.9663 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8403 - yolo_layer_3_loss: 6.1233resizing:  352 352\n","153/204 [=====================>........] - ETA: 31s - loss: 6.9603 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8349 - yolo_layer_3_loss: 6.1226resizing:  384 384\n","157/204 [======================>.......] - ETA: 29s - loss: 6.9307 - yolo_layer_1_loss: 0.0027 - yolo_layer_2_loss: 0.8141 - yolo_layer_3_loss: 6.1139resizing:  352 352\n","176/204 [========================>.....] - ETA: 17s - loss: 6.8579 - yolo_layer_1_loss: 0.0026 - yolo_layer_2_loss: 0.7562 - yolo_layer_3_loss: 6.0991resizing:  416 416\n","183/204 [=========================>....] - ETA: 12s - loss: 6.8811 - yolo_layer_1_loss: 0.0026 - yolo_layer_2_loss: 0.7276 - yolo_layer_3_loss: 6.1509resizing:  384 384\n","188/204 [==========================>...] - ETA: 9s - loss: 6.9442 - yolo_layer_1_loss: 0.0026 - yolo_layer_2_loss: 0.7624 - yolo_layer_3_loss: 6.1792 resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 6.8683 - yolo_layer_1_loss: 0.0025 - yolo_layer_2_loss: 0.7332 - yolo_layer_3_loss: 6.1326resizing:  416 416\n","204/204 [==============================] - 122s 597ms/step - loss: 6.8646 - yolo_layer_1_loss: 0.0025 - yolo_layer_2_loss: 0.7297 - yolo_layer_3_loss: 6.1325\n","\n","Epoch 00009: loss did not improve from 6.58361\n","Epoch 10/103\n","  4/204 [..............................] - ETA: 2:02 - loss: 5.8290 - yolo_layer_1_loss: 0.0022 - yolo_layer_2_loss: 0.0135 - yolo_layer_3_loss: 5.8134resizing:  384 384\n","resizing:  384 384\n","  6/204 [..............................] - ETA: 2:04 - loss: 6.2398 - yolo_layer_1_loss: 0.0024 - yolo_layer_2_loss: 0.0131 - yolo_layer_3_loss: 6.2244resizing:  352 352\n","  7/204 [>.............................] - ETA: 2:04 - loss: 6.0176 - yolo_layer_1_loss: 0.0024 - yolo_layer_2_loss: 0.0147 - yolo_layer_3_loss: 6.0005resizing:  416 416\n"," 10/204 [>.............................] - ETA: 2:03 - loss: 6.8533 - yolo_layer_1_loss: 0.0024 - yolo_layer_2_loss: 0.5302 - yolo_layer_3_loss: 6.3207resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:35 - loss: 6.3806 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.5151 - yolo_layer_3_loss: 5.8632resizing:  416 416\n"," 54/204 [======>.......................] - ETA: 1:34 - loss: 6.3688 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.4871 - yolo_layer_3_loss: 5.8794resizing:  352 352\n"," 55/204 [=======>......................] - ETA: 1:33 - loss: 6.3225 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.4784 - yolo_layer_3_loss: 5.8418resizing:  448 448\n"," 57/204 [=======>......................] - ETA: 1:32 - loss: 6.3128 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.4620 - yolo_layer_3_loss: 5.8485resizing:  352 352\n","resizing:  416 416\n"," 84/204 [===========>..................] - ETA: 1:15 - loss: 6.2671 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.5165 - yolo_layer_3_loss: 5.7483resizing:  448 448\n","106/204 [==============>...............] - ETA: 1:02 - loss: 6.1982 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.5467 - yolo_layer_3_loss: 5.6492resizing:  448 448\n","107/204 [==============>...............] - ETA: 1:01 - loss: 6.2522 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.5903 - yolo_layer_3_loss: 5.6595resizing:  448 448\n","112/204 [===============>..............] - ETA: 59s - loss: 6.2179 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.5871 - yolo_layer_3_loss: 5.6284resizing:  448 448\n","136/204 [===================>..........] - ETA: 44s - loss: 6.1928 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.6629 - yolo_layer_3_loss: 5.5276resizing:  448 448\n","138/204 [===================>..........] - ETA: 43s - loss: 6.1824 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.6536 - yolo_layer_3_loss: 5.5265resizing:  416 416\n","141/204 [===================>..........] - ETA: 41s - loss: 6.1983 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.6622 - yolo_layer_3_loss: 5.5338resizing:  352 352\n","154/204 [=====================>........] - ETA: 32s - loss: 6.1952 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.7039 - yolo_layer_3_loss: 5.4890resizing:  416 416\n","resizing:  352 352\n","156/204 [=====================>........] - ETA: 31s - loss: 6.1882 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.7005 - yolo_layer_3_loss: 5.4854resizing:  384 384\n","165/204 [=======================>......] - ETA: 25s - loss: 6.2181 - yolo_layer_1_loss: 0.0023 - yolo_layer_2_loss: 0.6854 - yolo_layer_3_loss: 5.5304resizing:  416 416\n","177/204 [=========================>....] - ETA: 17s - loss: 6.1699 - yolo_layer_1_loss: 0.0022 - yolo_layer_2_loss: 0.6422 - yolo_layer_3_loss: 5.5255resizing:  448 448\n","186/204 [==========================>...] - ETA: 11s - loss: 6.1328 - yolo_layer_1_loss: 0.0022 - yolo_layer_2_loss: 0.6258 - yolo_layer_3_loss: 5.5048resizing:  384 384\n","204/204 [==============================] - 130s 637ms/step - loss: 6.0457 - yolo_layer_1_loss: 0.0022 - yolo_layer_2_loss: 0.6175 - yolo_layer_3_loss: 5.4260\n","\n","Epoch 00010: loss improved from 6.58361 to 6.04573, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 11/103\n","  2/204 [..............................] - ETA: 1:55 - loss: 8.6896 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.6948 - yolo_layer_3_loss: 7.9930resizing:  384 384\n","  5/204 [..............................] - ETA: 1:51 - loss: 7.3133 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3742 - yolo_layer_3_loss: 6.9374resizing:  384 384\n"," 10/204 [>.............................] - ETA: 1:47 - loss: 7.3954 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.9345 - yolo_layer_3_loss: 6.4593resizing:  416 416\n"," 17/204 [=>............................] - ETA: 1:42 - loss: 7.2462 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.9654 - yolo_layer_3_loss: 6.2792resizing:  448 448\n"," 37/204 [====>.........................] - ETA: 1:41 - loss: 7.0049 - yolo_layer_1_loss: 0.0019 - yolo_layer_2_loss: 1.0851 - yolo_layer_3_loss: 5.9179resizing:  448 448\n"," 39/204 [====>.........................] - ETA: 1:40 - loss: 7.0121 - yolo_layer_1_loss: 0.0019 - yolo_layer_2_loss: 1.1321 - yolo_layer_3_loss: 5.8781resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:36 - loss: 6.9086 - yolo_layer_1_loss: 0.0019 - yolo_layer_2_loss: 1.0319 - yolo_layer_3_loss: 5.8748resizing:  352 352\n"," 58/204 [=======>......................] - ETA: 1:30 - loss: 6.7452 - yolo_layer_1_loss: 0.0019 - yolo_layer_2_loss: 0.9087 - yolo_layer_3_loss: 5.8346resizing:  352 352\n","resizing:  352 352\n"," 77/204 [==========>...................] - ETA: 1:14 - loss: 6.8533 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.8951 - yolo_layer_3_loss: 5.9563resizing:  352 352\n"," 83/204 [===========>..................] - ETA: 1:10 - loss: 6.8152 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.8311 - yolo_layer_3_loss: 5.9823resizing:  416 416\n"," 88/204 [===========>..................] - ETA: 1:06 - loss: 6.8469 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.7843 - yolo_layer_3_loss: 6.0607resizing:  352 352\n","101/204 [=============>................] - ETA: 58s - loss: 6.8111 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.8187 - yolo_layer_3_loss: 5.9906resizing:  352 352\n","106/204 [==============>...............] - ETA: 55s - loss: 6.8141 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.7806 - yolo_layer_3_loss: 6.0318resizing:  448 448\n","108/204 [==============>...............] - ETA: 54s - loss: 6.8248 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.7663 - yolo_layer_3_loss: 6.0567resizing:  384 384\n","117/204 [================>.............] - ETA: 49s - loss: 6.6816 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.7366 - yolo_layer_3_loss: 5.9433resizing:  352 352\n","123/204 [=================>............] - ETA: 45s - loss: 6.5827 - yolo_layer_1_loss: 0.0018 - yolo_layer_2_loss: 0.7031 - yolo_layer_3_loss: 5.8778resizing:  352 352\n","136/204 [===================>..........] - ETA: 38s - loss: 6.5237 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6368 - yolo_layer_3_loss: 5.8852resizing:  416 416\n","160/204 [======================>.......] - ETA: 24s - loss: 6.4802 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6450 - yolo_layer_3_loss: 5.8335resizing:  448 448\n","161/204 [======================>.......] - ETA: 24s - loss: 6.4857 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6410 - yolo_layer_3_loss: 5.8430resizing:  448 448\n","163/204 [======================>.......] - ETA: 23s - loss: 6.4515 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6333 - yolo_layer_3_loss: 5.8164resizing:  384 384\n","170/204 [========================>.....] - ETA: 19s - loss: 6.4781 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6386 - yolo_layer_3_loss: 5.8377resizing:  448 448\n","173/204 [========================>.....] - ETA: 17s - loss: 6.4826 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6535 - yolo_layer_3_loss: 5.8274resizing:  448 448\n","192/204 [===========================>..] - ETA: 6s - loss: 6.3925 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.6586 - yolo_layer_3_loss: 5.7321resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 6.4209 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.7036 - yolo_layer_3_loss: 5.7156resizing:  384 384\n","204/204 [==============================] - 119s 583ms/step - loss: 6.4324 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.7004 - yolo_layer_3_loss: 5.7302\n","\n","Epoch 00011: loss did not improve from 6.04573\n","Epoch 12/103\n","resizing:  448 448\n","  2/204 [..............................] - ETA: 1:43 - loss: 7.4783 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.5756 - yolo_layer_3_loss: 6.9013resizing:  384 384\n"," 22/204 [==>...........................] - ETA: 1:45 - loss: 5.6353 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.1556 - yolo_layer_3_loss: 5.4781resizing:  384 384\n"," 31/204 [===>..........................] - ETA: 1:38 - loss: 5.5353 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.1163 - yolo_layer_3_loss: 5.4175resizing:  448 448\n"," 37/204 [====>.........................] - ETA: 1:34 - loss: 5.7246 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.2377 - yolo_layer_3_loss: 5.4854resizing:  448 448\n"," 53/204 [======>.......................] - ETA: 1:28 - loss: 5.7922 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.3769 - yolo_layer_3_loss: 5.4137resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:27 - loss: 5.7810 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3627 - yolo_layer_3_loss: 5.4167resizing:  448 448\n"," 57/204 [=======>......................] - ETA: 1:27 - loss: 5.7982 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3565 - yolo_layer_3_loss: 5.4400resizing:  416 416\n"," 58/204 [=======>......................] - ETA: 1:27 - loss: 5.7667 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3530 - yolo_layer_3_loss: 5.4120resizing:  352 352\n"," 61/204 [=======>......................] - ETA: 1:25 - loss: 5.7452 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3362 - yolo_layer_3_loss: 5.4074resizing:  448 448\n"," 73/204 [=========>....................] - ETA: 1:17 - loss: 5.7318 - yolo_layer_1_loss: 0.0017 - yolo_layer_2_loss: 0.3423 - yolo_layer_3_loss: 5.3878resizing:  384 384\n","114/204 [===============>..............] - ETA: 53s - loss: 5.6928 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.4026 - yolo_layer_3_loss: 5.2886resizing:  384 384\n","122/204 [================>.............] - ETA: 48s - loss: 5.7560 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.4315 - yolo_layer_3_loss: 5.3229resizing:  416 416\n","124/204 [=================>............] - ETA: 46s - loss: 5.7373 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.4248 - yolo_layer_3_loss: 5.3109resizing:  352 352\n","131/204 [==================>...........] - ETA: 42s - loss: 5.7044 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.4151 - yolo_layer_3_loss: 5.2878resizing:  384 384\n","133/204 [==================>...........] - ETA: 41s - loss: 5.7072 - yolo_layer_1_loss: 0.0016 - yolo_layer_2_loss: 0.4114 - yolo_layer_3_loss: 5.2943resizing:  416 416\n","141/204 [===================>..........] - ETA: 36s - loss: 5.7572 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4349 - yolo_layer_3_loss: 5.3207resizing:  352 352\n","153/204 [=====================>........] - ETA: 29s - loss: 5.7304 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4192 - yolo_layer_3_loss: 5.3097resizing:  352 352\n","155/204 [=====================>........] - ETA: 28s - loss: 5.7257 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4139 - yolo_layer_3_loss: 5.3103resizing:  416 416\n","159/204 [======================>.......] - ETA: 26s - loss: 5.7215 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4043 - yolo_layer_3_loss: 5.3157resizing:  448 448\n","164/204 [=======================>......] - ETA: 23s - loss: 5.7074 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4118 - yolo_layer_3_loss: 5.2941resizing:  384 384\n","171/204 [========================>.....] - ETA: 19s - loss: 5.7372 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4127 - yolo_layer_3_loss: 5.3230resizing:  448 448\n","176/204 [========================>.....] - ETA: 16s - loss: 5.7213 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4363 - yolo_layer_3_loss: 5.2835resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 5.7715 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4684 - yolo_layer_3_loss: 5.3016resizing:  352 352\n","204/204 [==============================] - 121s 593ms/step - loss: 5.7605 - yolo_layer_1_loss: 0.0015 - yolo_layer_2_loss: 0.4661 - yolo_layer_3_loss: 5.2929\n","\n","Epoch 00012: loss improved from 6.04573 to 5.76049, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 13/103\n","  4/204 [..............................] - ETA: 1:48 - loss: 4.7040 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0966 - yolo_layer_3_loss: 4.6064resizing:  352 352\n","  6/204 [..............................] - ETA: 1:44 - loss: 4.8563 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0669 - yolo_layer_3_loss: 4.7883resizing:  416 416\n","  8/204 [>.............................] - ETA: 1:41 - loss: 5.2118 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0516 - yolo_layer_3_loss: 5.1590resizing:  384 384\n"," 28/204 [===>..........................] - ETA: 1:34 - loss: 6.0298 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6003 - yolo_layer_3_loss: 5.4284resizing:  416 416\n"," 33/204 [===>..........................] - ETA: 1:32 - loss: 5.8866 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.5108 - yolo_layer_3_loss: 5.3747resizing:  448 448\n"," 56/204 [=======>......................] - ETA: 1:26 - loss: 6.0574 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5794 - yolo_layer_3_loss: 5.4768resizing:  384 384\n"," 58/204 [=======>......................] - ETA: 1:25 - loss: 6.0088 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5642 - yolo_layer_3_loss: 5.4433resizing:  448 448\n"," 72/204 [=========>....................] - ETA: 1:19 - loss: 5.8766 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5071 - yolo_layer_3_loss: 5.3681resizing:  384 384\n"," 83/204 [===========>..................] - ETA: 1:14 - loss: 5.9147 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.6243 - yolo_layer_3_loss: 5.2890resizing:  448 448\n"," 84/204 [===========>..................] - ETA: 1:13 - loss: 5.8877 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.6170 - yolo_layer_3_loss: 5.2694resizing:  352 352\n"," 86/204 [===========>..................] - ETA: 1:12 - loss: 5.8632 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.6028 - yolo_layer_3_loss: 5.2590resizing:  352 352\n","101/204 [=============>................] - ETA: 1:01 - loss: 5.9008 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5324 - yolo_layer_3_loss: 5.3670resizing:  352 352\n","106/204 [==============>...............] - ETA: 58s - loss: 5.9015 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5090 - yolo_layer_3_loss: 5.3911resizing:  384 384\n","114/204 [===============>..............] - ETA: 53s - loss: 5.7796 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.4738 - yolo_layer_3_loss: 5.3045resizing:  448 448\n","119/204 [================>.............] - ETA: 49s - loss: 5.8551 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5537 - yolo_layer_3_loss: 5.3001resizing:  416 416\n","126/204 [=================>............] - ETA: 45s - loss: 5.9100 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.6012 - yolo_layer_3_loss: 5.3075resizing:  384 384\n","129/204 [=================>............] - ETA: 44s - loss: 5.9272 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.6047 - yolo_layer_3_loss: 5.3212resizing:  352 352\n","159/204 [======================>.......] - ETA: 26s - loss: 5.8791 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5365 - yolo_layer_3_loss: 5.3413resizing:  384 384\n","165/204 [=======================>......] - ETA: 22s - loss: 5.9155 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.5173 - yolo_layer_3_loss: 5.3969resizing:  448 448\n","176/204 [========================>.....] - ETA: 16s - loss: 5.9147 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4891 - yolo_layer_3_loss: 5.4243resizing:  352 352\n","180/204 [=========================>....] - ETA: 13s - loss: 5.8712 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4906 - yolo_layer_3_loss: 5.3794resizing:  352 352\n","184/204 [==========================>...] - ETA: 11s - loss: 5.8464 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4950 - yolo_layer_3_loss: 5.3501resizing:  416 416\n","191/204 [===========================>..] - ETA: 7s - loss: 5.8377 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.5135 - yolo_layer_3_loss: 5.3229resizing:  384 384\n","204/204 [==============================] - 118s 578ms/step - loss: 5.8576 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.5029 - yolo_layer_3_loss: 5.3535\n","\n","Epoch 00013: loss did not improve from 5.76049\n","Epoch 14/103\n","  1/204 [..............................] - ETA: 1:49 - loss: 7.8626 - yolo_layer_1_loss: 9.9853e-04 - yolo_layer_2_loss: 0.0236 - yolo_layer_3_loss: 7.8381resizing:  384 384\n","  4/204 [..............................] - ETA: 1:48 - loss: 5.7634 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0131 - yolo_layer_3_loss: 5.7493resizing:  416 416\n"," 12/204 [>.............................] - ETA: 1:48 - loss: 5.3810 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0282 - yolo_layer_3_loss: 5.3517resizing:  416 416\n"," 21/204 [==>...........................] - ETA: 1:49 - loss: 5.4481 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.2830 - yolo_layer_3_loss: 5.1639resizing:  352 352\n"," 26/204 [==>...........................] - ETA: 1:48 - loss: 5.4908 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.2354 - yolo_layer_3_loss: 5.2543resizing:  352 352\n"," 38/204 [====>.........................] - ETA: 1:38 - loss: 5.7881 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.3558 - yolo_layer_3_loss: 5.4312resizing:  448 448\n"," 58/204 [=======>......................] - ETA: 1:26 - loss: 5.6514 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4214 - yolo_layer_3_loss: 5.2289resizing:  384 384\n"," 59/204 [=======>......................] - ETA: 1:25 - loss: 5.6748 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4169 - yolo_layer_3_loss: 5.2567resizing:  416 416\n"," 76/204 [==========>...................] - ETA: 1:18 - loss: 5.4752 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.3937 - yolo_layer_3_loss: 5.0803resizing:  352 352\n"," 81/204 [==========>...................] - ETA: 1:15 - loss: 5.5381 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.3847 - yolo_layer_3_loss: 5.1522resizing:  384 384\n"," 84/204 [===========>..................] - ETA: 1:13 - loss: 5.5667 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4170 - yolo_layer_3_loss: 5.1484resizing:  384 384\n"," 88/204 [===========>..................] - ETA: 1:11 - loss: 5.5762 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4274 - yolo_layer_3_loss: 5.1477resizing:  352 352\n","104/204 [==============>...............] - ETA: 59s - loss: 5.3988 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.4156 - yolo_layer_3_loss: 4.9821 resizing:  416 416\n","110/204 [===============>..............] - ETA: 55s - loss: 5.4620 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4030 - yolo_layer_3_loss: 5.0579resizing:  384 384\n","114/204 [===============>..............] - ETA: 53s - loss: 5.4439 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4060 - yolo_layer_3_loss: 5.0368resizing:  352 352\n","121/204 [================>.............] - ETA: 49s - loss: 5.4053 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3829 - yolo_layer_3_loss: 5.0213resizing:  384 384\n","135/204 [==================>...........] - ETA: 40s - loss: 5.4574 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3789 - yolo_layer_3_loss: 5.0774resizing:  352 352\n","140/204 [===================>..........] - ETA: 37s - loss: 5.4442 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3656 - yolo_layer_3_loss: 5.0774resizing:  416 416\n","155/204 [=====================>........] - ETA: 28s - loss: 5.4352 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3547 - yolo_layer_3_loss: 5.0794resizing:  384 384\n","159/204 [======================>.......] - ETA: 26s - loss: 5.4522 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3646 - yolo_layer_3_loss: 5.0865resizing:  448 448\n","163/204 [======================>.......] - ETA: 24s - loss: 5.4631 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3562 - yolo_layer_3_loss: 5.1058resizing:  352 352\n","164/204 [=======================>......] - ETA: 23s - loss: 5.4583 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3541 - yolo_layer_3_loss: 5.1031resizing:  416 416\n","177/204 [=========================>....] - ETA: 15s - loss: 5.4331 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3574 - yolo_layer_3_loss: 5.0746resizing:  448 448\n","183/204 [=========================>....] - ETA: 12s - loss: 5.4333 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3461 - yolo_layer_3_loss: 5.0862resizing:  448 448\n","204/204 [==============================] - 122s 598ms/step - loss: 5.4342 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.3496 - yolo_layer_3_loss: 5.0835\n","\n","Epoch 00014: loss improved from 5.76049 to 5.43422, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 15/103\n","  4/204 [..............................] - ETA: 2:22 - loss: 4.8791 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 1.1601 - yolo_layer_3_loss: 3.7176resizing:  448 448\n","  9/204 [>.............................] - ETA: 2:17 - loss: 5.1684 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.8728 - yolo_layer_3_loss: 4.2942resizing:  448 448\n"," 17/204 [=>............................] - ETA: 2:11 - loss: 5.6001 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 1.1595 - yolo_layer_3_loss: 4.4393resizing:  384 384\n"," 28/204 [===>..........................] - ETA: 2:03 - loss: 5.1191 - yolo_layer_1_loss: 0.0014 - yolo_layer_2_loss: 0.9040 - yolo_layer_3_loss: 4.2137resizing:  416 416\n"," 30/204 [===>..........................] - ETA: 1:59 - loss: 5.1628 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.8441 - yolo_layer_3_loss: 4.3173resizing:  352 352\n"," 38/204 [====>.........................] - ETA: 1:49 - loss: 5.1976 - yolo_layer_1_loss: 0.0013 - yolo_layer_2_loss: 0.7458 - yolo_layer_3_loss: 4.4506resizing:  384 384\n"," 50/204 [======>.......................] - ETA: 1:36 - loss: 5.4061 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.6271 - yolo_layer_3_loss: 4.7779resizing:  416 416\n"," 54/204 [======>.......................] - ETA: 1:33 - loss: 5.5551 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.6738 - yolo_layer_3_loss: 4.8802resizing:  384 384\n"," 59/204 [=======>......................] - ETA: 1:30 - loss: 5.3886 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.6172 - yolo_layer_3_loss: 4.7703resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:28 - loss: 5.4048 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.6187 - yolo_layer_3_loss: 4.7849resizing:  352 352\n"," 68/204 [=========>....................] - ETA: 1:23 - loss: 5.4542 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5748 - yolo_layer_3_loss: 4.8782resizing:  448 448\n"," 69/204 [=========>....................] - ETA: 1:23 - loss: 5.4301 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5666 - yolo_layer_3_loss: 4.8623resizing:  384 384\n","107/204 [==============>...............] - ETA: 56s - loss: 5.5142 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5289 - yolo_layer_3_loss: 4.9843resizing:  352 352\n","108/204 [==============>...............] - ETA: 56s - loss: 5.5110 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5241 - yolo_layer_3_loss: 4.9859resizing:  352 352\n","109/204 [===============>..............] - ETA: 55s - loss: 5.5148 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5193 - yolo_layer_3_loss: 4.9944resizing:  448 448\n","120/204 [================>.............] - ETA: 48s - loss: 5.4133 - yolo_layer_1_loss: 0.0010 - yolo_layer_2_loss: 0.4938 - yolo_layer_3_loss: 4.9185resizing:  448 448\n","124/204 [=================>............] - ETA: 46s - loss: 5.4234 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4781 - yolo_layer_3_loss: 4.9443resizing:  384 384\n","131/204 [==================>...........] - ETA: 43s - loss: 5.4658 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4789 - yolo_layer_3_loss: 4.9858resizing:  352 352\n","152/204 [=====================>........] - ETA: 30s - loss: 5.5134 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4248 - yolo_layer_3_loss: 5.0875resizing:  384 384\n","156/204 [=====================>........] - ETA: 27s - loss: 5.5206 - yolo_layer_1_loss: 0.0010 - yolo_layer_2_loss: 0.4491 - yolo_layer_3_loss: 5.0705resizing:  448 448\n","160/204 [======================>.......] - ETA: 25s - loss: 5.4991 - yolo_layer_1_loss: 0.0010 - yolo_layer_2_loss: 0.4405 - yolo_layer_3_loss: 5.0575resizing:  448 448\n","163/204 [======================>.......] - ETA: 23s - loss: 5.5037 - yolo_layer_1_loss: 0.0010 - yolo_layer_2_loss: 0.4325 - yolo_layer_3_loss: 5.0702resizing:  352 352\n","170/204 [========================>.....] - ETA: 19s - loss: 5.4984 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4313 - yolo_layer_3_loss: 5.0660resizing:  384 384\n","171/204 [========================>.....] - ETA: 19s - loss: 5.5291 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4542 - yolo_layer_3_loss: 5.0738resizing:  416 416\n","204/204 [==============================] - 121s 592ms/step - loss: 5.5370 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.4647 - yolo_layer_3_loss: 5.0713\n","\n","Epoch 00015: loss did not improve from 5.43422\n","Epoch 16/103\n","  6/204 [..............................] - ETA: 2:07 - loss: 5.1245 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.0224 - yolo_layer_3_loss: 5.1010resizing:  384 384\n","  9/204 [>.............................] - ETA: 2:05 - loss: 5.2693 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.5284 - yolo_layer_3_loss: 4.7397resizing:  352 352\n"," 14/204 [=>............................] - ETA: 2:02 - loss: 5.1545 - yolo_layer_1_loss: 0.0012 - yolo_layer_2_loss: 0.5625 - yolo_layer_3_loss: 4.5908resizing:  448 448\n"," 17/204 [=>............................] - ETA: 1:58 - loss: 5.6175 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7160 - yolo_layer_3_loss: 4.9003resizing:  352 352\n"," 19/204 [=>............................] - ETA: 1:55 - loss: 5.7898 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6411 - yolo_layer_3_loss: 5.1476resizing:  352 352\n"," 25/204 [==>...........................] - ETA: 1:46 - loss: 5.9800 - yolo_layer_1_loss: 0.0010 - yolo_layer_2_loss: 0.8585 - yolo_layer_3_loss: 5.1204resizing:  448 448\n"," 56/204 [=======>......................] - ETA: 1:32 - loss: 5.8813 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7061 - yolo_layer_3_loss: 5.1742resizing:  448 448\n"," 72/204 [=========>....................] - ETA: 1:24 - loss: 5.7056 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6940 - yolo_layer_3_loss: 5.0105resizing:  416 416\n"," 73/204 [=========>....................] - ETA: 1:23 - loss: 5.7045 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7138 - yolo_layer_3_loss: 4.9896resizing:  384 384\n"," 75/204 [==========>...................] - ETA: 1:22 - loss: 5.7551 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7279 - yolo_layer_3_loss: 5.0261resizing:  416 416\n"," 78/204 [==========>...................] - ETA: 1:21 - loss: 5.7495 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7335 - yolo_layer_3_loss: 5.0149resizing:  448 448\n"," 80/204 [==========>...................] - ETA: 1:20 - loss: 5.7438 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7376 - yolo_layer_3_loss: 5.0051resizing:  448 448\n","103/204 [==============>...............] - ETA: 1:05 - loss: 5.7053 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7280 - yolo_layer_3_loss: 4.9761resizing:  384 384\n","107/204 [==============>...............] - ETA: 1:03 - loss: 5.7740 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7781 - yolo_layer_3_loss: 4.9948resizing:  416 416\n","110/204 [===============>..............] - ETA: 1:01 - loss: 5.7583 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7573 - yolo_layer_3_loss: 4.9999resizing:  448 448\n","126/204 [=================>............] - ETA: 50s - loss: 5.6840 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7356 - yolo_layer_3_loss: 4.9472resizing:  384 384\n","135/204 [==================>...........] - ETA: 44s - loss: 5.6429 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7557 - yolo_layer_3_loss: 4.8861resizing:  352 352\n","136/204 [===================>..........] - ETA: 44s - loss: 5.6638 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7502 - yolo_layer_3_loss: 4.9124resizing:  448 448\n","153/204 [=====================>........] - ETA: 32s - loss: 5.6235 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7442 - yolo_layer_3_loss: 4.8782resizing:  448 448\n","156/204 [=====================>........] - ETA: 30s - loss: 5.6255 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7418 - yolo_layer_3_loss: 4.8827resizing:  448 448\n","resizing:  384 384\n","163/204 [======================>.......] - ETA: 26s - loss: 5.5783 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.7275 - yolo_layer_3_loss: 4.8496resizing:  352 352\n","185/204 [==========================>...] - ETA: 12s - loss: 5.5992 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6586 - yolo_layer_3_loss: 4.9395resizing:  384 384\n","187/204 [==========================>...] - ETA: 10s - loss: 5.6014 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6525 - yolo_layer_3_loss: 4.9478resizing:  384 384\n","204/204 [==============================] - 127s 621ms/step - loss: 5.5754 - yolo_layer_1_loss: 0.0011 - yolo_layer_2_loss: 0.6672 - yolo_layer_3_loss: 4.9071\n","\n","Epoch 00016: loss did not improve from 5.43422\n","Epoch 17/103\n","  2/204 [..............................] - ETA: 1:48 - loss: 6.0969 - yolo_layer_1_loss: 7.9263e-04 - yolo_layer_2_loss: 0.0105 - yolo_layer_3_loss: 6.0857resizing:  448 448\n","  4/204 [..............................] - ETA: 1:47 - loss: 6.4599 - yolo_layer_1_loss: 8.4004e-04 - yolo_layer_2_loss: 1.1252 - yolo_layer_3_loss: 5.3338resizing:  448 448\n","  7/204 [>.............................] - ETA: 1:52 - loss: 5.6064 - yolo_layer_1_loss: 8.8288e-04 - yolo_layer_2_loss: 0.6467 - yolo_layer_3_loss: 4.9588resizing:  352 352\n"," 21/204 [==>...........................] - ETA: 1:52 - loss: 5.8652 - yolo_layer_1_loss: 9.8795e-04 - yolo_layer_2_loss: 0.5913 - yolo_layer_3_loss: 5.2729resizing:  352 352\n"," 25/204 [==>...........................] - ETA: 1:46 - loss: 5.5742 - yolo_layer_1_loss: 9.5649e-04 - yolo_layer_2_loss: 0.4988 - yolo_layer_3_loss: 5.0745resizing:  352 352\n"," 37/204 [====>.........................] - ETA: 1:34 - loss: 5.5962 - yolo_layer_1_loss: 8.7980e-04 - yolo_layer_2_loss: 0.3747 - yolo_layer_3_loss: 5.2207resizing:  352 352\n"," 52/204 [======>.......................] - ETA: 1:22 - loss: 5.4095 - yolo_layer_1_loss: 8.3457e-04 - yolo_layer_2_loss: 0.2710 - yolo_layer_3_loss: 5.1377resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:20 - loss: 5.4415 - yolo_layer_1_loss: 8.2817e-04 - yolo_layer_2_loss: 0.2611 - yolo_layer_3_loss: 5.1795resizing:  384 384\n"," 57/204 [=======>......................] - ETA: 1:19 - loss: 5.4439 - yolo_layer_1_loss: 8.3642e-04 - yolo_layer_2_loss: 0.3216 - yolo_layer_3_loss: 5.1214resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:17 - loss: 5.3397 - yolo_layer_1_loss: 8.4647e-04 - yolo_layer_2_loss: 0.2975 - yolo_layer_3_loss: 5.0414resizing:  352 352\n"," 67/204 [========>.....................] - ETA: 1:14 - loss: 5.3162 - yolo_layer_1_loss: 8.4390e-04 - yolo_layer_2_loss: 0.2757 - yolo_layer_3_loss: 5.0397resizing:  352 352\n"," 71/204 [=========>....................] - ETA: 1:12 - loss: 5.2952 - yolo_layer_1_loss: 8.3898e-04 - yolo_layer_2_loss: 0.2685 - yolo_layer_3_loss: 5.0258resizing:  352 352\n","102/204 [==============>...............] - ETA: 54s - loss: 5.2946 - yolo_layer_1_loss: 7.8664e-04 - yolo_layer_2_loss: 0.2480 - yolo_layer_3_loss: 5.0459resizing:  448 448\n","106/204 [==============>...............] - ETA: 52s - loss: 5.2916 - yolo_layer_1_loss: 7.8798e-04 - yolo_layer_2_loss: 0.2638 - yolo_layer_3_loss: 5.0270resizing:  416 416\n","107/204 [==============>...............] - ETA: 51s - loss: 5.2970 - yolo_layer_1_loss: 7.9467e-04 - yolo_layer_2_loss: 0.2614 - yolo_layer_3_loss: 5.0348resizing:  416 416\n","109/204 [===============>..............] - ETA: 51s - loss: 5.2511 - yolo_layer_1_loss: 7.9797e-04 - yolo_layer_2_loss: 0.2567 - yolo_layer_3_loss: 4.9935resizing:  448 448\n","125/204 [=================>............] - ETA: 43s - loss: 5.3236 - yolo_layer_1_loss: 8.2085e-04 - yolo_layer_2_loss: 0.3852 - yolo_layer_3_loss: 4.9377resizing:  384 384\n","127/204 [=================>............] - ETA: 42s - loss: 5.3532 - yolo_layer_1_loss: 8.2364e-04 - yolo_layer_2_loss: 0.3993 - yolo_layer_3_loss: 4.9530resizing:  416 416\n","153/204 [=====================>........] - ETA: 29s - loss: 5.3147 - yolo_layer_1_loss: 8.4238e-04 - yolo_layer_2_loss: 0.4076 - yolo_layer_3_loss: 4.9062resizing:  416 416\n","156/204 [=====================>........] - ETA: 27s - loss: 5.3082 - yolo_layer_1_loss: 8.4360e-04 - yolo_layer_2_loss: 0.3999 - yolo_layer_3_loss: 4.9075resizing:  448 448\n","170/204 [========================>.....] - ETA: 19s - loss: 5.2082 - yolo_layer_1_loss: 8.6881e-04 - yolo_layer_2_loss: 0.3727 - yolo_layer_3_loss: 4.8346resizing:  352 352\n","172/204 [========================>.....] - ETA: 18s - loss: 5.2070 - yolo_layer_1_loss: 8.7195e-04 - yolo_layer_2_loss: 0.3778 - yolo_layer_3_loss: 4.8283resizing:  448 448\n","183/204 [=========================>....] - ETA: 12s - loss: 5.1874 - yolo_layer_1_loss: 8.8388e-04 - yolo_layer_2_loss: 0.3949 - yolo_layer_3_loss: 4.7916resizing:  416 416\n","191/204 [===========================>..] - ETA: 7s - loss: 5.1793 - yolo_layer_1_loss: 9.0129e-04 - yolo_layer_2_loss: 0.4182 - yolo_layer_3_loss: 4.7602resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 5.2442 - yolo_layer_1_loss: 9.0565e-04 - yolo_layer_2_loss: 0.4728 - yolo_layer_3_loss: 4.7705resizing:  352 352\n","204/204 [==============================] - 122s 597ms/step - loss: 5.2422 - yolo_layer_1_loss: 9.0503e-04 - yolo_layer_2_loss: 0.4773 - yolo_layer_3_loss: 4.7640\n","\n","Epoch 00017: loss improved from 5.43422 to 5.24224, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","resizing:  384 384\n","Epoch 18/103\n","  3/204 [..............................] - ETA: 1:45 - loss: 3.2289 - yolo_layer_1_loss: 7.6586e-04 - yolo_layer_2_loss: 0.0631 - yolo_layer_3_loss: 3.1650resizing:  384 384\n","  7/204 [>.............................] - ETA: 1:46 - loss: 4.4528 - yolo_layer_1_loss: 8.3381e-04 - yolo_layer_2_loss: 0.3062 - yolo_layer_3_loss: 4.1457resizing:  352 352\n"," 30/204 [===>..........................] - ETA: 1:31 - loss: 4.8959 - yolo_layer_1_loss: 7.4079e-04 - yolo_layer_2_loss: 0.1662 - yolo_layer_3_loss: 4.7290resizing:  384 384\n"," 38/204 [====>.........................] - ETA: 1:25 - loss: 5.2551 - yolo_layer_1_loss: 7.0868e-04 - yolo_layer_2_loss: 0.1786 - yolo_layer_3_loss: 5.0758resizing:  384 384\n"," 60/204 [=======>......................] - ETA: 1:15 - loss: 5.4724 - yolo_layer_1_loss: 7.0141e-04 - yolo_layer_2_loss: 0.3956 - yolo_layer_3_loss: 5.0761resizing:  416 416\n"," 71/204 [=========>....................] - ETA: 1:09 - loss: 5.4986 - yolo_layer_1_loss: 7.1145e-04 - yolo_layer_2_loss: 0.4073 - yolo_layer_3_loss: 5.0907resizing:  352 352\n"," 78/204 [==========>...................] - ETA: 1:07 - loss: 5.4441 - yolo_layer_1_loss: 7.2436e-04 - yolo_layer_2_loss: 0.3871 - yolo_layer_3_loss: 5.0562resizing:  448 448\n"," 80/204 [==========>...................] - ETA: 1:06 - loss: 5.4593 - yolo_layer_1_loss: 7.2723e-04 - yolo_layer_2_loss: 0.3926 - yolo_layer_3_loss: 5.0660resizing:  416 416\n"," 86/204 [===========>..................] - ETA: 1:03 - loss: 5.4513 - yolo_layer_1_loss: 7.2396e-04 - yolo_layer_2_loss: 0.3696 - yolo_layer_3_loss: 5.0809resizing:  448 448\n"," 88/204 [===========>..................] - ETA: 1:02 - loss: 5.4398 - yolo_layer_1_loss: 7.2452e-04 - yolo_layer_2_loss: 0.3613 - yolo_layer_3_loss: 5.0778resizing:  448 448\n","102/204 [==============>...............] - ETA: 56s - loss: 5.4229 - yolo_layer_1_loss: 7.6127e-04 - yolo_layer_2_loss: 0.3241 - yolo_layer_3_loss: 5.0980resizing:  352 352\n","104/204 [==============>...............] - ETA: 55s - loss: 5.4027 - yolo_layer_1_loss: 7.6853e-04 - yolo_layer_2_loss: 0.3183 - yolo_layer_3_loss: 5.0836resizing:  384 384\n","118/204 [================>.............] - ETA: 47s - loss: 5.2813 - yolo_layer_1_loss: 7.5940e-04 - yolo_layer_2_loss: 0.2889 - yolo_layer_3_loss: 4.9916resizing:  352 352\n","122/204 [================>.............] - ETA: 45s - loss: 5.3201 - yolo_layer_1_loss: 7.5708e-04 - yolo_layer_2_loss: 0.3394 - yolo_layer_3_loss: 4.9800resizing:  448 448\n","131/204 [==================>...........] - ETA: 40s - loss: 5.3521 - yolo_layer_1_loss: 7.4809e-04 - yolo_layer_2_loss: 0.3563 - yolo_layer_3_loss: 4.9950resizing:  416 416\n","133/204 [==================>...........] - ETA: 39s - loss: 5.3499 - yolo_layer_1_loss: 7.4500e-04 - yolo_layer_2_loss: 0.3510 - yolo_layer_3_loss: 4.9981resizing:  352 352\n","152/204 [=====================>........] - ETA: 29s - loss: 5.3551 - yolo_layer_1_loss: 7.5676e-04 - yolo_layer_2_loss: 0.3281 - yolo_layer_3_loss: 5.0263resizing:  384 384\n","158/204 [======================>.......] - ETA: 25s - loss: 5.3362 - yolo_layer_1_loss: 7.5145e-04 - yolo_layer_2_loss: 0.3157 - yolo_layer_3_loss: 5.0197resizing:  352 352\n","159/204 [======================>.......] - ETA: 25s - loss: 5.3466 - yolo_layer_1_loss: 7.5087e-04 - yolo_layer_2_loss: 0.3138 - yolo_layer_3_loss: 5.0321resizing:  448 448\n","161/204 [======================>.......] - ETA: 23s - loss: 5.3318 - yolo_layer_1_loss: 7.5047e-04 - yolo_layer_2_loss: 0.3099 - yolo_layer_3_loss: 5.0211resizing:  352 352\n","172/204 [========================>.....] - ETA: 17s - loss: 5.2810 - yolo_layer_1_loss: 7.5261e-04 - yolo_layer_2_loss: 0.3018 - yolo_layer_3_loss: 4.9784resizing:  448 448\n","175/204 [========================>.....] - ETA: 16s - loss: 5.2767 - yolo_layer_1_loss: 7.4942e-04 - yolo_layer_2_loss: 0.2966 - yolo_layer_3_loss: 4.9794resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 5.3204 - yolo_layer_1_loss: 7.3354e-04 - yolo_layer_2_loss: 0.3554 - yolo_layer_3_loss: 4.9643resizing:  352 352\n","204/204 [==============================] - 112s 550ms/step - loss: 5.3318 - yolo_layer_1_loss: 7.3292e-04 - yolo_layer_2_loss: 0.3536 - yolo_layer_3_loss: 4.9775\n","\n","Epoch 00018: loss did not improve from 5.24224\n","Epoch 19/103\n","  1/204 [..............................] - ETA: 1:36 - loss: 5.4053 - yolo_layer_1_loss: 5.5866e-04 - yolo_layer_2_loss: 0.0038 - yolo_layer_3_loss: 5.4009resizing:  448 448\n","  8/204 [>.............................] - ETA: 1:53 - loss: 4.6329 - yolo_layer_1_loss: 6.8701e-04 - yolo_layer_2_loss: 0.0037 - yolo_layer_3_loss: 4.6285resizing:  384 384\n"," 17/204 [=>............................] - ETA: 2:00 - loss: 5.0739 - yolo_layer_1_loss: 8.3990e-04 - yolo_layer_2_loss: 0.5977 - yolo_layer_3_loss: 4.4754resizing:  448 448\n"," 27/204 [==>...........................] - ETA: 1:49 - loss: 4.8014 - yolo_layer_1_loss: 7.8319e-04 - yolo_layer_2_loss: 0.4764 - yolo_layer_3_loss: 4.3242resizing:  384 384\n"," 38/204 [====>.........................] - ETA: 1:45 - loss: 4.6349 - yolo_layer_1_loss: 8.1966e-04 - yolo_layer_2_loss: 0.4036 - yolo_layer_3_loss: 4.2305resizing:  352 352\n"," 50/204 [======>.......................] - ETA: 1:33 - loss: 4.7170 - yolo_layer_1_loss: 7.7869e-04 - yolo_layer_2_loss: 0.3896 - yolo_layer_3_loss: 4.3266resizing:  416 416\n"," 58/204 [=======>......................] - ETA: 1:29 - loss: 4.6752 - yolo_layer_1_loss: 7.6567e-04 - yolo_layer_2_loss: 0.3725 - yolo_layer_3_loss: 4.3020resizing:  416 416\n"," 69/204 [=========>....................] - ETA: 1:23 - loss: 4.6539 - yolo_layer_1_loss: 7.6181e-04 - yolo_layer_2_loss: 0.3530 - yolo_layer_3_loss: 4.3002resizing:  416 416\n"," 76/204 [==========>...................] - ETA: 1:19 - loss: 4.7242 - yolo_layer_1_loss: 7.5469e-04 - yolo_layer_2_loss: 0.3786 - yolo_layer_3_loss: 4.3448resizing:  448 448\n"," 79/204 [==========>...................] - ETA: 1:17 - loss: 4.7451 - yolo_layer_1_loss: 7.5324e-04 - yolo_layer_2_loss: 0.3646 - yolo_layer_3_loss: 4.3798resizing:  416 416\n"," 90/204 [============>.................] - ETA: 1:11 - loss: 4.7675 - yolo_layer_1_loss: 7.5272e-04 - yolo_layer_2_loss: 0.3889 - yolo_layer_3_loss: 4.3779resizing:  352 352\n","107/204 [==============>...............] - ETA: 1:00 - loss: 4.8631 - yolo_layer_1_loss: 7.4757e-04 - yolo_layer_2_loss: 0.4573 - yolo_layer_3_loss: 4.4050resizing:  448 448\n","119/204 [================>.............] - ETA: 52s - loss: 5.0053 - yolo_layer_1_loss: 7.3973e-04 - yolo_layer_2_loss: 0.5131 - yolo_layer_3_loss: 4.4915resizing:  448 448\n","120/204 [================>.............] - ETA: 51s - loss: 4.9941 - yolo_layer_1_loss: 7.3947e-04 - yolo_layer_2_loss: 0.5089 - yolo_layer_3_loss: 4.4844resizing:  416 416\n","125/204 [=================>............] - ETA: 49s - loss: 4.9895 - yolo_layer_1_loss: 7.4252e-04 - yolo_layer_2_loss: 0.5116 - yolo_layer_3_loss: 4.4772resizing:  448 448\n","127/204 [=================>............] - ETA: 47s - loss: 4.9832 - yolo_layer_1_loss: 7.4378e-04 - yolo_layer_2_loss: 0.5342 - yolo_layer_3_loss: 4.4483resizing:  352 352\n","133/204 [==================>...........] - ETA: 44s - loss: 4.9293 - yolo_layer_1_loss: 7.4737e-04 - yolo_layer_2_loss: 0.5437 - yolo_layer_3_loss: 4.3848resizing:  448 448\n","155/204 [=====================>........] - ETA: 30s - loss: 4.9246 - yolo_layer_1_loss: 7.4434e-04 - yolo_layer_2_loss: 0.4993 - yolo_layer_3_loss: 4.4245resizing:  352 352\n","163/204 [======================>.......] - ETA: 25s - loss: 4.9023 - yolo_layer_1_loss: 7.4660e-04 - yolo_layer_2_loss: 0.4863 - yolo_layer_3_loss: 4.4152resizing:  384 384\n","168/204 [=======================>......] - ETA: 22s - loss: 4.9082 - yolo_layer_1_loss: 7.3996e-04 - yolo_layer_2_loss: 0.4726 - yolo_layer_3_loss: 4.4349resizing:  352 352\n","170/204 [========================>.....] - ETA: 21s - loss: 4.9187 - yolo_layer_1_loss: 7.3751e-04 - yolo_layer_2_loss: 0.4788 - yolo_layer_3_loss: 4.4392resizing:  352 352\n","173/204 [========================>.....] - ETA: 19s - loss: 4.9128 - yolo_layer_1_loss: 7.3343e-04 - yolo_layer_2_loss: 0.4706 - yolo_layer_3_loss: 4.4415resizing:  384 384\n","176/204 [========================>.....] - ETA: 17s - loss: 4.9176 - yolo_layer_1_loss: 7.3131e-04 - yolo_layer_2_loss: 0.4626 - yolo_layer_3_loss: 4.4542resizing:  352 352\n","204/204 [==============================] - 123s 602ms/step - loss: 4.9456 - yolo_layer_1_loss: 7.0320e-04 - yolo_layer_2_loss: 0.4385 - yolo_layer_3_loss: 4.5063\n","\n","Epoch 00019: loss improved from 5.24224 to 4.94556, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 20/103\n","resizing:  448 448\n","  2/204 [..............................] - ETA: 1:42 - loss: 5.5817 - yolo_layer_1_loss: 5.6465e-04 - yolo_layer_2_loss: 0.6348 - yolo_layer_3_loss: 4.9463resizing:  352 352\n","  5/204 [..............................] - ETA: 1:47 - loss: 5.1687 - yolo_layer_1_loss: 6.2123e-04 - yolo_layer_2_loss: 0.6724 - yolo_layer_3_loss: 4.4957resizing:  448 448\n"," 25/204 [==>...........................] - ETA: 1:48 - loss: 5.3040 - yolo_layer_1_loss: 7.0914e-04 - yolo_layer_2_loss: 0.4545 - yolo_layer_3_loss: 4.8488resizing:  352 352\n"," 36/204 [====>.........................] - ETA: 1:46 - loss: 5.4178 - yolo_layer_1_loss: 7.5991e-04 - yolo_layer_2_loss: 0.5874 - yolo_layer_3_loss: 4.8296resizing:  384 384\n"," 38/204 [====>.........................] - ETA: 1:44 - loss: 5.4736 - yolo_layer_1_loss: 7.5350e-04 - yolo_layer_2_loss: 0.5566 - yolo_layer_3_loss: 4.9162resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:30 - loss: 5.2497 - yolo_layer_1_loss: 6.9745e-04 - yolo_layer_2_loss: 0.4189 - yolo_layer_3_loss: 4.8302resizing:  384 384\n"," 52/204 [======>.......................] - ETA: 1:30 - loss: 5.2066 - yolo_layer_1_loss: 6.9467e-04 - yolo_layer_2_loss: 0.4133 - yolo_layer_3_loss: 4.7926resizing:  448 448\n"," 61/204 [=======>......................] - ETA: 1:26 - loss: 5.2993 - yolo_layer_1_loss: 7.0150e-04 - yolo_layer_2_loss: 0.5382 - yolo_layer_3_loss: 4.7604resizing:  352 352\n"," 76/204 [==========>...................] - ETA: 1:18 - loss: 5.1469 - yolo_layer_1_loss: 7.0068e-04 - yolo_layer_2_loss: 0.4823 - yolo_layer_3_loss: 4.6639resizing:  416 416\n"," 79/204 [==========>...................] - ETA: 1:15 - loss: 5.1151 - yolo_layer_1_loss: 6.9236e-04 - yolo_layer_2_loss: 0.4847 - yolo_layer_3_loss: 4.6298resizing:  416 416\n"," 80/204 [==========>...................] - ETA: 1:15 - loss: 5.1380 - yolo_layer_1_loss: 6.8951e-04 - yolo_layer_2_loss: 0.4932 - yolo_layer_3_loss: 4.6441resizing:  352 352\n","106/204 [==============>...............] - ETA: 57s - loss: 5.1572 - yolo_layer_1_loss: 6.4053e-04 - yolo_layer_2_loss: 0.3945 - yolo_layer_3_loss: 4.7620resizing:  448 448\n","107/204 [==============>...............] - ETA: 56s - loss: 5.1476 - yolo_layer_1_loss: 6.3906e-04 - yolo_layer_2_loss: 0.3909 - yolo_layer_3_loss: 4.7561resizing:  384 384\n","120/204 [================>.............] - ETA: 48s - loss: 5.0302 - yolo_layer_1_loss: 6.2884e-04 - yolo_layer_2_loss: 0.3536 - yolo_layer_3_loss: 4.6761resizing:  416 416\n","126/204 [=================>............] - ETA: 44s - loss: 5.0336 - yolo_layer_1_loss: 6.2299e-04 - yolo_layer_2_loss: 0.3495 - yolo_layer_3_loss: 4.6835resizing:  416 416\n","139/204 [===================>..........] - ETA: 37s - loss: 4.9399 - yolo_layer_1_loss: 6.2216e-04 - yolo_layer_2_loss: 0.3420 - yolo_layer_3_loss: 4.5973resizing:  352 352\n","140/204 [===================>..........] - ETA: 36s - loss: 4.9190 - yolo_layer_1_loss: 6.2283e-04 - yolo_layer_2_loss: 0.3396 - yolo_layer_3_loss: 4.5788resizing:  448 448\n","158/204 [======================>.......] - ETA: 26s - loss: 4.9212 - yolo_layer_1_loss: 6.2848e-04 - yolo_layer_2_loss: 0.3220 - yolo_layer_3_loss: 4.5985resizing:  448 448\n","159/204 [======================>.......] - ETA: 26s - loss: 4.9113 - yolo_layer_1_loss: 6.2878e-04 - yolo_layer_2_loss: 0.3201 - yolo_layer_3_loss: 4.5907resizing:  352 352\n","161/204 [======================>.......] - ETA: 25s - loss: 4.8896 - yolo_layer_1_loss: 6.3065e-04 - yolo_layer_2_loss: 0.3161 - yolo_layer_3_loss: 4.5728resizing:  384 384\n","167/204 [=======================>......] - ETA: 21s - loss: 4.9200 - yolo_layer_1_loss: 6.3377e-04 - yolo_layer_2_loss: 0.3756 - yolo_layer_3_loss: 4.5438resizing:  384 384\n","170/204 [========================>.....] - ETA: 20s - loss: 4.9458 - yolo_layer_1_loss: 6.3448e-04 - yolo_layer_2_loss: 0.4016 - yolo_layer_3_loss: 4.5436resizing:  352 352\n","184/204 [==========================>...] - ETA: 11s - loss: 4.9496 - yolo_layer_1_loss: 6.2461e-04 - yolo_layer_2_loss: 0.3976 - yolo_layer_3_loss: 4.5514resizing:  384 384\n","204/204 [==============================] - 119s 581ms/step - loss: 4.9626 - yolo_layer_1_loss: 6.1336e-04 - yolo_layer_2_loss: 0.3757 - yolo_layer_3_loss: 4.5863\n","\n","Epoch 00020: loss did not improve from 4.94556\n","Epoch 21/103\n","  1/204 [..............................] - ETA: 1:48 - loss: 6.3126 - yolo_layer_1_loss: 5.1027e-04 - yolo_layer_2_loss: 0.0032 - yolo_layer_3_loss: 6.3089resizing:  416 416\n"," 11/204 [>.............................] - ETA: 1:56 - loss: 4.8227 - yolo_layer_1_loss: 5.6709e-04 - yolo_layer_2_loss: 0.4125 - yolo_layer_3_loss: 4.4097resizing:  448 448\n"," 15/204 [=>............................] - ETA: 1:56 - loss: 5.0830 - yolo_layer_1_loss: 5.7769e-04 - yolo_layer_2_loss: 0.5801 - yolo_layer_3_loss: 4.5023resizing:  416 416\n"," 32/204 [===>..........................] - ETA: 1:49 - loss: 5.1868 - yolo_layer_1_loss: 6.1276e-04 - yolo_layer_2_loss: 0.5370 - yolo_layer_3_loss: 4.6493resizing:  448 448\n"," 36/204 [====>.........................] - ETA: 1:47 - loss: 4.9700 - yolo_layer_1_loss: 6.0683e-04 - yolo_layer_2_loss: 0.4777 - yolo_layer_3_loss: 4.4917resizing:  416 416\n"," 39/204 [====>.........................] - ETA: 1:45 - loss: 4.8929 - yolo_layer_1_loss: 6.0779e-04 - yolo_layer_2_loss: 0.4412 - yolo_layer_3_loss: 4.4510resizing:  416 416\n"," 52/204 [======>.......................] - ETA: 1:37 - loss: 4.6819 - yolo_layer_1_loss: 6.1360e-04 - yolo_layer_2_loss: 0.3461 - yolo_layer_3_loss: 4.3352resizing:  448 448\n"," 53/204 [======>.......................] - ETA: 1:37 - loss: 4.6604 - yolo_layer_1_loss: 6.1668e-04 - yolo_layer_2_loss: 0.3398 - yolo_layer_3_loss: 4.3200resizing:  384 384\n"," 64/204 [========>.....................] - ETA: 1:28 - loss: 4.6855 - yolo_layer_1_loss: 6.1923e-04 - yolo_layer_2_loss: 0.3047 - yolo_layer_3_loss: 4.3802resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:28 - loss: 4.7191 - yolo_layer_1_loss: 6.2052e-04 - yolo_layer_2_loss: 0.3003 - yolo_layer_3_loss: 4.4182resizing:  416 416\n"," 70/204 [=========>....................] - ETA: 1:23 - loss: 4.6689 - yolo_layer_1_loss: 6.1219e-04 - yolo_layer_2_loss: 0.2795 - yolo_layer_3_loss: 4.3888resizing:  384 384\n"," 72/204 [=========>....................] - ETA: 1:22 - loss: 4.6127 - yolo_layer_1_loss: 6.1023e-04 - yolo_layer_2_loss: 0.2718 - yolo_layer_3_loss: 4.3403resizing:  416 416\n","104/204 [==============>...............] - ETA: 1:02 - loss: 4.5422 - yolo_layer_1_loss: 6.0735e-04 - yolo_layer_2_loss: 0.2540 - yolo_layer_3_loss: 4.2876resizing:  448 448\n","105/204 [==============>...............] - ETA: 1:01 - loss: 4.5495 - yolo_layer_1_loss: 6.0646e-04 - yolo_layer_2_loss: 0.2649 - yolo_layer_3_loss: 4.2839resizing:  448 448\n","106/204 [==============>...............] - ETA: 1:01 - loss: 4.5334 - yolo_layer_1_loss: 6.0756e-04 - yolo_layer_2_loss: 0.2626 - yolo_layer_3_loss: 4.2702resizing:  352 352\n","107/204 [==============>...............] - ETA: 1:00 - loss: 4.5142 - yolo_layer_1_loss: 6.0695e-04 - yolo_layer_2_loss: 0.2602 - yolo_layer_3_loss: 4.2534resizing:  448 448\n","109/204 [===============>..............] - ETA: 59s - loss: 4.4803 - yolo_layer_1_loss: 6.0640e-04 - yolo_layer_2_loss: 0.2556 - yolo_layer_3_loss: 4.2242 resizing:  384 384\n","111/204 [===============>..............] - ETA: 58s - loss: 4.4901 - yolo_layer_1_loss: 6.0741e-04 - yolo_layer_2_loss: 0.2510 - yolo_layer_3_loss: 4.2385resizing:  416 416\n","154/204 [=====================>........] - ETA: 31s - loss: 4.5766 - yolo_layer_1_loss: 6.3770e-04 - yolo_layer_2_loss: 0.2699 - yolo_layer_3_loss: 4.3061resizing:  384 384\n","162/204 [======================>.......] - ETA: 26s - loss: 4.5401 - yolo_layer_1_loss: 6.3871e-04 - yolo_layer_2_loss: 0.2720 - yolo_layer_3_loss: 4.2674resizing:  352 352\n","168/204 [=======================>......] - ETA: 22s - loss: 4.5195 - yolo_layer_1_loss: 6.4239e-04 - yolo_layer_2_loss: 0.2624 - yolo_layer_3_loss: 4.2565resizing:  448 448\n","170/204 [========================>.....] - ETA: 21s - loss: 4.5244 - yolo_layer_1_loss: 6.4108e-04 - yolo_layer_2_loss: 0.2593 - yolo_layer_3_loss: 4.2644resizing:  448 448\n","186/204 [==========================>...] - ETA: 11s - loss: 4.5883 - yolo_layer_1_loss: 6.5445e-04 - yolo_layer_2_loss: 0.2713 - yolo_layer_3_loss: 4.3164resizing:  384 384\n","192/204 [===========================>..] - ETA: 7s - loss: 4.6179 - yolo_layer_1_loss: 6.6241e-04 - yolo_layer_2_loss: 0.2979 - yolo_layer_3_loss: 4.3193resizing:  384 384\n","204/204 [==============================] - 127s 623ms/step - loss: 4.5582 - yolo_layer_1_loss: 6.6025e-04 - yolo_layer_2_loss: 0.3014 - yolo_layer_3_loss: 4.2561\n","\n","Epoch 00021: loss improved from 4.94556 to 4.55819, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 22/103\n","  4/204 [..............................] - ETA: 1:51 - loss: 5.2528 - yolo_layer_1_loss: 4.9069e-04 - yolo_layer_2_loss: 0.6416 - yolo_layer_3_loss: 4.6107resizing:  384 384\n","  7/204 [>.............................] - ETA: 1:49 - loss: 5.3157 - yolo_layer_1_loss: 4.8194e-04 - yolo_layer_2_loss: 0.3678 - yolo_layer_3_loss: 4.9474resizing:  416 416\n"," 18/204 [=>............................] - ETA: 1:42 - loss: 5.6327 - yolo_layer_1_loss: 4.7269e-04 - yolo_layer_2_loss: 0.4154 - yolo_layer_3_loss: 5.2169resizing:  448 448\n"," 25/204 [==>...........................] - ETA: 1:43 - loss: 5.4887 - yolo_layer_1_loss: 5.3721e-04 - yolo_layer_2_loss: 0.3933 - yolo_layer_3_loss: 5.0949resizing:  416 416\n"," 27/204 [==>...........................] - ETA: 1:43 - loss: 5.3300 - yolo_layer_1_loss: 5.3628e-04 - yolo_layer_2_loss: 0.3772 - yolo_layer_3_loss: 4.9523resizing:  416 416\n"," 32/204 [===>..........................] - ETA: 1:42 - loss: 5.3052 - yolo_layer_1_loss: 5.5756e-04 - yolo_layer_2_loss: 0.4182 - yolo_layer_3_loss: 4.8864resizing:  448 448\n"," 56/204 [=======>......................] - ETA: 1:33 - loss: 4.7134 - yolo_layer_1_loss: 6.1530e-04 - yolo_layer_2_loss: 0.3892 - yolo_layer_3_loss: 4.3236resizing:  384 384\n"," 63/204 [========>.....................] - ETA: 1:30 - loss: 4.6675 - yolo_layer_1_loss: 6.2270e-04 - yolo_layer_2_loss: 0.3919 - yolo_layer_3_loss: 4.2750resizing:  352 352\n"," 65/204 [========>.....................] - ETA: 1:29 - loss: 4.6967 - yolo_layer_1_loss: 6.2233e-04 - yolo_layer_2_loss: 0.3799 - yolo_layer_3_loss: 4.3162resizing:  352 352\n"," 72/204 [=========>....................] - ETA: 1:23 - loss: 4.7157 - yolo_layer_1_loss: 6.1400e-04 - yolo_layer_2_loss: 0.3432 - yolo_layer_3_loss: 4.3719resizing:  416 416\n"," 83/204 [===========>..................] - ETA: 1:14 - loss: 4.7104 - yolo_layer_1_loss: 5.9402e-04 - yolo_layer_2_loss: 0.3630 - yolo_layer_3_loss: 4.3468resizing:  448 448\n"," 90/204 [============>.................] - ETA: 1:10 - loss: 4.7091 - yolo_layer_1_loss: 5.9008e-04 - yolo_layer_2_loss: 0.3811 - yolo_layer_3_loss: 4.3275resizing:  448 448\n","103/204 [==============>...............] - ETA: 1:03 - loss: 4.8954 - yolo_layer_1_loss: 5.9679e-04 - yolo_layer_2_loss: 0.4413 - yolo_layer_3_loss: 4.4535resizing:  448 448\n","110/204 [===============>..............] - ETA: 59s - loss: 4.8503 - yolo_layer_1_loss: 6.0194e-04 - yolo_layer_2_loss: 0.4516 - yolo_layer_3_loss: 4.3981resizing:  352 352\n","117/204 [================>.............] - ETA: 55s - loss: 4.8715 - yolo_layer_1_loss: 6.0524e-04 - yolo_layer_2_loss: 0.4833 - yolo_layer_3_loss: 4.3876resizing:  352 352\n","120/204 [================>.............] - ETA: 53s - loss: 4.8480 - yolo_layer_1_loss: 6.0716e-04 - yolo_layer_2_loss: 0.4715 - yolo_layer_3_loss: 4.3758resizing:  416 416\n","127/204 [=================>............] - ETA: 48s - loss: 4.8451 - yolo_layer_1_loss: 5.9945e-04 - yolo_layer_2_loss: 0.4931 - yolo_layer_3_loss: 4.3514resizing:  416 416\n","129/204 [=================>............] - ETA: 47s - loss: 4.8861 - yolo_layer_1_loss: 5.9620e-04 - yolo_layer_2_loss: 0.5181 - yolo_layer_3_loss: 4.3674resizing:  384 384\n","154/204 [=====================>........] - ETA: 30s - loss: 4.8523 - yolo_layer_1_loss: 5.7783e-04 - yolo_layer_2_loss: 0.4621 - yolo_layer_3_loss: 4.3897resizing:  416 416\n","156/204 [=====================>........] - ETA: 29s - loss: 4.8521 - yolo_layer_1_loss: 5.7625e-04 - yolo_layer_2_loss: 0.4562 - yolo_layer_3_loss: 4.3953resizing:  416 416\n","159/204 [======================>.......] - ETA: 27s - loss: 4.8558 - yolo_layer_1_loss: 5.7405e-04 - yolo_layer_2_loss: 0.4492 - yolo_layer_3_loss: 4.4060resizing:  448 448\n","174/204 [========================>.....] - ETA: 18s - loss: 4.7855 - yolo_layer_1_loss: 5.7907e-04 - yolo_layer_2_loss: 0.4528 - yolo_layer_3_loss: 4.3321resizing:  416 416\n","177/204 [=========================>....] - ETA: 16s - loss: 4.7749 - yolo_layer_1_loss: 5.8060e-04 - yolo_layer_2_loss: 0.4535 - yolo_layer_3_loss: 4.3208resizing:  352 352\n","185/204 [==========================>...] - ETA: 11s - loss: 4.7389 - yolo_layer_1_loss: 5.8316e-04 - yolo_layer_2_loss: 0.4509 - yolo_layer_3_loss: 4.2875resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 4.7413 - yolo_layer_1_loss: 5.7623e-04 - yolo_layer_2_loss: 0.4519 - yolo_layer_3_loss: 4.2888resizing:  416 416\n","204/204 [==============================] - 127s 621ms/step - loss: 4.7381 - yolo_layer_1_loss: 5.7561e-04 - yolo_layer_2_loss: 0.4502 - yolo_layer_3_loss: 4.2873\n","\n","Epoch 00022: loss did not improve from 4.55819\n","Epoch 23/103\n"," 14/204 [=>............................] - ETA: 2:02 - loss: 4.5377 - yolo_layer_1_loss: 5.1874e-04 - yolo_layer_2_loss: 0.2788 - yolo_layer_3_loss: 4.2584resizing:  416 416\n"," 22/204 [==>...........................] - ETA: 1:57 - loss: 4.4872 - yolo_layer_1_loss: 5.1069e-04 - yolo_layer_2_loss: 0.2037 - yolo_layer_3_loss: 4.2830resizing:  352 352\n"," 24/204 [==>...........................] - ETA: 1:56 - loss: 4.4394 - yolo_layer_1_loss: 5.0500e-04 - yolo_layer_2_loss: 0.1877 - yolo_layer_3_loss: 4.2512resizing:  384 384\n"," 26/204 [==>...........................] - ETA: 1:54 - loss: 4.4451 - yolo_layer_1_loss: 5.0056e-04 - yolo_layer_2_loss: 0.3074 - yolo_layer_3_loss: 4.1372resizing:  352 352\n"," 36/204 [====>.........................] - ETA: 1:46 - loss: 4.3695 - yolo_layer_1_loss: 4.9420e-04 - yolo_layer_2_loss: 0.2241 - yolo_layer_3_loss: 4.1450resizing:  352 352\n"," 53/204 [======>.......................] - ETA: 1:28 - loss: 4.4706 - yolo_layer_1_loss: 4.6628e-04 - yolo_layer_2_loss: 0.2598 - yolo_layer_3_loss: 4.2103resizing:  352 352\n"," 59/204 [=======>......................] - ETA: 1:23 - loss: 4.5872 - yolo_layer_1_loss: 4.5790e-04 - yolo_layer_2_loss: 0.2339 - yolo_layer_3_loss: 4.3529resizing:  448 448\n"," 60/204 [=======>......................] - ETA: 1:23 - loss: 4.5736 - yolo_layer_1_loss: 4.5630e-04 - yolo_layer_2_loss: 0.2442 - yolo_layer_3_loss: 4.3289resizing:  416 416\n"," 74/204 [=========>....................] - ETA: 1:14 - loss: 4.4730 - yolo_layer_1_loss: 4.5388e-04 - yolo_layer_2_loss: 0.2234 - yolo_layer_3_loss: 4.2491resizing:  384 384\n"," 86/204 [===========>..................] - ETA: 1:08 - loss: 4.5737 - yolo_layer_1_loss: 4.5872e-04 - yolo_layer_2_loss: 0.2737 - yolo_layer_3_loss: 4.2995resizing:  352 352\n"," 90/204 [============>.................] - ETA: 1:06 - loss: 4.5649 - yolo_layer_1_loss: 4.5728e-04 - yolo_layer_2_loss: 0.2662 - yolo_layer_3_loss: 4.2982resizing:  448 448\n","104/204 [==============>...............] - ETA: 57s - loss: 4.5870 - yolo_layer_1_loss: 4.5810e-04 - yolo_layer_2_loss: 0.2309 - yolo_layer_3_loss: 4.3557resizing:  416 416\n","108/204 [==============>...............] - ETA: 55s - loss: 4.6188 - yolo_layer_1_loss: 4.6505e-04 - yolo_layer_2_loss: 0.2746 - yolo_layer_3_loss: 4.3437resizing:  352 352\n","113/204 [===============>..............] - ETA: 53s - loss: 4.6303 - yolo_layer_1_loss: 4.6982e-04 - yolo_layer_2_loss: 0.2626 - yolo_layer_3_loss: 4.3673resizing:  352 352\n","115/204 [===============>..............] - ETA: 52s - loss: 4.6388 - yolo_layer_1_loss: 4.7008e-04 - yolo_layer_2_loss: 0.2745 - yolo_layer_3_loss: 4.3638resizing:  416 416\n","131/204 [==================>...........] - ETA: 42s - loss: 4.6137 - yolo_layer_1_loss: 4.7128e-04 - yolo_layer_2_loss: 0.2820 - yolo_layer_3_loss: 4.3312resizing:  448 448\n","132/204 [==================>...........] - ETA: 42s - loss: 4.6013 - yolo_layer_1_loss: 4.7131e-04 - yolo_layer_2_loss: 0.2799 - yolo_layer_3_loss: 4.3210resizing:  352 352\n","155/204 [=====================>........] - ETA: 28s - loss: 4.6088 - yolo_layer_1_loss: 4.6967e-04 - yolo_layer_2_loss: 0.2797 - yolo_layer_3_loss: 4.3286resizing:  416 416\n","157/204 [======================>.......] - ETA: 27s - loss: 4.6082 - yolo_layer_1_loss: 4.6832e-04 - yolo_layer_2_loss: 0.2762 - yolo_layer_3_loss: 4.3315resizing:  384 384\n","160/204 [======================>.......] - ETA: 25s - loss: 4.5660 - yolo_layer_1_loss: 4.6801e-04 - yolo_layer_2_loss: 0.2773 - yolo_layer_3_loss: 4.2882resizing:  352 352\n","171/204 [========================>.....] - ETA: 19s - loss: 4.5402 - yolo_layer_1_loss: 4.6658e-04 - yolo_layer_2_loss: 0.2666 - yolo_layer_3_loss: 4.2731resizing:  352 352\n","182/204 [=========================>....] - ETA: 12s - loss: 4.5554 - yolo_layer_1_loss: 4.6215e-04 - yolo_layer_2_loss: 0.2653 - yolo_layer_3_loss: 4.2896resizing:  352 352\n","184/204 [==========================>...] - ETA: 11s - loss: 4.5614 - yolo_layer_1_loss: 4.6190e-04 - yolo_layer_2_loss: 0.2624 - yolo_layer_3_loss: 4.2985resizing:  448 448\n","204/204 [==============================] - 117s 574ms/step - loss: 4.5669 - yolo_layer_1_loss: 4.6579e-04 - yolo_layer_2_loss: 0.2395 - yolo_layer_3_loss: 4.3270\n","\n","Epoch 00023: loss did not improve from 4.55819\n","Epoch 24/103\n"," 13/204 [>.............................] - ETA: 2:14 - loss: 5.9901 - yolo_layer_1_loss: 6.1574e-04 - yolo_layer_2_loss: 1.0606 - yolo_layer_3_loss: 4.9289resizing:  448 448\n"," 17/204 [=>............................] - ETA: 2:11 - loss: 5.3895 - yolo_layer_1_loss: 6.0328e-04 - yolo_layer_2_loss: 0.8139 - yolo_layer_3_loss: 4.5750resizing:  384 384\n"," 18/204 [=>............................] - ETA: 2:10 - loss: 5.2684 - yolo_layer_1_loss: 6.0454e-04 - yolo_layer_2_loss: 0.7709 - yolo_layer_3_loss: 4.4969resizing:  352 352\n"," 22/204 [==>...........................] - ETA: 2:07 - loss: 4.9461 - yolo_layer_1_loss: 5.9661e-04 - yolo_layer_2_loss: 0.6313 - yolo_layer_3_loss: 4.3143resizing:  416 416\n"," 28/204 [===>..........................] - ETA: 2:03 - loss: 4.8815 - yolo_layer_1_loss: 5.9346e-04 - yolo_layer_2_loss: 0.5925 - yolo_layer_3_loss: 4.2883resizing:  416 416\n"," 35/204 [====>.........................] - ETA: 1:53 - loss: 4.7700 - yolo_layer_1_loss: 5.5812e-04 - yolo_layer_2_loss: 0.4873 - yolo_layer_3_loss: 4.2821resizing:  416 416\n"," 52/204 [======>.......................] - ETA: 1:40 - loss: 4.7481 - yolo_layer_1_loss: 5.3167e-04 - yolo_layer_2_loss: 0.4606 - yolo_layer_3_loss: 4.2870resizing:  352 352\n"," 72/204 [=========>....................] - ETA: 1:22 - loss: 4.8108 - yolo_layer_1_loss: 5.0288e-04 - yolo_layer_2_loss: 0.3490 - yolo_layer_3_loss: 4.4613resizing:  416 416\n"," 77/204 [==========>...................] - ETA: 1:17 - loss: 4.8140 - yolo_layer_1_loss: 4.9383e-04 - yolo_layer_2_loss: 0.3264 - yolo_layer_3_loss: 4.4871resizing:  416 416\n"," 78/204 [==========>...................] - ETA: 1:17 - loss: 4.8297 - yolo_layer_1_loss: 4.9228e-04 - yolo_layer_2_loss: 0.3223 - yolo_layer_3_loss: 4.5069resizing:  416 416\n"," 79/204 [==========>...................] - ETA: 1:16 - loss: 4.8176 - yolo_layer_1_loss: 4.9141e-04 - yolo_layer_2_loss: 0.3182 - yolo_layer_3_loss: 4.4989resizing:  384 384\n"," 83/204 [===========>..................] - ETA: 1:13 - loss: 4.8554 - yolo_layer_1_loss: 4.8614e-04 - yolo_layer_2_loss: 0.3030 - yolo_layer_3_loss: 4.5519resizing:  384 384\n","104/204 [==============>...............] - ETA: 59s - loss: 4.7625 - yolo_layer_1_loss: 4.8101e-04 - yolo_layer_2_loss: 0.2665 - yolo_layer_3_loss: 4.4954 resizing:  352 352\n","105/204 [==============>...............] - ETA: 59s - loss: 4.7729 - yolo_layer_1_loss: 4.8011e-04 - yolo_layer_2_loss: 0.2640 - yolo_layer_3_loss: 4.5084resizing:  352 352\n","107/204 [==============>...............] - ETA: 57s - loss: 4.7641 - yolo_layer_1_loss: 4.7854e-04 - yolo_layer_2_loss: 0.2780 - yolo_layer_3_loss: 4.4856resizing:  384 384\n","137/204 [===================>..........] - ETA: 39s - loss: 4.7161 - yolo_layer_1_loss: 4.6157e-04 - yolo_layer_2_loss: 0.2494 - yolo_layer_3_loss: 4.4662resizing:  352 352\n","138/204 [===================>..........] - ETA: 38s - loss: 4.7039 - yolo_layer_1_loss: 4.6137e-04 - yolo_layer_2_loss: 0.2476 - yolo_layer_3_loss: 4.4558resizing:  352 352\n","139/204 [===================>..........] - ETA: 37s - loss: 4.7006 - yolo_layer_1_loss: 4.6102e-04 - yolo_layer_2_loss: 0.2459 - yolo_layer_3_loss: 4.4543resizing:  384 384\n","152/204 [=====================>........] - ETA: 30s - loss: 4.6786 - yolo_layer_1_loss: 4.5597e-04 - yolo_layer_2_loss: 0.2276 - yolo_layer_3_loss: 4.4506resizing:  416 416\n","161/204 [======================>.......] - ETA: 24s - loss: 4.6463 - yolo_layer_1_loss: 4.5584e-04 - yolo_layer_2_loss: 0.2498 - yolo_layer_3_loss: 4.3960resizing:  352 352\n","166/204 [=======================>......] - ETA: 22s - loss: 4.6211 - yolo_layer_1_loss: 4.5589e-04 - yolo_layer_2_loss: 0.2431 - yolo_layer_3_loss: 4.3775resizing:  416 416\n","171/204 [========================>.....] - ETA: 19s - loss: 4.6039 - yolo_layer_1_loss: 4.5511e-04 - yolo_layer_2_loss: 0.2361 - yolo_layer_3_loss: 4.3674resizing:  416 416\n","189/204 [==========================>...] - ETA: 8s - loss: 4.5465 - yolo_layer_1_loss: 4.5356e-04 - yolo_layer_2_loss: 0.2431 - yolo_layer_3_loss: 4.3030resizing:  384 384\n","191/204 [===========================>..] - ETA: 7s - loss: 4.5441 - yolo_layer_1_loss: 4.5332e-04 - yolo_layer_2_loss: 0.2405 - yolo_layer_3_loss: 4.3031resizing:  416 416\n","204/204 [==============================] - 120s 590ms/step - loss: 4.4803 - yolo_layer_1_loss: 4.5214e-04 - yolo_layer_2_loss: 0.2336 - yolo_layer_3_loss: 4.2463\n","\n","Epoch 00024: loss improved from 4.55819 to 4.48032, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 25/103\n","  4/204 [..............................] - ETA: 2:13 - loss: 3.7038 - yolo_layer_1_loss: 4.7568e-04 - yolo_layer_2_loss: 0.0025 - yolo_layer_3_loss: 3.7009resizing:  384 384\n"," 10/204 [>.............................] - ETA: 2:07 - loss: 3.8098 - yolo_layer_1_loss: 4.8245e-04 - yolo_layer_2_loss: 0.5805 - yolo_layer_3_loss: 3.2289resizing:  416 416\n"," 11/204 [>.............................] - ETA: 2:06 - loss: 3.8934 - yolo_layer_1_loss: 4.7282e-04 - yolo_layer_2_loss: 0.5279 - yolo_layer_3_loss: 3.3651resizing:  416 416\n"," 23/204 [==>...........................] - ETA: 1:53 - loss: 4.4666 - yolo_layer_1_loss: 4.3356e-04 - yolo_layer_2_loss: 0.2546 - yolo_layer_3_loss: 4.2115resizing:  448 448\n"," 24/204 [==>...........................] - ETA: 1:53 - loss: 4.5000 - yolo_layer_1_loss: 4.3416e-04 - yolo_layer_2_loss: 0.3380 - yolo_layer_3_loss: 4.1616resizing:  416 416\n"," 36/204 [====>.........................] - ETA: 1:47 - loss: 4.3526 - yolo_layer_1_loss: 4.3320e-04 - yolo_layer_2_loss: 0.2906 - yolo_layer_3_loss: 4.0616resizing:  384 384\n"," 60/204 [=======>......................] - ETA: 1:28 - loss: 4.4328 - yolo_layer_1_loss: 4.2174e-04 - yolo_layer_2_loss: 0.3533 - yolo_layer_3_loss: 4.0791resizing:  384 384\n"," 69/204 [=========>....................] - ETA: 1:22 - loss: 4.4805 - yolo_layer_1_loss: 4.1816e-04 - yolo_layer_2_loss: 0.3468 - yolo_layer_3_loss: 4.1333resizing:  384 384\n"," 73/204 [=========>....................] - ETA: 1:19 - loss: 4.4219 - yolo_layer_1_loss: 4.1534e-04 - yolo_layer_2_loss: 0.3280 - yolo_layer_3_loss: 4.0935resizing:  448 448\n"," 76/204 [==========>...................] - ETA: 1:17 - loss: 4.4376 - yolo_layer_1_loss: 4.1371e-04 - yolo_layer_2_loss: 0.3152 - yolo_layer_3_loss: 4.1219resizing:  352 352\n"," 77/204 [==========>...................] - ETA: 1:16 - loss: 4.4491 - yolo_layer_1_loss: 4.1446e-04 - yolo_layer_2_loss: 0.3112 - yolo_layer_3_loss: 4.1375resizing:  352 352\n"," 86/204 [===========>..................] - ETA: 1:10 - loss: 4.4282 - yolo_layer_1_loss: 4.1715e-04 - yolo_layer_2_loss: 0.3327 - yolo_layer_3_loss: 4.0951resizing:  448 448\n","102/204 [==============>...............] - ETA: 1:00 - loss: 4.4353 - yolo_layer_1_loss: 4.2067e-04 - yolo_layer_2_loss: 0.3575 - yolo_layer_3_loss: 4.0773resizing:  352 352\n","111/204 [===============>..............] - ETA: 54s - loss: 4.4306 - yolo_layer_1_loss: 4.1949e-04 - yolo_layer_2_loss: 0.3501 - yolo_layer_3_loss: 4.0801resizing:  448 448\n","118/204 [================>.............] - ETA: 50s - loss: 4.5382 - yolo_layer_1_loss: 4.1444e-04 - yolo_layer_2_loss: 0.3307 - yolo_layer_3_loss: 4.2070resizing:  384 384\n","130/204 [==================>...........] - ETA: 43s - loss: 4.5785 - yolo_layer_1_loss: 4.1894e-04 - yolo_layer_2_loss: 0.3570 - yolo_layer_3_loss: 4.2211resizing:  448 448\n","137/204 [===================>..........] - ETA: 39s - loss: 4.6096 - yolo_layer_1_loss: 4.1790e-04 - yolo_layer_2_loss: 0.3391 - yolo_layer_3_loss: 4.2701resizing:  352 352\n","140/204 [===================>..........] - ETA: 37s - loss: 4.6117 - yolo_layer_1_loss: 4.1670e-04 - yolo_layer_2_loss: 0.3319 - yolo_layer_3_loss: 4.2794resizing:  384 384\n","158/204 [======================>.......] - ETA: 26s - loss: 4.6481 - yolo_layer_1_loss: 4.2502e-04 - yolo_layer_2_loss: 0.3636 - yolo_layer_3_loss: 4.2840resizing:  352 352\n","resizing:  448 448\n","165/204 [=======================>......] - ETA: 22s - loss: 4.6638 - yolo_layer_1_loss: 4.2411e-04 - yolo_layer_2_loss: 0.3483 - yolo_layer_3_loss: 4.3151resizing:  416 416\n","166/204 [=======================>......] - ETA: 22s - loss: 4.6656 - yolo_layer_1_loss: 4.2354e-04 - yolo_layer_2_loss: 0.3462 - yolo_layer_3_loss: 4.3190resizing:  448 448\n","167/204 [=======================>......] - ETA: 21s - loss: 4.6492 - yolo_layer_1_loss: 4.2437e-04 - yolo_layer_2_loss: 0.3442 - yolo_layer_3_loss: 4.3046resizing:  448 448\n","178/204 [=========================>....] - ETA: 15s - loss: 4.5973 - yolo_layer_1_loss: 4.3222e-04 - yolo_layer_2_loss: 0.3308 - yolo_layer_3_loss: 4.2660resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 4.5824 - yolo_layer_1_loss: 4.3680e-04 - yolo_layer_2_loss: 0.3733 - yolo_layer_3_loss: 4.2087resizing:  416 416\n","204/204 [==============================] - 121s 593ms/step - loss: 4.5727 - yolo_layer_1_loss: 4.3647e-04 - yolo_layer_2_loss: 0.3715 - yolo_layer_3_loss: 4.2008\n","\n","Epoch 00025: loss did not improve from 4.48032\n","Epoch 26/103\n","resizing:  448 448\n","resizing:  352 352\n","  2/204 [..............................] - ETA: 2:10 - loss: 3.1879 - yolo_layer_1_loss: 4.5081e-04 - yolo_layer_2_loss: 0.0035 - yolo_layer_3_loss: 3.1839resizing:  352 352\n","  3/204 [..............................] - ETA: 2:13 - loss: 3.0030 - yolo_layer_1_loss: 4.9588e-04 - yolo_layer_2_loss: 0.0032 - yolo_layer_3_loss: 2.9993resizing:  448 448\n"," 38/204 [====>.........................] - ETA: 1:50 - loss: 4.1041 - yolo_layer_1_loss: 5.2002e-04 - yolo_layer_2_loss: 0.5645 - yolo_layer_3_loss: 3.5391resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:41 - loss: 3.9751 - yolo_layer_1_loss: 5.1122e-04 - yolo_layer_2_loss: 0.5062 - yolo_layer_3_loss: 3.4684resizing:  416 416\n","resizing:  448 448\n"," 58/204 [=======>......................] - ETA: 1:36 - loss: 4.0989 - yolo_layer_1_loss: 5.0511e-04 - yolo_layer_2_loss: 0.5513 - yolo_layer_3_loss: 3.5471resizing:  352 352\n"," 62/204 [========>.....................] - ETA: 1:34 - loss: 4.0870 - yolo_layer_1_loss: 5.0171e-04 - yolo_layer_2_loss: 0.5353 - yolo_layer_3_loss: 3.5513resizing:  416 416\n"," 69/204 [=========>....................] - ETA: 1:30 - loss: 4.0350 - yolo_layer_1_loss: 5.0059e-04 - yolo_layer_2_loss: 0.4814 - yolo_layer_3_loss: 3.5531resizing:  448 448\n"," 73/204 [=========>....................] - ETA: 1:26 - loss: 4.0164 - yolo_layer_1_loss: 4.9121e-04 - yolo_layer_2_loss: 0.4552 - yolo_layer_3_loss: 3.5608resizing:  448 448\n","112/204 [===============>..............] - ETA: 1:01 - loss: 4.2926 - yolo_layer_1_loss: 4.9882e-04 - yolo_layer_2_loss: 0.5709 - yolo_layer_3_loss: 3.7212resizing:  416 416\n","122/204 [================>.............] - ETA: 55s - loss: 4.3629 - yolo_layer_1_loss: 5.0027e-04 - yolo_layer_2_loss: 0.5971 - yolo_layer_3_loss: 3.7653resizing:  416 416\n","126/204 [=================>............] - ETA: 52s - loss: 4.3570 - yolo_layer_1_loss: 4.9913e-04 - yolo_layer_2_loss: 0.5899 - yolo_layer_3_loss: 3.7666resizing:  384 384\n","134/204 [==================>...........] - ETA: 47s - loss: 4.3906 - yolo_layer_1_loss: 4.9137e-04 - yolo_layer_2_loss: 0.5843 - yolo_layer_3_loss: 3.8058resizing:  448 448\n","139/204 [===================>..........] - ETA: 43s - loss: 4.3995 - yolo_layer_1_loss: 4.8692e-04 - yolo_layer_2_loss: 0.5765 - yolo_layer_3_loss: 3.8225resizing:  384 384\n","141/204 [===================>..........] - ETA: 42s - loss: 4.4062 - yolo_layer_1_loss: 4.8454e-04 - yolo_layer_2_loss: 0.5684 - yolo_layer_3_loss: 3.8373resizing:  384 384\n","152/204 [=====================>........] - ETA: 34s - loss: 4.4027 - yolo_layer_1_loss: 4.7912e-04 - yolo_layer_2_loss: 0.5733 - yolo_layer_3_loss: 3.8290resizing:  416 416\n","155/204 [=====================>........] - ETA: 32s - loss: 4.4305 - yolo_layer_1_loss: 4.7872e-04 - yolo_layer_2_loss: 0.5622 - yolo_layer_3_loss: 3.8679resizing:  448 448\n","157/204 [======================>.......] - ETA: 31s - loss: 4.4720 - yolo_layer_1_loss: 4.7765e-04 - yolo_layer_2_loss: 0.5551 - yolo_layer_3_loss: 3.9165resizing:  448 448\n","165/204 [=======================>......] - ETA: 25s - loss: 4.4892 - yolo_layer_1_loss: 4.7791e-04 - yolo_layer_2_loss: 0.5569 - yolo_layer_3_loss: 3.9319resizing:  448 448\n","179/204 [=========================>....] - ETA: 16s - loss: 4.4953 - yolo_layer_1_loss: 4.7304e-04 - yolo_layer_2_loss: 0.5935 - yolo_layer_3_loss: 3.9014resizing:  416 416\n","188/204 [==========================>...] - ETA: 10s - loss: 4.4648 - yolo_layer_1_loss: 4.7186e-04 - yolo_layer_2_loss: 0.5732 - yolo_layer_3_loss: 3.8911resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 4.4504 - yolo_layer_1_loss: 4.6319e-04 - yolo_layer_2_loss: 0.5479 - yolo_layer_3_loss: 3.9020resizing:  416 416\n","204/204 [==============================] - 136s 664ms/step - loss: 4.4490 - yolo_layer_1_loss: 4.6224e-04 - yolo_layer_2_loss: 0.5452 - yolo_layer_3_loss: 3.9033\n","\n","Epoch 00026: loss improved from 4.48032 to 4.44900, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 27/103\n"," 13/204 [>.............................] - ETA: 2:04 - loss: 4.1690 - yolo_layer_1_loss: 3.5974e-04 - yolo_layer_2_loss: 0.5448 - yolo_layer_3_loss: 3.6238resizing:  384 384\n"," 15/204 [=>............................] - ETA: 2:03 - loss: 4.0263 - yolo_layer_1_loss: 3.6664e-04 - yolo_layer_2_loss: 0.4724 - yolo_layer_3_loss: 3.5535resizing:  448 448\n"," 19/204 [=>............................] - ETA: 2:00 - loss: 4.2707 - yolo_layer_1_loss: 3.6594e-04 - yolo_layer_2_loss: 0.5412 - yolo_layer_3_loss: 3.7291resizing:  352 352\n"," 20/204 [=>............................] - ETA: 1:59 - loss: 4.3521 - yolo_layer_1_loss: 3.6855e-04 - yolo_layer_2_loss: 0.5143 - yolo_layer_3_loss: 3.8375resizing:  352 352\n"," 34/204 [====>.........................] - ETA: 1:47 - loss: 4.2395 - yolo_layer_1_loss: 3.8777e-04 - yolo_layer_2_loss: 0.3497 - yolo_layer_3_loss: 3.8894resizing:  352 352\n"," 51/204 [======>.......................] - ETA: 1:29 - loss: 4.4930 - yolo_layer_1_loss: 3.6877e-04 - yolo_layer_2_loss: 0.3595 - yolo_layer_3_loss: 4.1331resizing:  352 352\n"," 52/204 [======>.......................] - ETA: 1:28 - loss: 4.4679 - yolo_layer_1_loss: 3.6767e-04 - yolo_layer_2_loss: 0.3526 - yolo_layer_3_loss: 4.1149resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:26 - loss: 4.4185 - yolo_layer_1_loss: 3.6528e-04 - yolo_layer_2_loss: 0.3396 - yolo_layer_3_loss: 4.0785resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:25 - loss: 4.4967 - yolo_layer_1_loss: 3.6270e-04 - yolo_layer_2_loss: 0.3276 - yolo_layer_3_loss: 4.1688resizing:  352 352\n"," 71/204 [=========>....................] - ETA: 1:15 - loss: 4.5368 - yolo_layer_1_loss: 3.6382e-04 - yolo_layer_2_loss: 0.3810 - yolo_layer_3_loss: 4.1554resizing:  384 384\n"," 73/204 [=========>....................] - ETA: 1:14 - loss: 4.5087 - yolo_layer_1_loss: 3.6164e-04 - yolo_layer_2_loss: 0.3707 - yolo_layer_3_loss: 4.1377resizing:  416 416\n","105/204 [==============>...............] - ETA: 56s - loss: 4.5970 - yolo_layer_1_loss: 3.6231e-04 - yolo_layer_2_loss: 0.4196 - yolo_layer_3_loss: 4.1771resizing:  384 384\n","108/204 [==============>...............] - ETA: 55s - loss: 4.5890 - yolo_layer_1_loss: 3.6212e-04 - yolo_layer_2_loss: 0.4300 - yolo_layer_3_loss: 4.1586resizing:  416 416\n","115/204 [===============>..............] - ETA: 51s - loss: 4.6294 - yolo_layer_1_loss: 3.6184e-04 - yolo_layer_2_loss: 0.4194 - yolo_layer_3_loss: 4.2096resizing:  384 384\n","121/204 [================>.............] - ETA: 48s - loss: 4.5856 - yolo_layer_1_loss: 3.6147e-04 - yolo_layer_2_loss: 0.4083 - yolo_layer_3_loss: 4.1769resizing:  448 448\n","123/204 [=================>............] - ETA: 47s - loss: 4.5557 - yolo_layer_1_loss: 3.6116e-04 - yolo_layer_2_loss: 0.4017 - yolo_layer_3_loss: 4.1536resizing:  384 384\n","137/204 [===================>..........] - ETA: 38s - loss: 4.5752 - yolo_layer_1_loss: 3.6237e-04 - yolo_layer_2_loss: 0.3910 - yolo_layer_3_loss: 4.1839resizing:  352 352\n","152/204 [=====================>........] - ETA: 29s - loss: 4.5029 - yolo_layer_1_loss: 3.5865e-04 - yolo_layer_2_loss: 0.3558 - yolo_layer_3_loss: 4.1468resizing:  448 448\n","155/204 [=====================>........] - ETA: 28s - loss: 4.4746 - yolo_layer_1_loss: 3.5979e-04 - yolo_layer_2_loss: 0.3497 - yolo_layer_3_loss: 4.1245resizing:  384 384\n","resizing:  416 416\n","157/204 [======================>.......] - ETA: 27s - loss: 4.4814 - yolo_layer_1_loss: 3.6089e-04 - yolo_layer_2_loss: 0.3806 - yolo_layer_3_loss: 4.1004resizing:  384 384\n","169/204 [=======================>......] - ETA: 20s - loss: 4.4681 - yolo_layer_1_loss: 3.6231e-04 - yolo_layer_2_loss: 0.3665 - yolo_layer_3_loss: 4.1012resizing:  352 352\n","171/204 [========================>.....] - ETA: 19s - loss: 4.4455 - yolo_layer_1_loss: 3.6225e-04 - yolo_layer_2_loss: 0.3623 - yolo_layer_3_loss: 4.0829resizing:  384 384\n","204/204 [==============================] - 117s 573ms/step - loss: 4.4695 - yolo_layer_1_loss: 3.5262e-04 - yolo_layer_2_loss: 0.3430 - yolo_layer_3_loss: 4.1262\n","\n","Epoch 00027: loss did not improve from 4.44900\n","Epoch 28/103\n","  1/204 [..............................] - ETA: 1:47 - loss: 3.3701 - yolo_layer_1_loss: 3.3682e-04 - yolo_layer_2_loss: 0.0016 - yolo_layer_3_loss: 3.3682resizing:  352 352\n","  5/204 [..............................] - ETA: 1:48 - loss: 4.3653 - yolo_layer_1_loss: 3.6483e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 4.3635resizing:  384 384\n","  8/204 [>.............................] - ETA: 1:44 - loss: 3.9908 - yolo_layer_1_loss: 3.3717e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 3.9890resizing:  352 352\n"," 10/204 [>.............................] - ETA: 1:41 - loss: 3.9453 - yolo_layer_1_loss: 3.2250e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 3.9436resizing:  448 448\n"," 21/204 [==>...........................] - ETA: 1:35 - loss: 4.4153 - yolo_layer_1_loss: 3.1474e-04 - yolo_layer_2_loss: 0.2655 - yolo_layer_3_loss: 4.1495resizing:  448 448\n"," 22/204 [==>...........................] - ETA: 1:36 - loss: 4.3458 - yolo_layer_1_loss: 3.1739e-04 - yolo_layer_2_loss: 0.2535 - yolo_layer_3_loss: 4.0920resizing:  352 352\n"," 60/204 [=======>......................] - ETA: 1:18 - loss: 4.6099 - yolo_layer_1_loss: 3.3839e-04 - yolo_layer_2_loss: 0.3875 - yolo_layer_3_loss: 4.2220resizing:  352 352\n"," 61/204 [=======>......................] - ETA: 1:17 - loss: 4.5970 - yolo_layer_1_loss: 3.3861e-04 - yolo_layer_2_loss: 0.3812 - yolo_layer_3_loss: 4.2155resizing:  384 384\n"," 63/204 [========>.....................] - ETA: 1:16 - loss: 4.5254 - yolo_layer_1_loss: 3.3955e-04 - yolo_layer_2_loss: 0.3693 - yolo_layer_3_loss: 4.1558resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:15 - loss: 4.5391 - yolo_layer_1_loss: 3.3796e-04 - yolo_layer_2_loss: 0.3580 - yolo_layer_3_loss: 4.1808resizing:  416 416\n"," 72/204 [=========>....................] - ETA: 1:10 - loss: 4.5506 - yolo_layer_1_loss: 3.3390e-04 - yolo_layer_2_loss: 0.3235 - yolo_layer_3_loss: 4.2268resizing:  384 384\n"," 81/204 [==========>...................] - ETA: 1:07 - loss: 4.5141 - yolo_layer_1_loss: 3.4290e-04 - yolo_layer_2_loss: 0.3200 - yolo_layer_3_loss: 4.1937resizing:  352 352\n","117/204 [================>.............] - ETA: 46s - loss: 4.3905 - yolo_layer_1_loss: 3.3767e-04 - yolo_layer_2_loss: 0.2281 - yolo_layer_3_loss: 4.1621resizing:  416 416\n","127/204 [=================>............] - ETA: 41s - loss: 4.4766 - yolo_layer_1_loss: 3.3597e-04 - yolo_layer_2_loss: 0.2103 - yolo_layer_3_loss: 4.2660resizing:  448 448\n","129/204 [=================>............] - ETA: 40s - loss: 4.4789 - yolo_layer_1_loss: 3.3586e-04 - yolo_layer_2_loss: 0.2070 - yolo_layer_3_loss: 4.2715resizing:  416 416\n","132/204 [==================>...........] - ETA: 38s - loss: 4.4584 - yolo_layer_1_loss: 3.3581e-04 - yolo_layer_2_loss: 0.2024 - yolo_layer_3_loss: 4.2557resizing:  416 416\n","134/204 [==================>...........] - ETA: 37s - loss: 4.4612 - yolo_layer_1_loss: 3.3561e-04 - yolo_layer_2_loss: 0.1994 - yolo_layer_3_loss: 4.2615resizing:  448 448\n","137/204 [===================>..........] - ETA: 36s - loss: 4.4602 - yolo_layer_1_loss: 3.3668e-04 - yolo_layer_2_loss: 0.2076 - yolo_layer_3_loss: 4.2523resizing:  448 448\n","152/204 [=====================>........] - ETA: 28s - loss: 4.4722 - yolo_layer_1_loss: 3.4912e-04 - yolo_layer_2_loss: 0.2328 - yolo_layer_3_loss: 4.2391resizing:  384 384\n","154/204 [=====================>........] - ETA: 27s - loss: 4.4809 - yolo_layer_1_loss: 3.4941e-04 - yolo_layer_2_loss: 0.2449 - yolo_layer_3_loss: 4.2356resizing:  448 448\n","160/204 [======================>.......] - ETA: 24s - loss: 4.4830 - yolo_layer_1_loss: 3.4957e-04 - yolo_layer_2_loss: 0.2560 - yolo_layer_3_loss: 4.2267resizing:  384 384\n","161/204 [======================>.......] - ETA: 24s - loss: 4.5019 - yolo_layer_1_loss: 3.5000e-04 - yolo_layer_2_loss: 0.2879 - yolo_layer_3_loss: 4.2136resizing:  384 384\n","166/204 [=======================>......] - ETA: 21s - loss: 4.4677 - yolo_layer_1_loss: 3.5332e-04 - yolo_layer_2_loss: 0.2795 - yolo_layer_3_loss: 4.1879resizing:  352 352\n","183/204 [=========================>....] - ETA: 11s - loss: 4.4782 - yolo_layer_1_loss: 3.4966e-04 - yolo_layer_2_loss: 0.2677 - yolo_layer_3_loss: 4.2102resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 4.5060 - yolo_layer_1_loss: 3.4658e-04 - yolo_layer_2_loss: 0.2715 - yolo_layer_3_loss: 4.2342resizing:  416 416\n","204/204 [==============================] - 115s 562ms/step - loss: 4.5156 - yolo_layer_1_loss: 3.4675e-04 - yolo_layer_2_loss: 0.2702 - yolo_layer_3_loss: 4.2451\n","\n","Epoch 00028: loss did not improve from 4.44900\n","Epoch 29/103\n","resizing:  448 448\n","  3/204 [..............................] - ETA: 2:11 - loss: 5.1944 - yolo_layer_1_loss: 3.8519e-04 - yolo_layer_2_loss: 1.0285 - yolo_layer_3_loss: 4.1655resizing:  352 352\n"," 19/204 [=>............................] - ETA: 1:48 - loss: 4.5850 - yolo_layer_1_loss: 3.4467e-04 - yolo_layer_2_loss: 0.2587 - yolo_layer_3_loss: 4.3260resizing:  416 416\n"," 23/204 [==>...........................] - ETA: 1:43 - loss: 4.4154 - yolo_layer_1_loss: 3.3280e-04 - yolo_layer_2_loss: 0.2141 - yolo_layer_3_loss: 4.2009resizing:  448 448\n"," 33/204 [===>..........................] - ETA: 1:36 - loss: 4.1515 - yolo_layer_1_loss: 3.2232e-04 - yolo_layer_2_loss: 0.1892 - yolo_layer_3_loss: 3.9619resizing:  352 352\n"," 53/204 [======>.......................] - ETA: 1:26 - loss: 4.1397 - yolo_layer_1_loss: 3.4443e-04 - yolo_layer_2_loss: 0.2341 - yolo_layer_3_loss: 3.9052resizing:  384 384\n"," 59/204 [=======>......................] - ETA: 1:22 - loss: 4.0547 - yolo_layer_1_loss: 3.4389e-04 - yolo_layer_2_loss: 0.2105 - yolo_layer_3_loss: 3.8439resizing:  448 448\n"," 62/204 [========>.....................] - ETA: 1:20 - loss: 4.1468 - yolo_layer_1_loss: 3.4322e-04 - yolo_layer_2_loss: 0.2323 - yolo_layer_3_loss: 3.9142resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:19 - loss: 4.1216 - yolo_layer_1_loss: 3.4956e-04 - yolo_layer_2_loss: 0.2217 - yolo_layer_3_loss: 3.8996resizing:  416 416\n"," 78/204 [==========>...................] - ETA: 1:13 - loss: 4.0904 - yolo_layer_1_loss: 3.6579e-04 - yolo_layer_2_loss: 0.2886 - yolo_layer_3_loss: 3.8015resizing:  352 352\n"," 89/204 [============>.................] - ETA: 1:08 - loss: 4.1091 - yolo_layer_1_loss: 3.7098e-04 - yolo_layer_2_loss: 0.2684 - yolo_layer_3_loss: 3.8404resizing:  352 352\n","104/204 [==============>...............] - ETA: 57s - loss: 4.0969 - yolo_layer_1_loss: 3.5859e-04 - yolo_layer_2_loss: 0.2831 - yolo_layer_3_loss: 3.8134resizing:  352 352\n","108/204 [==============>...............] - ETA: 55s - loss: 4.1015 - yolo_layer_1_loss: 3.5550e-04 - yolo_layer_2_loss: 0.2727 - yolo_layer_3_loss: 3.8285resizing:  352 352\n","resizing:  448 448\n","112/204 [===============>..............] - ETA: 52s - loss: 4.1387 - yolo_layer_1_loss: 3.5128e-04 - yolo_layer_2_loss: 0.2630 - yolo_layer_3_loss: 3.8753resizing:  352 352\n","126/204 [=================>............] - ETA: 44s - loss: 4.1356 - yolo_layer_1_loss: 3.5307e-04 - yolo_layer_2_loss: 0.2861 - yolo_layer_3_loss: 3.8491resizing:  416 416\n","133/204 [==================>...........] - ETA: 40s - loss: 4.1307 - yolo_layer_1_loss: 3.4814e-04 - yolo_layer_2_loss: 0.2867 - yolo_layer_3_loss: 3.8437resizing:  384 384\n","152/204 [=====================>........] - ETA: 29s - loss: 4.1993 - yolo_layer_1_loss: 3.4270e-04 - yolo_layer_2_loss: 0.3069 - yolo_layer_3_loss: 3.8921resizing:  416 416\n","155/204 [=====================>........] - ETA: 27s - loss: 4.1680 - yolo_layer_1_loss: 3.4171e-04 - yolo_layer_2_loss: 0.3010 - yolo_layer_3_loss: 3.8667resizing:  448 448\n","174/204 [========================>.....] - ETA: 17s - loss: 4.2006 - yolo_layer_1_loss: 3.4895e-04 - yolo_layer_2_loss: 0.3258 - yolo_layer_3_loss: 3.8745resizing:  352 352\n","184/204 [==========================>...] - ETA: 11s - loss: 4.2024 - yolo_layer_1_loss: 3.5244e-04 - yolo_layer_2_loss: 0.3183 - yolo_layer_3_loss: 3.8838resizing:  448 448\n","188/204 [==========================>...] - ETA: 9s - loss: 4.1696 - yolo_layer_1_loss: 3.5231e-04 - yolo_layer_2_loss: 0.3115 - yolo_layer_3_loss: 3.8577 resizing:  352 352\n","189/204 [==========================>...] - ETA: 8s - loss: 4.1814 - yolo_layer_1_loss: 3.5171e-04 - yolo_layer_2_loss: 0.3099 - yolo_layer_3_loss: 3.8712resizing:  352 352\n","204/204 [==============================] - 119s 585ms/step - loss: 4.2104 - yolo_layer_1_loss: 3.4768e-04 - yolo_layer_2_loss: 0.3523 - yolo_layer_3_loss: 3.8578\n","\n","Epoch 00029: loss improved from 4.44900 to 4.21038, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 30/103\n","  1/204 [..............................] - ETA: 1:49 - loss: 5.8054 - yolo_layer_1_loss: 4.2957e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 5.8039resizing:  448 448\n","  2/204 [..............................] - ETA: 1:43 - loss: 4.3216 - yolo_layer_1_loss: 3.2808e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 4.3202resizing:  384 384\n","  6/204 [..............................] - ETA: 1:39 - loss: 4.0444 - yolo_layer_1_loss: 2.5994e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 4.0430resizing:  352 352\n","  7/204 [>.............................] - ETA: 1:38 - loss: 4.0114 - yolo_layer_1_loss: 2.5770e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 4.0100resizing:  352 352\n","  8/204 [>.............................] - ETA: 1:42 - loss: 3.9696 - yolo_layer_1_loss: 2.7800e-04 - yolo_layer_2_loss: 0.0012 - yolo_layer_3_loss: 3.9682resizing:  384 384\n"," 13/204 [>.............................] - ETA: 1:41 - loss: 4.5716 - yolo_layer_1_loss: 2.8027e-04 - yolo_layer_2_loss: 0.1928 - yolo_layer_3_loss: 4.3785resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:21 - loss: 4.1780 - yolo_layer_1_loss: 2.8595e-04 - yolo_layer_2_loss: 0.1635 - yolo_layer_3_loss: 4.0142resizing:  384 384\n"," 54/204 [======>.......................] - ETA: 1:20 - loss: 4.1142 - yolo_layer_1_loss: 2.8567e-04 - yolo_layer_2_loss: 0.1545 - yolo_layer_3_loss: 3.9594resizing:  352 352\n"," 59/204 [=======>......................] - ETA: 1:17 - loss: 4.2238 - yolo_layer_1_loss: 2.8475e-04 - yolo_layer_2_loss: 0.2189 - yolo_layer_3_loss: 4.0046resizing:  416 416\n"," 61/204 [=======>......................] - ETA: 1:16 - loss: 4.2896 - yolo_layer_1_loss: 2.8443e-04 - yolo_layer_2_loss: 0.2935 - yolo_layer_3_loss: 3.9958resizing:  416 416\n"," 70/204 [=========>....................] - ETA: 1:11 - loss: 4.3636 - yolo_layer_1_loss: 2.8619e-04 - yolo_layer_2_loss: 0.3066 - yolo_layer_3_loss: 4.0567resizing:  352 352\n"," 72/204 [=========>....................] - ETA: 1:10 - loss: 4.3530 - yolo_layer_1_loss: 2.8766e-04 - yolo_layer_2_loss: 0.2982 - yolo_layer_3_loss: 4.0545resizing:  384 384\n","105/204 [==============>...............] - ETA: 53s - loss: 4.5080 - yolo_layer_1_loss: 2.9790e-04 - yolo_layer_2_loss: 0.3341 - yolo_layer_3_loss: 4.1736resizing:  416 416\n","107/204 [==============>...............] - ETA: 52s - loss: 4.5294 - yolo_layer_1_loss: 2.9896e-04 - yolo_layer_2_loss: 0.3560 - yolo_layer_3_loss: 4.1731resizing:  384 384\n","108/204 [==============>...............] - ETA: 52s - loss: 4.5217 - yolo_layer_1_loss: 2.9877e-04 - yolo_layer_2_loss: 0.3637 - yolo_layer_3_loss: 4.1577resizing:  352 352\n","129/204 [=================>............] - ETA: 40s - loss: 4.5289 - yolo_layer_1_loss: 2.9971e-04 - yolo_layer_2_loss: 0.3190 - yolo_layer_3_loss: 4.2096resizing:  352 352\n","132/204 [==================>...........] - ETA: 38s - loss: 4.5214 - yolo_layer_1_loss: 3.0079e-04 - yolo_layer_2_loss: 0.3179 - yolo_layer_3_loss: 4.2033resizing:  352 352\n","141/204 [===================>..........] - ETA: 33s - loss: 4.5262 - yolo_layer_1_loss: 2.9918e-04 - yolo_layer_2_loss: 0.3001 - yolo_layer_3_loss: 4.2258resizing:  416 416\n","153/204 [=====================>........] - ETA: 27s - loss: 4.5657 - yolo_layer_1_loss: 3.0662e-04 - yolo_layer_2_loss: 0.2905 - yolo_layer_3_loss: 4.2749resizing:  416 416\n","resizing:  448 448\n","160/204 [======================>.......] - ETA: 23s - loss: 4.5494 - yolo_layer_1_loss: 3.0976e-04 - yolo_layer_2_loss: 0.2949 - yolo_layer_3_loss: 4.2542resizing:  384 384\n","162/204 [======================>.......] - ETA: 22s - loss: 4.5336 - yolo_layer_1_loss: 3.1884e-04 - yolo_layer_2_loss: 0.2983 - yolo_layer_3_loss: 4.2349resizing:  448 448\n","168/204 [=======================>......] - ETA: 19s - loss: 4.5174 - yolo_layer_1_loss: 3.2260e-04 - yolo_layer_2_loss: 0.3077 - yolo_layer_3_loss: 4.2094resizing:  416 416\n","174/204 [========================>.....] - ETA: 16s - loss: 4.5011 - yolo_layer_1_loss: 3.2527e-04 - yolo_layer_2_loss: 0.3283 - yolo_layer_3_loss: 4.1724resizing:  448 448\n","204/204 [==============================] - 117s 572ms/step - loss: 4.4253 - yolo_layer_1_loss: 3.3736e-04 - yolo_layer_2_loss: 0.3421 - yolo_layer_3_loss: 4.0829\n","\n","Epoch 00030: loss did not improve from 4.21038\n","Epoch 31/103\n","resizing:  352 352\n","  1/204 [..............................] - ETA: 2:19 - loss: 5.6176 - yolo_layer_1_loss: 3.8557e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 5.6158resizing:  384 384\n"," 13/204 [>.............................] - ETA: 1:49 - loss: 4.4589 - yolo_layer_1_loss: 3.0565e-04 - yolo_layer_2_loss: 0.4118 - yolo_layer_3_loss: 4.0468resizing:  384 384\n"," 26/204 [==>...........................] - ETA: 1:39 - loss: 4.4625 - yolo_layer_1_loss: 2.8509e-04 - yolo_layer_2_loss: 0.2067 - yolo_layer_3_loss: 4.2555resizing:  384 384\n"," 30/204 [===>..........................] - ETA: 1:36 - loss: 4.3377 - yolo_layer_1_loss: 2.9131e-04 - yolo_layer_2_loss: 0.1794 - yolo_layer_3_loss: 4.1580resizing:  384 384\n"," 39/204 [====>.........................] - ETA: 1:31 - loss: 4.1609 - yolo_layer_1_loss: 2.8992e-04 - yolo_layer_2_loss: 0.2195 - yolo_layer_3_loss: 3.9412resizing:  416 416\n"," 50/204 [======>.......................] - ETA: 1:24 - loss: 4.2693 - yolo_layer_1_loss: 2.9079e-04 - yolo_layer_2_loss: 0.3012 - yolo_layer_3_loss: 3.9678resizing:  352 352\n","resizing:  352 352\n"," 53/204 [======>.......................] - ETA: 1:23 - loss: 4.3777 - yolo_layer_1_loss: 2.9477e-04 - yolo_layer_2_loss: 0.3018 - yolo_layer_3_loss: 4.0756resizing:  416 416\n"," 54/204 [======>.......................] - ETA: 1:22 - loss: 4.3361 - yolo_layer_1_loss: 2.9303e-04 - yolo_layer_2_loss: 0.2963 - yolo_layer_3_loss: 4.0396resizing:  384 384\n"," 67/204 [========>.....................] - ETA: 1:15 - loss: 4.3976 - yolo_layer_1_loss: 2.8312e-04 - yolo_layer_2_loss: 0.3318 - yolo_layer_3_loss: 4.0655resizing:  352 352\n"," 80/204 [==========>...................] - ETA: 1:07 - loss: 4.5371 - yolo_layer_1_loss: 2.7897e-04 - yolo_layer_2_loss: 0.3552 - yolo_layer_3_loss: 4.1816resizing:  352 352\n","104/204 [==============>...............] - ETA: 53s - loss: 4.3947 - yolo_layer_1_loss: 2.6693e-04 - yolo_layer_2_loss: 0.2830 - yolo_layer_3_loss: 4.1114resizing:  416 416\n","105/204 [==============>...............] - ETA: 52s - loss: 4.3938 - yolo_layer_1_loss: 2.6633e-04 - yolo_layer_2_loss: 0.2803 - yolo_layer_3_loss: 4.1132resizing:  352 352\n","108/204 [==============>...............] - ETA: 51s - loss: 4.4036 - yolo_layer_1_loss: 2.6510e-04 - yolo_layer_2_loss: 0.2939 - yolo_layer_3_loss: 4.1094resizing:  448 448\n","117/204 [================>.............] - ETA: 46s - loss: 4.3762 - yolo_layer_1_loss: 2.6338e-04 - yolo_layer_2_loss: 0.3309 - yolo_layer_3_loss: 4.0451resizing:  384 384\n","129/204 [=================>............] - ETA: 41s - loss: 4.4093 - yolo_layer_1_loss: 2.7155e-04 - yolo_layer_2_loss: 0.3582 - yolo_layer_3_loss: 4.0508resizing:  448 448\n","133/204 [==================>...........] - ETA: 38s - loss: 4.3866 - yolo_layer_1_loss: 2.7111e-04 - yolo_layer_2_loss: 0.3475 - yolo_layer_3_loss: 4.0388resizing:  448 448\n","152/204 [=====================>........] - ETA: 29s - loss: 4.4035 - yolo_layer_1_loss: 2.7550e-04 - yolo_layer_2_loss: 0.3336 - yolo_layer_3_loss: 4.0696resizing:  352 352\n","153/204 [=====================>........] - ETA: 28s - loss: 4.4122 - yolo_layer_1_loss: 2.7575e-04 - yolo_layer_2_loss: 0.3323 - yolo_layer_3_loss: 4.0796resizing:  384 384\n","155/204 [=====================>........] - ETA: 27s - loss: 4.4176 - yolo_layer_1_loss: 2.7801e-04 - yolo_layer_2_loss: 0.3386 - yolo_layer_3_loss: 4.0787resizing:  448 448\n","156/204 [=====================>........] - ETA: 26s - loss: 4.4354 - yolo_layer_1_loss: 2.7793e-04 - yolo_layer_2_loss: 0.3364 - yolo_layer_3_loss: 4.0987resizing:  384 384\n","166/204 [=======================>......] - ETA: 21s - loss: 4.3916 - yolo_layer_1_loss: 2.7729e-04 - yolo_layer_2_loss: 0.3398 - yolo_layer_3_loss: 4.0515resizing:  448 448\n","179/204 [=========================>....] - ETA: 14s - loss: 4.3659 - yolo_layer_1_loss: 2.7646e-04 - yolo_layer_2_loss: 0.3649 - yolo_layer_3_loss: 4.0007resizing:  384 384\n","204/204 [==============================] - 116s 569ms/step - loss: 4.3813 - yolo_layer_1_loss: 2.7986e-04 - yolo_layer_2_loss: 0.3369 - yolo_layer_3_loss: 4.0441\n","\n","Epoch 00031: loss did not improve from 4.21038\n","Epoch 32/103\n","  3/204 [..............................] - ETA: 1:48 - loss: 4.5971 - yolo_layer_1_loss: 2.9903e-04 - yolo_layer_2_loss: 0.6795 - yolo_layer_3_loss: 3.9172resizing:  416 416\n","resizing:  448 448\n","  8/204 [>.............................] - ETA: 1:47 - loss: 5.2008 - yolo_layer_1_loss: 2.6926e-04 - yolo_layer_2_loss: 0.6445 - yolo_layer_3_loss: 4.5561resizing:  352 352\n"," 11/204 [>.............................] - ETA: 1:52 - loss: 5.2263 - yolo_layer_1_loss: 2.9028e-04 - yolo_layer_2_loss: 0.6649 - yolo_layer_3_loss: 4.5611resizing:  384 384\n"," 13/204 [>.............................] - ETA: 1:55 - loss: 4.8531 - yolo_layer_1_loss: 3.0242e-04 - yolo_layer_2_loss: 0.6419 - yolo_layer_3_loss: 4.2109resizing:  384 384\n"," 36/204 [====>.........................] - ETA: 1:38 - loss: 4.6196 - yolo_layer_1_loss: 2.9011e-04 - yolo_layer_2_loss: 0.4180 - yolo_layer_3_loss: 4.2013resizing:  416 416\n"," 59/204 [=======>......................] - ETA: 1:25 - loss: 4.4965 - yolo_layer_1_loss: 2.8184e-04 - yolo_layer_2_loss: 0.4951 - yolo_layer_3_loss: 4.0011resizing:  416 416\n"," 61/204 [=======>......................] - ETA: 1:24 - loss: 4.4542 - yolo_layer_1_loss: 2.8102e-04 - yolo_layer_2_loss: 0.4789 - yolo_layer_3_loss: 3.9750resizing:  416 416\n"," 62/204 [========>.....................] - ETA: 1:23 - loss: 4.4286 - yolo_layer_1_loss: 2.8109e-04 - yolo_layer_2_loss: 0.4712 - yolo_layer_3_loss: 3.9571resizing:  352 352\n"," 63/204 [========>.....................] - ETA: 1:23 - loss: 4.3940 - yolo_layer_1_loss: 2.8042e-04 - yolo_layer_2_loss: 0.4638 - yolo_layer_3_loss: 3.9300resizing:  384 384\n"," 65/204 [========>.....................] - ETA: 1:22 - loss: 4.3409 - yolo_layer_1_loss: 2.7989e-04 - yolo_layer_2_loss: 0.4496 - yolo_layer_3_loss: 3.8911resizing:  448 448\n"," 67/204 [========>.....................] - ETA: 1:21 - loss: 4.3666 - yolo_layer_1_loss: 2.7936e-04 - yolo_layer_2_loss: 0.4362 - yolo_layer_3_loss: 3.9301resizing:  416 416\n","105/204 [==============>...............] - ETA: 1:00 - loss: 4.2694 - yolo_layer_1_loss: 2.8731e-04 - yolo_layer_2_loss: 0.3372 - yolo_layer_3_loss: 3.9319resizing:  352 352\n","113/204 [===============>..............] - ETA: 55s - loss: 4.3445 - yolo_layer_1_loss: 2.8409e-04 - yolo_layer_2_loss: 0.3134 - yolo_layer_3_loss: 4.0308resizing:  352 352\n","118/204 [================>.............] - ETA: 52s - loss: 4.3836 - yolo_layer_1_loss: 2.8121e-04 - yolo_layer_2_loss: 0.3115 - yolo_layer_3_loss: 4.0718resizing:  448 448\n","121/204 [================>.............] - ETA: 50s - loss: 4.3766 - yolo_layer_1_loss: 2.8020e-04 - yolo_layer_2_loss: 0.3039 - yolo_layer_3_loss: 4.0724resizing:  352 352\n","122/204 [================>.............] - ETA: 49s - loss: 4.4114 - yolo_layer_1_loss: 2.7953e-04 - yolo_layer_2_loss: 0.3014 - yolo_layer_3_loss: 4.1097resizing:  352 352\n","132/204 [==================>...........] - ETA: 43s - loss: 4.4605 - yolo_layer_1_loss: 2.7683e-04 - yolo_layer_2_loss: 0.2788 - yolo_layer_3_loss: 4.1814resizing:  416 416\n","153/204 [=====================>........] - ETA: 30s - loss: 4.3807 - yolo_layer_1_loss: 2.7242e-04 - yolo_layer_2_loss: 0.2409 - yolo_layer_3_loss: 4.1396resizing:  448 448\n","157/204 [======================>.......] - ETA: 27s - loss: 4.3924 - yolo_layer_1_loss: 2.7260e-04 - yolo_layer_2_loss: 0.2668 - yolo_layer_3_loss: 4.1253resizing:  416 416\n","159/204 [======================>.......] - ETA: 26s - loss: 4.3986 - yolo_layer_1_loss: 2.7358e-04 - yolo_layer_2_loss: 0.2698 - yolo_layer_3_loss: 4.1285resizing:  384 384\n","160/204 [======================>.......] - ETA: 26s - loss: 4.3866 - yolo_layer_1_loss: 2.7391e-04 - yolo_layer_2_loss: 0.2682 - yolo_layer_3_loss: 4.1181resizing:  448 448\n","178/204 [=========================>....] - ETA: 15s - loss: 4.3359 - yolo_layer_1_loss: 2.7965e-04 - yolo_layer_2_loss: 0.2678 - yolo_layer_3_loss: 4.0678resizing:  352 352\n","181/204 [=========================>....] - ETA: 13s - loss: 4.3642 - yolo_layer_1_loss: 2.8106e-04 - yolo_layer_2_loss: 0.2945 - yolo_layer_3_loss: 4.0694resizing:  352 352\n","204/204 [==============================] - 123s 602ms/step - loss: 4.4156 - yolo_layer_1_loss: 2.8047e-04 - yolo_layer_2_loss: 0.2904 - yolo_layer_3_loss: 4.1249\n","\n","Epoch 00032: loss did not improve from 4.21038\n","Epoch 33/103\n","  8/204 [>.............................] - ETA: 1:37 - loss: 4.4257 - yolo_layer_1_loss: 2.3920e-04 - yolo_layer_2_loss: 0.0013 - yolo_layer_3_loss: 4.4242resizing:  448 448\n","resizing:  416 416\n"," 10/204 [>.............................] - ETA: 1:36 - loss: 4.5981 - yolo_layer_1_loss: 2.4783e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 4.5965resizing:  448 448\n"," 12/204 [>.............................] - ETA: 1:35 - loss: 4.2772 - yolo_layer_1_loss: 2.4519e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 4.2755resizing:  384 384\n"," 25/204 [==>...........................] - ETA: 1:37 - loss: 4.4236 - yolo_layer_1_loss: 2.5699e-04 - yolo_layer_2_loss: 0.3646 - yolo_layer_3_loss: 4.0588resizing:  448 448\n"," 38/204 [====>.........................] - ETA: 1:31 - loss: 4.4292 - yolo_layer_1_loss: 2.6282e-04 - yolo_layer_2_loss: 0.2888 - yolo_layer_3_loss: 4.1401resizing:  416 416\n"," 57/204 [=======>......................] - ETA: 1:26 - loss: 4.3169 - yolo_layer_1_loss: 2.7796e-04 - yolo_layer_2_loss: 0.4252 - yolo_layer_3_loss: 3.8914resizing:  416 416\n"," 78/204 [==========>...................] - ETA: 1:16 - loss: 4.3639 - yolo_layer_1_loss: 2.7709e-04 - yolo_layer_2_loss: 0.4056 - yolo_layer_3_loss: 3.9580resizing:  352 352\n"," 80/204 [==========>...................] - ETA: 1:15 - loss: 4.3309 - yolo_layer_1_loss: 2.7724e-04 - yolo_layer_2_loss: 0.3956 - yolo_layer_3_loss: 3.9351resizing:  384 384\n"," 82/204 [===========>..................] - ETA: 1:14 - loss: 4.3717 - yolo_layer_1_loss: 2.7765e-04 - yolo_layer_2_loss: 0.3860 - yolo_layer_3_loss: 3.9854resizing:  448 448\n"," 84/204 [===========>..................] - ETA: 1:13 - loss: 4.3995 - yolo_layer_1_loss: 2.7708e-04 - yolo_layer_2_loss: 0.3769 - yolo_layer_3_loss: 4.0223resizing:  352 352\n"," 87/204 [===========>..................] - ETA: 1:11 - loss: 4.3992 - yolo_layer_1_loss: 2.7669e-04 - yolo_layer_2_loss: 0.3820 - yolo_layer_3_loss: 4.0169resizing:  416 416\n","101/204 [=============>................] - ETA: 1:02 - loss: 4.3266 - yolo_layer_1_loss: 2.7334e-04 - yolo_layer_2_loss: 0.3504 - yolo_layer_3_loss: 3.9759resizing:  384 384\n","112/204 [===============>..............] - ETA: 55s - loss: 4.2973 - yolo_layer_1_loss: 2.6876e-04 - yolo_layer_2_loss: 0.3221 - yolo_layer_3_loss: 3.9749resizing:  448 448\n","117/204 [================>.............] - ETA: 52s - loss: 4.3013 - yolo_layer_1_loss: 2.6763e-04 - yolo_layer_2_loss: 0.3094 - yolo_layer_3_loss: 3.9917resizing:  416 416\n","119/204 [================>.............] - ETA: 50s - loss: 4.2787 - yolo_layer_1_loss: 2.6700e-04 - yolo_layer_2_loss: 0.3042 - yolo_layer_3_loss: 3.9742resizing:  448 448\n","129/204 [=================>............] - ETA: 45s - loss: 4.2249 - yolo_layer_1_loss: 2.6724e-04 - yolo_layer_2_loss: 0.2808 - yolo_layer_3_loss: 3.9438resizing:  352 352\n","135/204 [==================>...........] - ETA: 41s - loss: 4.2586 - yolo_layer_1_loss: 2.6886e-04 - yolo_layer_2_loss: 0.2685 - yolo_layer_3_loss: 3.9899resizing:  384 384\n","155/204 [=====================>........] - ETA: 29s - loss: 4.1963 - yolo_layer_1_loss: 2.6379e-04 - yolo_layer_2_loss: 0.2696 - yolo_layer_3_loss: 3.9264resizing:  448 448\n","resizing:  352 352\n","164/204 [=======================>......] - ETA: 23s - loss: 4.1850 - yolo_layer_1_loss: 2.6129e-04 - yolo_layer_2_loss: 0.2692 - yolo_layer_3_loss: 3.9156resizing:  352 352\n","176/204 [========================>.....] - ETA: 16s - loss: 4.2238 - yolo_layer_1_loss: 2.5758e-04 - yolo_layer_2_loss: 0.2693 - yolo_layer_3_loss: 3.9543resizing:  448 448\n","182/204 [=========================>....] - ETA: 12s - loss: 4.2516 - yolo_layer_1_loss: 2.5581e-04 - yolo_layer_2_loss: 0.2604 - yolo_layer_3_loss: 3.9909resizing:  416 416\n","192/204 [===========================>..] - ETA: 7s - loss: 4.2201 - yolo_layer_1_loss: 2.5637e-04 - yolo_layer_2_loss: 0.2513 - yolo_layer_3_loss: 3.9686resizing:  352 352\n","204/204 [==============================] - 120s 589ms/step - loss: 4.2112 - yolo_layer_1_loss: 2.5504e-04 - yolo_layer_2_loss: 0.2686 - yolo_layer_3_loss: 3.9424\n","\n","Epoch 00033: loss did not improve from 4.21038\n","resizing:  352 352\n","\n","Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","Epoch 34/103\n","  4/204 [..............................] - ETA: 1:42 - loss: 4.8503 - yolo_layer_1_loss: 1.8858e-04 - yolo_layer_2_loss: 0.1839 - yolo_layer_3_loss: 4.6663resizing:  416 416\n"," 23/204 [==>...........................] - ETA: 1:39 - loss: 4.4766 - yolo_layer_1_loss: 2.2250e-04 - yolo_layer_2_loss: 0.4295 - yolo_layer_3_loss: 4.0469resizing:  448 448\n"," 31/204 [===>..........................] - ETA: 1:39 - loss: 4.2248 - yolo_layer_1_loss: 2.2890e-04 - yolo_layer_2_loss: 0.3250 - yolo_layer_3_loss: 3.8996resizing:  352 352\n"," 35/204 [====>.........................] - ETA: 1:39 - loss: 4.1604 - yolo_layer_1_loss: 2.3545e-04 - yolo_layer_2_loss: 0.3527 - yolo_layer_3_loss: 3.8074resizing:  384 384\n"," 37/204 [====>.........................] - ETA: 1:39 - loss: 4.0622 - yolo_layer_1_loss: 2.3763e-04 - yolo_layer_2_loss: 0.3346 - yolo_layer_3_loss: 3.7273resizing:  448 448\n"," 61/204 [=======>......................] - ETA: 1:28 - loss: 4.2096 - yolo_layer_1_loss: 2.5689e-04 - yolo_layer_2_loss: 0.4181 - yolo_layer_3_loss: 3.7912resizing:  448 448\n"," 69/204 [=========>....................] - ETA: 1:24 - loss: 4.0486 - yolo_layer_1_loss: 2.6167e-04 - yolo_layer_2_loss: 0.3707 - yolo_layer_3_loss: 3.6776resizing:  416 416\n"," 72/204 [=========>....................] - ETA: 1:23 - loss: 4.0997 - yolo_layer_1_loss: 2.6154e-04 - yolo_layer_2_loss: 0.3558 - yolo_layer_3_loss: 3.7436resizing:  416 416\n"," 75/204 [==========>...................] - ETA: 1:21 - loss: 4.1675 - yolo_layer_1_loss: 2.6365e-04 - yolo_layer_2_loss: 0.3721 - yolo_layer_3_loss: 3.7951resizing:  352 352\n"," 79/204 [==========>...................] - ETA: 1:19 - loss: 4.1497 - yolo_layer_1_loss: 2.6574e-04 - yolo_layer_2_loss: 0.3535 - yolo_layer_3_loss: 3.7960resizing:  352 352\n"," 89/204 [============>.................] - ETA: 1:12 - loss: 4.0788 - yolo_layer_1_loss: 2.6135e-04 - yolo_layer_2_loss: 0.3436 - yolo_layer_3_loss: 3.7350resizing:  352 352\n","101/204 [=============>................] - ETA: 1:03 - loss: 4.1974 - yolo_layer_1_loss: 2.5413e-04 - yolo_layer_2_loss: 0.3151 - yolo_layer_3_loss: 3.8820resizing:  352 352\n","102/204 [==============>...............] - ETA: 1:02 - loss: 4.1926 - yolo_layer_1_loss: 2.5381e-04 - yolo_layer_2_loss: 0.3232 - yolo_layer_3_loss: 3.8691resizing:  352 352\n","106/204 [==============>...............] - ETA: 59s - loss: 4.2058 - yolo_layer_1_loss: 2.5278e-04 - yolo_layer_2_loss: 0.3252 - yolo_layer_3_loss: 3.8803 resizing:  416 416\n","107/204 [==============>...............] - ETA: 59s - loss: 4.1930 - yolo_layer_1_loss: 2.5221e-04 - yolo_layer_2_loss: 0.3222 - yolo_layer_3_loss: 3.8705resizing:  416 416\n","123/204 [=================>............] - ETA: 49s - loss: 4.0787 - yolo_layer_1_loss: 2.4828e-04 - yolo_layer_2_loss: 0.2897 - yolo_layer_3_loss: 3.7887resizing:  384 384\n","128/204 [=================>............] - ETA: 46s - loss: 4.0647 - yolo_layer_1_loss: 2.4861e-04 - yolo_layer_2_loss: 0.2785 - yolo_layer_3_loss: 3.7859resizing:  352 352\n","152/204 [=====================>........] - ETA: 31s - loss: 4.1138 - yolo_layer_1_loss: 2.4532e-04 - yolo_layer_2_loss: 0.3481 - yolo_layer_3_loss: 3.7655resizing:  384 384\n","167/204 [=======================>......] - ETA: 21s - loss: 4.1157 - yolo_layer_1_loss: 2.4280e-04 - yolo_layer_2_loss: 0.3393 - yolo_layer_3_loss: 3.7762resizing:  352 352\n","172/204 [========================>.....] - ETA: 18s - loss: 4.1064 - yolo_layer_1_loss: 2.4218e-04 - yolo_layer_2_loss: 0.3473 - yolo_layer_3_loss: 3.7589resizing:  352 352\n","177/204 [=========================>....] - ETA: 15s - loss: 4.1157 - yolo_layer_1_loss: 2.4172e-04 - yolo_layer_2_loss: 0.3375 - yolo_layer_3_loss: 3.7779resizing:  416 416\n","183/204 [=========================>....] - ETA: 12s - loss: 4.1049 - yolo_layer_1_loss: 2.4057e-04 - yolo_layer_2_loss: 0.3265 - yolo_layer_3_loss: 3.7782resizing:  448 448\n","186/204 [==========================>...] - ETA: 10s - loss: 4.1031 - yolo_layer_1_loss: 2.3961e-04 - yolo_layer_2_loss: 0.3212 - yolo_layer_3_loss: 3.7817resizing:  384 384\n","204/204 [==============================] - 120s 587ms/step - loss: 4.1184 - yolo_layer_1_loss: 2.3964e-04 - yolo_layer_2_loss: 0.3262 - yolo_layer_3_loss: 3.7919\n","\n","Epoch 00034: loss improved from 4.21038 to 4.11837, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","resizing:  384 384\n","Epoch 35/103\n","  3/204 [..............................] - ETA: 1:52 - loss: 2.8832 - yolo_layer_1_loss: 2.0942e-04 - yolo_layer_2_loss: 0.0275 - yolo_layer_3_loss: 2.8555resizing:  384 384\n"," 20/204 [=>............................] - ETA: 1:41 - loss: 4.0629 - yolo_layer_1_loss: 2.1889e-04 - yolo_layer_2_loss: 0.1077 - yolo_layer_3_loss: 3.9550resizing:  352 352\n"," 33/204 [===>..........................] - ETA: 1:33 - loss: 4.0212 - yolo_layer_1_loss: 2.1667e-04 - yolo_layer_2_loss: 0.1115 - yolo_layer_3_loss: 3.9095resizing:  352 352\n"," 35/204 [====>.........................] - ETA: 1:32 - loss: 3.9982 - yolo_layer_1_loss: 2.1605e-04 - yolo_layer_2_loss: 0.1052 - yolo_layer_3_loss: 3.8929resizing:  384 384\n"," 38/204 [====>.........................] - ETA: 1:29 - loss: 4.0870 - yolo_layer_1_loss: 2.1472e-04 - yolo_layer_2_loss: 0.0969 - yolo_layer_3_loss: 3.9898resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:21 - loss: 3.9312 - yolo_layer_1_loss: 2.0926e-04 - yolo_layer_2_loss: 0.0908 - yolo_layer_3_loss: 3.8403resizing:  384 384\n"," 55/204 [=======>......................] - ETA: 1:19 - loss: 3.8992 - yolo_layer_1_loss: 2.0922e-04 - yolo_layer_2_loss: 0.1437 - yolo_layer_3_loss: 3.7553resizing:  416 416\n"," 57/204 [=======>......................] - ETA: 1:18 - loss: 3.8675 - yolo_layer_1_loss: 2.0846e-04 - yolo_layer_2_loss: 0.1388 - yolo_layer_3_loss: 3.7285resizing:  384 384\n"," 76/204 [==========>...................] - ETA: 1:09 - loss: 3.8730 - yolo_layer_1_loss: 2.1324e-04 - yolo_layer_2_loss: 0.1680 - yolo_layer_3_loss: 3.7048resizing:  416 416\n"," 86/204 [===========>..................] - ETA: 1:04 - loss: 3.9498 - yolo_layer_1_loss: 2.1512e-04 - yolo_layer_2_loss: 0.1591 - yolo_layer_3_loss: 3.7905resizing:  384 384\n"," 89/204 [============>.................] - ETA: 1:02 - loss: 3.9329 - yolo_layer_1_loss: 2.1535e-04 - yolo_layer_2_loss: 0.1666 - yolo_layer_3_loss: 3.7661resizing:  384 384\n","106/204 [==============>...............] - ETA: 54s - loss: 3.8633 - yolo_layer_1_loss: 2.1702e-04 - yolo_layer_2_loss: 0.1472 - yolo_layer_3_loss: 3.7159resizing:  448 448\n","110/204 [===============>..............] - ETA: 51s - loss: 3.8500 - yolo_layer_1_loss: 2.1718e-04 - yolo_layer_2_loss: 0.1419 - yolo_layer_3_loss: 3.7078resizing:  448 448\n","113/204 [===============>..............] - ETA: 50s - loss: 3.8033 - yolo_layer_1_loss: 2.1822e-04 - yolo_layer_2_loss: 0.1382 - yolo_layer_3_loss: 3.6649resizing:  384 384\n","116/204 [================>.............] - ETA: 49s - loss: 3.7642 - yolo_layer_1_loss: 2.2070e-04 - yolo_layer_2_loss: 0.1425 - yolo_layer_3_loss: 3.6214resizing:  384 384\n","119/204 [================>.............] - ETA: 47s - loss: 3.7368 - yolo_layer_1_loss: 2.2353e-04 - yolo_layer_2_loss: 0.1431 - yolo_layer_3_loss: 3.5935resizing:  352 352\n","127/204 [=================>............] - ETA: 43s - loss: 3.7332 - yolo_layer_1_loss: 2.2761e-04 - yolo_layer_2_loss: 0.1456 - yolo_layer_3_loss: 3.5873resizing:  448 448\n","154/204 [=====================>........] - ETA: 28s - loss: 3.6927 - yolo_layer_1_loss: 2.3081e-04 - yolo_layer_2_loss: 0.1752 - yolo_layer_3_loss: 3.5173resizing:  384 384\n","157/204 [======================>.......] - ETA: 27s - loss: 3.6888 - yolo_layer_1_loss: 2.3175e-04 - yolo_layer_2_loss: 0.1912 - yolo_layer_3_loss: 3.4973resizing:  352 352\n","164/204 [=======================>......] - ETA: 23s - loss: 3.7391 - yolo_layer_1_loss: 2.3246e-04 - yolo_layer_2_loss: 0.2182 - yolo_layer_3_loss: 3.5207resizing:  384 384\n","165/204 [=======================>......] - ETA: 22s - loss: 3.7402 - yolo_layer_1_loss: 2.3217e-04 - yolo_layer_2_loss: 0.2169 - yolo_layer_3_loss: 3.5231resizing:  448 448\n","168/204 [=======================>......] - ETA: 20s - loss: 3.7364 - yolo_layer_1_loss: 2.3181e-04 - yolo_layer_2_loss: 0.2130 - yolo_layer_3_loss: 3.5231resizing:  384 384\n","181/204 [=========================>....] - ETA: 13s - loss: 3.7420 - yolo_layer_1_loss: 2.3525e-04 - yolo_layer_2_loss: 0.1978 - yolo_layer_3_loss: 3.5440resizing:  384 384\n","204/204 [==============================] - 117s 571ms/step - loss: 3.7982 - yolo_layer_1_loss: 2.3205e-04 - yolo_layer_2_loss: 0.2196 - yolo_layer_3_loss: 3.5784\n","\n","Epoch 00035: loss improved from 4.11837 to 3.79819, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 36/103\n","  6/204 [..............................] - ETA: 1:52 - loss: 3.3021 - yolo_layer_1_loss: 2.1951e-04 - yolo_layer_2_loss: 0.0020 - yolo_layer_3_loss: 3.2999resizing:  416 416\n"," 10/204 [>.............................] - ETA: 1:48 - loss: 3.0848 - yolo_layer_1_loss: 2.1733e-04 - yolo_layer_2_loss: 0.1266 - yolo_layer_3_loss: 2.9580resizing:  448 448\n"," 25/204 [==>...........................] - ETA: 1:47 - loss: 2.9128 - yolo_layer_1_loss: 2.4115e-04 - yolo_layer_2_loss: 0.0900 - yolo_layer_3_loss: 2.8226resizing:  448 448\n"," 27/204 [==>...........................] - ETA: 1:47 - loss: 2.9526 - yolo_layer_1_loss: 2.4204e-04 - yolo_layer_2_loss: 0.0834 - yolo_layer_3_loss: 2.8689resizing:  384 384\n"," 28/204 [===>..........................] - ETA: 1:47 - loss: 2.9226 - yolo_layer_1_loss: 2.4578e-04 - yolo_layer_2_loss: 0.0832 - yolo_layer_3_loss: 2.8392resizing:  448 448\n"," 31/204 [===>..........................] - ETA: 1:47 - loss: 2.9868 - yolo_layer_1_loss: 2.4660e-04 - yolo_layer_2_loss: 0.1181 - yolo_layer_3_loss: 2.8685resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:37 - loss: 3.1269 - yolo_layer_1_loss: 2.5930e-04 - yolo_layer_2_loss: 0.2065 - yolo_layer_3_loss: 2.9201resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:32 - loss: 3.1468 - yolo_layer_1_loss: 2.5662e-04 - yolo_layer_2_loss: 0.1849 - yolo_layer_3_loss: 2.9616resizing:  352 352\n"," 65/204 [========>.....................] - ETA: 1:25 - loss: 3.2819 - yolo_layer_1_loss: 2.5081e-04 - yolo_layer_2_loss: 0.1623 - yolo_layer_3_loss: 3.1193resizing:  352 352\n"," 68/204 [=========>....................] - ETA: 1:22 - loss: 3.3027 - yolo_layer_1_loss: 2.4771e-04 - yolo_layer_2_loss: 0.1552 - yolo_layer_3_loss: 3.1473resizing:  352 352\n"," 69/204 [=========>....................] - ETA: 1:21 - loss: 3.3033 - yolo_layer_1_loss: 2.4676e-04 - yolo_layer_2_loss: 0.1530 - yolo_layer_3_loss: 3.1501resizing:  448 448\n"," 76/204 [==========>...................] - ETA: 1:16 - loss: 3.3491 - yolo_layer_1_loss: 2.4055e-04 - yolo_layer_2_loss: 0.1390 - yolo_layer_3_loss: 3.2098resizing:  416 416\n","102/204 [==============>...............] - ETA: 1:01 - loss: 3.4894 - yolo_layer_1_loss: 2.4165e-04 - yolo_layer_2_loss: 0.2004 - yolo_layer_3_loss: 3.2888resizing:  352 352\n","106/204 [==============>...............] - ETA: 59s - loss: 3.4761 - yolo_layer_1_loss: 2.4092e-04 - yolo_layer_2_loss: 0.1952 - yolo_layer_3_loss: 3.2807 resizing:  352 352\n","109/204 [===============>..............] - ETA: 57s - loss: 3.4573 - yolo_layer_1_loss: 2.3957e-04 - yolo_layer_2_loss: 0.1899 - yolo_layer_3_loss: 3.2672resizing:  352 352\n","116/204 [================>.............] - ETA: 52s - loss: 3.5349 - yolo_layer_1_loss: 2.3791e-04 - yolo_layer_2_loss: 0.1785 - yolo_layer_3_loss: 3.3561resizing:  352 352\n","121/204 [================>.............] - ETA: 49s - loss: 3.5804 - yolo_layer_1_loss: 2.3591e-04 - yolo_layer_2_loss: 0.2067 - yolo_layer_3_loss: 3.3735resizing:  352 352\n","139/204 [===================>..........] - ETA: 37s - loss: 3.6153 - yolo_layer_1_loss: 2.3079e-04 - yolo_layer_2_loss: 0.1801 - yolo_layer_3_loss: 3.4350resizing:  352 352\n","152/204 [=====================>........] - ETA: 29s - loss: 3.6304 - yolo_layer_1_loss: 2.2743e-04 - yolo_layer_2_loss: 0.1855 - yolo_layer_3_loss: 3.4447resizing:  352 352\n","155/204 [=====================>........] - ETA: 28s - loss: 3.6428 - yolo_layer_1_loss: 2.2640e-04 - yolo_layer_2_loss: 0.1819 - yolo_layer_3_loss: 3.4606resizing:  416 416\n","161/204 [======================>.......] - ETA: 24s - loss: 3.6103 - yolo_layer_1_loss: 2.2647e-04 - yolo_layer_2_loss: 0.1868 - yolo_layer_3_loss: 3.4233resizing:  448 448\n","resizing:  448 448\n","179/204 [=========================>....] - ETA: 14s - loss: 3.5626 - yolo_layer_1_loss: 2.2945e-04 - yolo_layer_2_loss: 0.1795 - yolo_layer_3_loss: 3.3829resizing:  352 352\n","184/204 [==========================>...] - ETA: 11s - loss: 3.5481 - yolo_layer_1_loss: 2.3052e-04 - yolo_layer_2_loss: 0.1830 - yolo_layer_3_loss: 3.3648resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 3.5244 - yolo_layer_1_loss: 2.2898e-04 - yolo_layer_2_loss: 0.1741 - yolo_layer_3_loss: 3.3500resizing:  416 416\n","resizing:  416 416\n","204/204 [==============================] - 119s 581ms/step - loss: 3.5304 - yolo_layer_1_loss: 2.2878e-04 - yolo_layer_2_loss: 0.1733 - yolo_layer_3_loss: 3.3569\n","\n","Epoch 00036: loss improved from 3.79819 to 3.53040, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 37/103\n","  2/204 [..............................] - ETA: 2:12 - loss: 2.5992 - yolo_layer_1_loss: 2.1220e-04 - yolo_layer_2_loss: 0.0017 - yolo_layer_3_loss: 2.5972    resizing:  352 352\n","  3/204 [..............................] - ETA: 2:10 - loss: 3.7687 - yolo_layer_1_loss: 2.2491e-04 - yolo_layer_2_loss: 0.0017 - yolo_layer_3_loss: 3.7667resizing:  416 416\n","  5/204 [..............................] - ETA: 2:09 - loss: 4.1536 - yolo_layer_1_loss: 2.1900e-04 - yolo_layer_2_loss: 0.2997 - yolo_layer_3_loss: 3.8537resizing:  384 384\n"," 16/204 [=>............................] - ETA: 1:53 - loss: 4.1587 - yolo_layer_1_loss: 2.1656e-04 - yolo_layer_2_loss: 0.2622 - yolo_layer_3_loss: 3.8963resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:26 - loss: 3.7348 - yolo_layer_1_loss: 2.2855e-04 - yolo_layer_2_loss: 0.4309 - yolo_layer_3_loss: 3.3037resizing:  448 448\n"," 66/204 [========>.....................] - ETA: 1:25 - loss: 3.7855 - yolo_layer_1_loss: 2.2838e-04 - yolo_layer_2_loss: 0.4524 - yolo_layer_3_loss: 3.3328resizing:  416 416\n"," 73/204 [=========>....................] - ETA: 1:21 - loss: 3.6520 - yolo_layer_1_loss: 2.2902e-04 - yolo_layer_2_loss: 0.4091 - yolo_layer_3_loss: 3.2427resizing:  384 384\n"," 79/204 [==========>...................] - ETA: 1:18 - loss: 3.6452 - yolo_layer_1_loss: 2.2720e-04 - yolo_layer_2_loss: 0.3782 - yolo_layer_3_loss: 3.2668resizing:  448 448\n"," 81/204 [==========>...................] - ETA: 1:17 - loss: 3.6577 - yolo_layer_1_loss: 2.2719e-04 - yolo_layer_2_loss: 0.3827 - yolo_layer_3_loss: 3.2748resizing:  384 384\n"," 89/204 [============>.................] - ETA: 1:11 - loss: 3.5792 - yolo_layer_1_loss: 2.2513e-04 - yolo_layer_2_loss: 0.3492 - yolo_layer_3_loss: 3.2299resizing:  352 352\n","101/204 [=============>................] - ETA: 1:03 - loss: 3.6127 - yolo_layer_1_loss: 2.2498e-04 - yolo_layer_2_loss: 0.3295 - yolo_layer_3_loss: 3.2830resizing:  416 416\n","104/204 [==============>...............] - ETA: 1:01 - loss: 3.5904 - yolo_layer_1_loss: 2.2545e-04 - yolo_layer_2_loss: 0.3202 - yolo_layer_3_loss: 3.2700resizing:  384 384\n","109/204 [===============>..............] - ETA: 58s - loss: 3.5649 - yolo_layer_1_loss: 2.2784e-04 - yolo_layer_2_loss: 0.3236 - yolo_layer_3_loss: 3.2411resizing:  416 416\n","129/204 [=================>............] - ETA: 45s - loss: 3.6587 - yolo_layer_1_loss: 2.2667e-04 - yolo_layer_2_loss: 0.3294 - yolo_layer_3_loss: 3.3290resizing:  416 416\n","139/204 [===================>..........] - ETA: 40s - loss: 3.5775 - yolo_layer_1_loss: 2.2709e-04 - yolo_layer_2_loss: 0.3097 - yolo_layer_3_loss: 3.2676resizing:  416 416\n","140/204 [===================>..........] - ETA: 39s - loss: 3.5713 - yolo_layer_1_loss: 2.2745e-04 - yolo_layer_2_loss: 0.3075 - yolo_layer_3_loss: 3.2636resizing:  384 384\n","159/204 [======================>.......] - ETA: 27s - loss: 3.5639 - yolo_layer_1_loss: 2.2642e-04 - yolo_layer_2_loss: 0.3148 - yolo_layer_3_loss: 3.2489resizing:  384 384\n","172/204 [========================>.....] - ETA: 19s - loss: 3.5562 - yolo_layer_1_loss: 2.2567e-04 - yolo_layer_2_loss: 0.2974 - yolo_layer_3_loss: 3.2585resizing:  416 416\n","174/204 [========================>.....] - ETA: 18s - loss: 3.5404 - yolo_layer_1_loss: 2.2545e-04 - yolo_layer_2_loss: 0.2940 - yolo_layer_3_loss: 3.2461resizing:  352 352\n","175/204 [========================>.....] - ETA: 17s - loss: 3.5404 - yolo_layer_1_loss: 2.2531e-04 - yolo_layer_2_loss: 0.2923 - yolo_layer_3_loss: 3.2478resizing:  448 448\n","177/204 [=========================>....] - ETA: 16s - loss: 3.5331 - yolo_layer_1_loss: 2.2504e-04 - yolo_layer_2_loss: 0.2890 - yolo_layer_3_loss: 3.2439resizing:  384 384\n","189/204 [==========================>...] - ETA: 9s - loss: 3.5966 - yolo_layer_1_loss: 2.2475e-04 - yolo_layer_2_loss: 0.2916 - yolo_layer_3_loss: 3.3048resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 3.5887 - yolo_layer_1_loss: 2.2344e-04 - yolo_layer_2_loss: 0.2718 - yolo_layer_3_loss: 3.3167resizing:  384 384\n","204/204 [==============================] - 123s 602ms/step - loss: 3.5813 - yolo_layer_1_loss: 2.2343e-04 - yolo_layer_2_loss: 0.2704 - yolo_layer_3_loss: 3.3106\n","\n","Epoch 00037: loss did not improve from 3.53040\n","Epoch 38/103\n","  1/204 [..............................] - ETA: 1:46 - loss: 3.4078 - yolo_layer_1_loss: 1.9924e-04 - yolo_layer_2_loss: 0.0012 - yolo_layer_3_loss: 3.4064resizing:  384 384\n"," 17/204 [=>............................] - ETA: 1:42 - loss: 3.5917 - yolo_layer_1_loss: 2.0624e-04 - yolo_layer_2_loss: 0.0660 - yolo_layer_3_loss: 3.5256resizing:  352 352\n"," 21/204 [==>...........................] - ETA: 1:40 - loss: 3.3717 - yolo_layer_1_loss: 2.0073e-04 - yolo_layer_2_loss: 0.0536 - yolo_layer_3_loss: 3.3179resizing:  448 448\n"," 25/204 [==>...........................] - ETA: 1:38 - loss: 3.2328 - yolo_layer_1_loss: 2.0250e-04 - yolo_layer_2_loss: 0.0454 - yolo_layer_3_loss: 3.1872resizing:  352 352\n"," 32/204 [===>..........................] - ETA: 1:33 - loss: 3.3118 - yolo_layer_1_loss: 2.0539e-04 - yolo_layer_2_loss: 0.1557 - yolo_layer_3_loss: 3.1559resizing:  352 352\n"," 50/204 [======>.......................] - ETA: 1:23 - loss: 3.2295 - yolo_layer_1_loss: 2.0375e-04 - yolo_layer_2_loss: 0.1529 - yolo_layer_3_loss: 3.0764resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:22 - loss: 3.2411 - yolo_layer_1_loss: 2.0376e-04 - yolo_layer_2_loss: 0.1499 - yolo_layer_3_loss: 3.0910resizing:  384 384\n"," 66/204 [========>.....................] - ETA: 1:14 - loss: 3.3594 - yolo_layer_1_loss: 2.0183e-04 - yolo_layer_2_loss: 0.1797 - yolo_layer_3_loss: 3.1795resizing:  352 352\n"," 74/204 [=========>....................] - ETA: 1:10 - loss: 3.2902 - yolo_layer_1_loss: 2.0595e-04 - yolo_layer_2_loss: 0.1604 - yolo_layer_3_loss: 3.1296resizing:  384 384\n"," 79/204 [==========>...................] - ETA: 1:07 - loss: 3.2888 - yolo_layer_1_loss: 2.0682e-04 - yolo_layer_2_loss: 0.1503 - yolo_layer_3_loss: 3.1383resizing:  384 384\n"," 81/204 [==========>...................] - ETA: 1:06 - loss: 3.2761 - yolo_layer_1_loss: 2.0662e-04 - yolo_layer_2_loss: 0.1466 - yolo_layer_3_loss: 3.1293resizing:  448 448\n","102/204 [==============>...............] - ETA: 56s - loss: 3.4245 - yolo_layer_1_loss: 2.1423e-04 - yolo_layer_2_loss: 0.1678 - yolo_layer_3_loss: 3.2565resizing:  448 448\n","103/204 [==============>...............] - ETA: 55s - loss: 3.4141 - yolo_layer_1_loss: 2.1476e-04 - yolo_layer_2_loss: 0.1759 - yolo_layer_3_loss: 3.2380resizing:  416 416\n","104/204 [==============>...............] - ETA: 55s - loss: 3.4448 - yolo_layer_1_loss: 2.1516e-04 - yolo_layer_2_loss: 0.1742 - yolo_layer_3_loss: 3.2703resizing:  448 448\n","109/204 [===============>..............] - ETA: 53s - loss: 3.4225 - yolo_layer_1_loss: 2.1899e-04 - yolo_layer_2_loss: 0.1664 - yolo_layer_3_loss: 3.2559resizing:  384 384\n","112/204 [===============>..............] - ETA: 51s - loss: 3.4282 - yolo_layer_1_loss: 2.2020e-04 - yolo_layer_2_loss: 0.1773 - yolo_layer_3_loss: 3.2507resizing:  416 416\n","130/204 [==================>...........] - ETA: 42s - loss: 3.3406 - yolo_layer_1_loss: 2.2294e-04 - yolo_layer_2_loss: 0.1725 - yolo_layer_3_loss: 3.1679resizing:  416 416\n","156/204 [=====================>........] - ETA: 28s - loss: 3.3832 - yolo_layer_1_loss: 2.2384e-04 - yolo_layer_2_loss: 0.1995 - yolo_layer_3_loss: 3.1834resizing:  448 448\n","157/204 [======================>.......] - ETA: 27s - loss: 3.4049 - yolo_layer_1_loss: 2.2386e-04 - yolo_layer_2_loss: 0.2257 - yolo_layer_3_loss: 3.1790resizing:  416 416\n","162/204 [======================>.......] - ETA: 24s - loss: 3.3858 - yolo_layer_1_loss: 2.2375e-04 - yolo_layer_2_loss: 0.2242 - yolo_layer_3_loss: 3.1614resizing:  384 384\n","168/204 [=======================>......] - ETA: 21s - loss: 3.3593 - yolo_layer_1_loss: 2.2684e-04 - yolo_layer_2_loss: 0.2234 - yolo_layer_3_loss: 3.1357resizing:  416 416\n","177/204 [=========================>....] - ETA: 16s - loss: 3.4360 - yolo_layer_1_loss: 2.2627e-04 - yolo_layer_2_loss: 0.2864 - yolo_layer_3_loss: 3.1494resizing:  384 384\n","191/204 [===========================>..] - ETA: 7s - loss: 3.3970 - yolo_layer_1_loss: 2.2670e-04 - yolo_layer_2_loss: 0.2926 - yolo_layer_3_loss: 3.1042resizing:  448 448\n","203/204 [============================>.] - ETA: 0s - loss: 3.4647 - yolo_layer_1_loss: 2.2564e-04 - yolo_layer_2_loss: 0.2789 - yolo_layer_3_loss: 3.1856resizing:  384 384\n","204/204 [==============================] - 121s 593ms/step - loss: 3.4624 - yolo_layer_1_loss: 2.2586e-04 - yolo_layer_2_loss: 0.2776 - yolo_layer_3_loss: 3.1846\n","\n","Epoch 00038: loss improved from 3.53040 to 3.46238, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 39/103\n","  4/204 [..............................] - ETA: 1:51 - loss: 3.2923 - yolo_layer_1_loss: 2.3258e-04 - yolo_layer_2_loss: 9.7461e-04 - yolo_layer_3_loss: 3.2911resizing:  416 416\n"," 12/204 [>.............................] - ETA: 1:45 - loss: 2.7501 - yolo_layer_1_loss: 2.1237e-04 - yolo_layer_2_loss: 0.0012 - yolo_layer_3_loss: 2.7487resizing:  416 416\n"," 16/204 [=>............................] - ETA: 1:46 - loss: 2.8793 - yolo_layer_1_loss: 2.1522e-04 - yolo_layer_2_loss: 0.1343 - yolo_layer_3_loss: 2.7448resizing:  384 384\n"," 25/204 [==>...........................] - ETA: 1:47 - loss: 3.1184 - yolo_layer_1_loss: 2.2048e-04 - yolo_layer_2_loss: 0.1754 - yolo_layer_3_loss: 2.9427resizing:  384 384\n"," 29/204 [===>..........................] - ETA: 1:44 - loss: 3.1310 - yolo_layer_1_loss: 2.1903e-04 - yolo_layer_2_loss: 0.1514 - yolo_layer_3_loss: 2.9794resizing:  448 448\n"," 51/204 [======>.......................] - ETA: 1:32 - loss: 3.3194 - yolo_layer_1_loss: 2.2940e-04 - yolo_layer_2_loss: 0.2889 - yolo_layer_3_loss: 3.0302resizing:  448 448\n"," 53/204 [======>.......................] - ETA: 1:32 - loss: 3.3562 - yolo_layer_1_loss: 2.3051e-04 - yolo_layer_2_loss: 0.3019 - yolo_layer_3_loss: 3.0541resizing:  352 352\n"," 64/204 [========>.....................] - ETA: 1:26 - loss: 3.3967 - yolo_layer_1_loss: 2.3487e-04 - yolo_layer_2_loss: 0.3514 - yolo_layer_3_loss: 3.0450resizing:  352 352\n"," 70/204 [=========>....................] - ETA: 1:20 - loss: 3.4187 - yolo_layer_1_loss: 2.3068e-04 - yolo_layer_2_loss: 0.3214 - yolo_layer_3_loss: 3.0971resizing:  384 384\n"," 75/204 [==========>...................] - ETA: 1:17 - loss: 3.3495 - yolo_layer_1_loss: 2.2721e-04 - yolo_layer_2_loss: 0.3000 - yolo_layer_3_loss: 3.0493resizing:  448 448\n"," 88/204 [===========>..................] - ETA: 1:08 - loss: 3.3693 - yolo_layer_1_loss: 2.2280e-04 - yolo_layer_2_loss: 0.3395 - yolo_layer_3_loss: 3.0296resizing:  448 448\n","101/204 [=============>................] - ETA: 1:02 - loss: 3.4722 - yolo_layer_1_loss: 2.3025e-04 - yolo_layer_2_loss: 0.3611 - yolo_layer_3_loss: 3.1109resizing:  448 448\n","104/204 [==============>...............] - ETA: 1:00 - loss: 3.4886 - yolo_layer_1_loss: 2.3163e-04 - yolo_layer_2_loss: 0.3963 - yolo_layer_3_loss: 3.0921resizing:  352 352\n","118/204 [================>.............] - ETA: 51s - loss: 3.4469 - yolo_layer_1_loss: 2.2986e-04 - yolo_layer_2_loss: 0.3592 - yolo_layer_3_loss: 3.0875resizing:  352 352\n","124/204 [=================>............] - ETA: 47s - loss: 3.4985 - yolo_layer_1_loss: 2.2810e-04 - yolo_layer_2_loss: 0.3525 - yolo_layer_3_loss: 3.1458resizing:  384 384\n","128/204 [=================>............] - ETA: 45s - loss: 3.4836 - yolo_layer_1_loss: 2.2645e-04 - yolo_layer_2_loss: 0.3482 - yolo_layer_3_loss: 3.1352resizing:  448 448\n","136/204 [===================>..........] - ETA: 39s - loss: 3.5218 - yolo_layer_1_loss: 2.2412e-04 - yolo_layer_2_loss: 0.3356 - yolo_layer_3_loss: 3.1859resizing:  352 352\n","157/204 [======================>.......] - ETA: 27s - loss: 3.5340 - yolo_layer_1_loss: 2.2381e-04 - yolo_layer_2_loss: 0.2910 - yolo_layer_3_loss: 3.2427resizing:  416 416\n","167/204 [=======================>......] - ETA: 21s - loss: 3.5374 - yolo_layer_1_loss: 2.2260e-04 - yolo_layer_2_loss: 0.2736 - yolo_layer_3_loss: 3.2635resizing:  352 352\n","172/204 [========================>.....] - ETA: 18s - loss: 3.5235 - yolo_layer_1_loss: 2.2245e-04 - yolo_layer_2_loss: 0.2733 - yolo_layer_3_loss: 3.2500resizing:  416 416\n","179/204 [=========================>....] - ETA: 14s - loss: 3.4797 - yolo_layer_1_loss: 2.2190e-04 - yolo_layer_2_loss: 0.2661 - yolo_layer_3_loss: 3.2133resizing:  352 352\n","180/204 [=========================>....] - ETA: 14s - loss: 3.4740 - yolo_layer_1_loss: 2.2169e-04 - yolo_layer_2_loss: 0.2647 - yolo_layer_3_loss: 3.2091resizing:  416 416\n","192/204 [===========================>..] - ETA: 7s - loss: 3.4343 - yolo_layer_1_loss: 2.2162e-04 - yolo_layer_2_loss: 0.2688 - yolo_layer_3_loss: 3.1653resizing:  384 384\n","204/204 [==============================] - 121s 591ms/step - loss: 3.3912 - yolo_layer_1_loss: 2.2162e-04 - yolo_layer_2_loss: 0.2566 - yolo_layer_3_loss: 3.1344\n","\n","Epoch 00039: loss improved from 3.46238 to 3.39124, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 40/103\n"," 20/204 [=>............................] - ETA: 1:41 - loss: 3.0687 - yolo_layer_1_loss: 2.0583e-04 - yolo_layer_2_loss: 0.0416 - yolo_layer_3_loss: 3.0269resizing:  416 416\n"," 21/204 [==>...........................] - ETA: 1:40 - loss: 3.3406 - yolo_layer_1_loss: 2.0528e-04 - yolo_layer_2_loss: 0.1725 - yolo_layer_3_loss: 3.1680resizing:  448 448\n"," 22/204 [==>...........................] - ETA: 1:40 - loss: 3.2708 - yolo_layer_1_loss: 2.0371e-04 - yolo_layer_2_loss: 0.1647 - yolo_layer_3_loss: 3.1059resizing:  448 448\n"," 27/204 [==>...........................] - ETA: 1:37 - loss: 3.3427 - yolo_layer_1_loss: 2.0153e-04 - yolo_layer_2_loss: 0.1344 - yolo_layer_3_loss: 3.2081resizing:  384 384\n"," 34/204 [====>.........................] - ETA: 1:35 - loss: 3.3478 - yolo_layer_1_loss: 2.0797e-04 - yolo_layer_2_loss: 0.1386 - yolo_layer_3_loss: 3.2090resizing:  416 416\n"," 39/204 [====>.........................] - ETA: 1:34 - loss: 3.2120 - yolo_layer_1_loss: 2.1200e-04 - yolo_layer_2_loss: 0.1442 - yolo_layer_3_loss: 3.0676resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:28 - loss: 3.1911 - yolo_layer_1_loss: 2.1135e-04 - yolo_layer_2_loss: 0.1105 - yolo_layer_3_loss: 3.0803resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:25 - loss: 3.2131 - yolo_layer_1_loss: 2.1233e-04 - yolo_layer_2_loss: 0.1231 - yolo_layer_3_loss: 3.0898resizing:  384 384\n"," 69/204 [=========>....................] - ETA: 1:17 - loss: 3.2981 - yolo_layer_1_loss: 2.0927e-04 - yolo_layer_2_loss: 0.1158 - yolo_layer_3_loss: 3.1821resizing:  416 416\n"," 78/204 [==========>...................] - ETA: 1:11 - loss: 3.3149 - yolo_layer_1_loss: 2.0774e-04 - yolo_layer_2_loss: 0.1025 - yolo_layer_3_loss: 3.2122resizing:  352 352\n"," 80/204 [==========>...................] - ETA: 1:10 - loss: 3.2889 - yolo_layer_1_loss: 2.0704e-04 - yolo_layer_2_loss: 0.1000 - yolo_layer_3_loss: 3.1887resizing:  384 384\n"," 82/204 [===========>..................] - ETA: 1:09 - loss: 3.2819 - yolo_layer_1_loss: 2.0697e-04 - yolo_layer_2_loss: 0.0976 - yolo_layer_3_loss: 3.1841resizing:  448 448\n","101/204 [=============>................] - ETA: 1:00 - loss: 3.4289 - yolo_layer_1_loss: 2.1516e-04 - yolo_layer_2_loss: 0.2514 - yolo_layer_3_loss: 3.1772resizing:  384 384\n","112/204 [===============>..............] - ETA: 53s - loss: 3.3648 - yolo_layer_1_loss: 2.1499e-04 - yolo_layer_2_loss: 0.2268 - yolo_layer_3_loss: 3.1377resizing:  448 448\n","117/204 [================>.............] - ETA: 50s - loss: 3.4492 - yolo_layer_1_loss: 2.1422e-04 - yolo_layer_2_loss: 0.2339 - yolo_layer_3_loss: 3.2151resizing:  384 384\n","122/204 [================>.............] - ETA: 47s - loss: 3.4536 - yolo_layer_1_loss: 2.1328e-04 - yolo_layer_2_loss: 0.2482 - yolo_layer_3_loss: 3.2052resizing:  352 352\n","127/204 [=================>............] - ETA: 44s - loss: 3.4321 - yolo_layer_1_loss: 2.1630e-04 - yolo_layer_2_loss: 0.2385 - yolo_layer_3_loss: 3.1933resizing:  448 448\n","141/204 [===================>..........] - ETA: 36s - loss: 3.4523 - yolo_layer_1_loss: 2.1653e-04 - yolo_layer_2_loss: 0.2336 - yolo_layer_3_loss: 3.2185resizing:  448 448\n","158/204 [======================>.......] - ETA: 27s - loss: 3.4961 - yolo_layer_1_loss: 2.2092e-04 - yolo_layer_2_loss: 0.2527 - yolo_layer_3_loss: 3.2432resizing:  416 416\n","165/204 [=======================>......] - ETA: 23s - loss: 3.4658 - yolo_layer_1_loss: 2.2280e-04 - yolo_layer_2_loss: 0.2420 - yolo_layer_3_loss: 3.2236resizing:  384 384\n","169/204 [=======================>......] - ETA: 21s - loss: 3.4506 - yolo_layer_1_loss: 2.2355e-04 - yolo_layer_2_loss: 0.2546 - yolo_layer_3_loss: 3.1958resizing:  448 448\n","177/204 [=========================>....] - ETA: 16s - loss: 3.4112 - yolo_layer_1_loss: 2.2288e-04 - yolo_layer_2_loss: 0.2467 - yolo_layer_3_loss: 3.1643resizing:  352 352\n","183/204 [=========================>....] - ETA: 12s - loss: 3.4182 - yolo_layer_1_loss: 2.2297e-04 - yolo_layer_2_loss: 0.2553 - yolo_layer_3_loss: 3.1627resizing:  448 448\n","192/204 [===========================>..] - ETA: 7s - loss: 3.4368 - yolo_layer_1_loss: 2.2343e-04 - yolo_layer_2_loss: 0.2494 - yolo_layer_3_loss: 3.1872resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 3.4489 - yolo_layer_1_loss: 2.2509e-04 - yolo_layer_2_loss: 0.2574 - yolo_layer_3_loss: 3.1913resizing:  384 384\n","204/204 [==============================] - 124s 608ms/step - loss: 3.4489 - yolo_layer_1_loss: 2.2510e-04 - yolo_layer_2_loss: 0.2595 - yolo_layer_3_loss: 3.1891\n","\n","Epoch 00040: loss did not improve from 3.39124\n","Epoch 41/103\n","resizing:  448 448\n","resizing:  352 352\n","  7/204 [>.............................] - ETA: 1:50 - loss: 3.4252 - yolo_layer_1_loss: 2.0202e-04 - yolo_layer_2_loss: 0.0015 - yolo_layer_3_loss: 3.4235resizing:  384 384\n"," 11/204 [>.............................] - ETA: 1:44 - loss: 3.7690 - yolo_layer_1_loss: 2.0782e-04 - yolo_layer_2_loss: 0.0098 - yolo_layer_3_loss: 3.7589resizing:  448 448\n"," 26/204 [==>...........................] - ETA: 1:39 - loss: 3.4469 - yolo_layer_1_loss: 2.1296e-04 - yolo_layer_2_loss: 0.1689 - yolo_layer_3_loss: 3.2778resizing:  416 416\n"," 52/204 [======>.......................] - ETA: 1:33 - loss: 3.1554 - yolo_layer_1_loss: 2.2390e-04 - yolo_layer_2_loss: 0.2512 - yolo_layer_3_loss: 2.9040resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:32 - loss: 3.2231 - yolo_layer_1_loss: 2.2320e-04 - yolo_layer_2_loss: 0.2708 - yolo_layer_3_loss: 2.9521resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:28 - loss: 3.1710 - yolo_layer_1_loss: 2.2923e-04 - yolo_layer_2_loss: 0.2362 - yolo_layer_3_loss: 2.9346resizing:  384 384\n"," 64/204 [========>.....................] - ETA: 1:26 - loss: 3.1296 - yolo_layer_1_loss: 2.2789e-04 - yolo_layer_2_loss: 0.2288 - yolo_layer_3_loss: 2.9006resizing:  416 416\n"," 66/204 [========>.....................] - ETA: 1:25 - loss: 3.1111 - yolo_layer_1_loss: 2.2699e-04 - yolo_layer_2_loss: 0.2219 - yolo_layer_3_loss: 2.8890resizing:  448 448\n"," 70/204 [=========>....................] - ETA: 1:22 - loss: 3.0877 - yolo_layer_1_loss: 2.2502e-04 - yolo_layer_2_loss: 0.2247 - yolo_layer_3_loss: 2.8628resizing:  416 416\n","101/204 [=============>................] - ETA: 1:03 - loss: 3.2226 - yolo_layer_1_loss: 2.2499e-04 - yolo_layer_2_loss: 0.2391 - yolo_layer_3_loss: 2.9833resizing:  352 352\n","resizing:  448 448\n","103/204 [==============>...............] - ETA: 1:02 - loss: 3.2200 - yolo_layer_1_loss: 2.2473e-04 - yolo_layer_2_loss: 0.2383 - yolo_layer_3_loss: 2.9815resizing:  416 416\n","108/204 [==============>...............] - ETA: 59s - loss: 3.2330 - yolo_layer_1_loss: 2.2690e-04 - yolo_layer_2_loss: 0.2381 - yolo_layer_3_loss: 2.9947 resizing:  384 384\n","113/204 [===============>..............] - ETA: 56s - loss: 3.1913 - yolo_layer_1_loss: 2.2739e-04 - yolo_layer_2_loss: 0.2349 - yolo_layer_3_loss: 2.9562resizing:  384 384\n","117/204 [================>.............] - ETA: 54s - loss: 3.1856 - yolo_layer_1_loss: 2.2724e-04 - yolo_layer_2_loss: 0.2269 - yolo_layer_3_loss: 2.9585resizing:  352 352\n","156/204 [=====================>........] - ETA: 28s - loss: 3.3234 - yolo_layer_1_loss: 2.1701e-04 - yolo_layer_2_loss: 0.2405 - yolo_layer_3_loss: 3.0828resizing:  384 384\n","161/204 [======================>.......] - ETA: 25s - loss: 3.3400 - yolo_layer_1_loss: 2.1570e-04 - yolo_layer_2_loss: 0.2331 - yolo_layer_3_loss: 3.1067resizing:  416 416\n","162/204 [======================>.......] - ETA: 24s - loss: 3.3320 - yolo_layer_1_loss: 2.1633e-04 - yolo_layer_2_loss: 0.2316 - yolo_layer_3_loss: 3.1001resizing:  352 352\n","169/204 [=======================>......] - ETA: 20s - loss: 3.3104 - yolo_layer_1_loss: 2.1496e-04 - yolo_layer_2_loss: 0.2221 - yolo_layer_3_loss: 3.0881resizing:  384 384\n","170/204 [========================>.....] - ETA: 20s - loss: 3.3000 - yolo_layer_1_loss: 2.1469e-04 - yolo_layer_2_loss: 0.2208 - yolo_layer_3_loss: 3.0790resizing:  416 416\n","183/204 [=========================>....] - ETA: 12s - loss: 3.2890 - yolo_layer_1_loss: 2.1343e-04 - yolo_layer_2_loss: 0.2097 - yolo_layer_3_loss: 3.0791resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 3.3217 - yolo_layer_1_loss: 2.1541e-04 - yolo_layer_2_loss: 0.2060 - yolo_layer_3_loss: 3.1155resizing:  384 384\n","204/204 [==============================] - 121s 592ms/step - loss: 3.3230 - yolo_layer_1_loss: 2.1552e-04 - yolo_layer_2_loss: 0.2050 - yolo_layer_3_loss: 3.1177\n","\n","Epoch 00041: loss improved from 3.39124 to 3.32299, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 42/103\n","  4/204 [..............................] - ETA: 1:57 - loss: 2.5916 - yolo_layer_1_loss: 1.8240e-04 - yolo_layer_2_loss: 0.1926 - yolo_layer_3_loss: 2.3988resizing:  448 448\n"," 19/204 [=>............................] - ETA: 1:53 - loss: 3.3485 - yolo_layer_1_loss: 2.0890e-04 - yolo_layer_2_loss: 0.1393 - yolo_layer_3_loss: 3.2090resizing:  352 352\n"," 27/204 [==>...........................] - ETA: 1:53 - loss: 3.2701 - yolo_layer_1_loss: 2.2569e-04 - yolo_layer_2_loss: 0.1234 - yolo_layer_3_loss: 3.1465resizing:  352 352\n"," 34/204 [====>.........................] - ETA: 1:47 - loss: 3.4518 - yolo_layer_1_loss: 2.2203e-04 - yolo_layer_2_loss: 0.1411 - yolo_layer_3_loss: 3.3105resizing:  416 416\n"," 38/204 [====>.........................] - ETA: 1:42 - loss: 3.4219 - yolo_layer_1_loss: 2.1858e-04 - yolo_layer_2_loss: 0.1536 - yolo_layer_3_loss: 3.2681resizing:  448 448\n"," 50/204 [======>.......................] - ETA: 1:32 - loss: 3.3660 - yolo_layer_1_loss: 2.1504e-04 - yolo_layer_2_loss: 0.1692 - yolo_layer_3_loss: 3.1966resizing:  448 448\n"," 51/204 [======>.......................] - ETA: 1:32 - loss: 3.4164 - yolo_layer_1_loss: 2.1660e-04 - yolo_layer_2_loss: 0.1659 - yolo_layer_3_loss: 3.2502resizing:  384 384\n"," 52/204 [======>.......................] - ETA: 1:31 - loss: 3.3944 - yolo_layer_1_loss: 2.1777e-04 - yolo_layer_2_loss: 0.1628 - yolo_layer_3_loss: 3.2314resizing:  416 416\n"," 53/204 [======>.......................] - ETA: 1:31 - loss: 3.4149 - yolo_layer_1_loss: 2.1812e-04 - yolo_layer_2_loss: 0.1597 - yolo_layer_3_loss: 3.2549resizing:  384 384\n"," 69/204 [=========>....................] - ETA: 1:21 - loss: 3.4946 - yolo_layer_1_loss: 2.1392e-04 - yolo_layer_2_loss: 0.1324 - yolo_layer_3_loss: 3.3620resizing:  384 384\n"," 80/204 [==========>...................] - ETA: 1:13 - loss: 3.5728 - yolo_layer_1_loss: 2.1145e-04 - yolo_layer_2_loss: 0.1639 - yolo_layer_3_loss: 3.4087resizing:  384 384\n","105/204 [==============>...............] - ETA: 57s - loss: 3.5030 - yolo_layer_1_loss: 2.0843e-04 - yolo_layer_2_loss: 0.1539 - yolo_layer_3_loss: 3.3489resizing:  384 384\n","108/204 [==============>...............] - ETA: 55s - loss: 3.5114 - yolo_layer_1_loss: 2.0857e-04 - yolo_layer_2_loss: 0.1497 - yolo_layer_3_loss: 3.3616resizing:  352 352\n","109/204 [===============>..............] - ETA: 54s - loss: 3.5168 - yolo_layer_1_loss: 2.0830e-04 - yolo_layer_2_loss: 0.1483 - yolo_layer_3_loss: 3.3683resizing:  448 448\n","114/204 [===============>..............] - ETA: 51s - loss: 3.4650 - yolo_layer_1_loss: 2.0711e-04 - yolo_layer_2_loss: 0.1418 - yolo_layer_3_loss: 3.3230resizing:  448 448\n","133/204 [==================>...........] - ETA: 41s - loss: 3.3976 - yolo_layer_1_loss: 2.1284e-04 - yolo_layer_2_loss: 0.1500 - yolo_layer_3_loss: 3.2474resizing:  448 448\n","141/204 [===================>..........] - ETA: 37s - loss: 3.3328 - yolo_layer_1_loss: 2.1444e-04 - yolo_layer_2_loss: 0.1550 - yolo_layer_3_loss: 3.1776resizing:  352 352\n","152/204 [=====================>........] - ETA: 31s - loss: 3.3476 - yolo_layer_1_loss: 2.1747e-04 - yolo_layer_2_loss: 0.1873 - yolo_layer_3_loss: 3.1601resizing:  448 448\n","159/204 [======================>.......] - ETA: 27s - loss: 3.3703 - yolo_layer_1_loss: 2.1868e-04 - yolo_layer_2_loss: 0.2133 - yolo_layer_3_loss: 3.1568resizing:  416 416\n","166/204 [=======================>......] - ETA: 23s - loss: 3.4486 - yolo_layer_1_loss: 2.2166e-04 - yolo_layer_2_loss: 0.2667 - yolo_layer_3_loss: 3.1817resizing:  416 416\n","173/204 [========================>.....] - ETA: 18s - loss: 3.4593 - yolo_layer_1_loss: 2.2187e-04 - yolo_layer_2_loss: 0.2662 - yolo_layer_3_loss: 3.1929resizing:  384 384\n","180/204 [=========================>....] - ETA: 14s - loss: 3.4232 - yolo_layer_1_loss: 2.2165e-04 - yolo_layer_2_loss: 0.2559 - yolo_layer_3_loss: 3.1670resizing:  384 384\n","186/204 [==========================>...] - ETA: 11s - loss: 3.4118 - yolo_layer_1_loss: 2.2057e-04 - yolo_layer_2_loss: 0.2514 - yolo_layer_3_loss: 3.1602resizing:  448 448\n","204/204 [==============================] - 125s 611ms/step - loss: 3.4387 - yolo_layer_1_loss: 2.2100e-04 - yolo_layer_2_loss: 0.2521 - yolo_layer_3_loss: 3.1864\n","\n","Epoch 00042: loss did not improve from 3.32299\n","Epoch 43/103\n","resizing:  448 448\n","  5/204 [..............................] - ETA: 2:21 - loss: 3.1092 - yolo_layer_1_loss: 2.6164e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 3.1078resizing:  384 384\n"," 13/204 [>.............................] - ETA: 2:15 - loss: 3.0693 - yolo_layer_1_loss: 2.5752e-04 - yolo_layer_2_loss: 0.3205 - yolo_layer_3_loss: 2.7485resizing:  416 416\n"," 20/204 [=>............................] - ETA: 2:02 - loss: 3.1868 - yolo_layer_1_loss: 2.4339e-04 - yolo_layer_2_loss: 0.2087 - yolo_layer_3_loss: 2.9779resizing:  448 448\n"," 21/204 [==>...........................] - ETA: 2:00 - loss: 3.1634 - yolo_layer_1_loss: 2.4072e-04 - yolo_layer_2_loss: 0.2412 - yolo_layer_3_loss: 2.9219resizing:  352 352\n"," 32/204 [===>..........................] - ETA: 1:51 - loss: 3.0788 - yolo_layer_1_loss: 2.3224e-04 - yolo_layer_2_loss: 0.1851 - yolo_layer_3_loss: 2.8935resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:26 - loss: 3.1511 - yolo_layer_1_loss: 2.2144e-04 - yolo_layer_2_loss: 0.1448 - yolo_layer_3_loss: 3.0061resizing:  352 352\n"," 67/204 [========>.....................] - ETA: 1:25 - loss: 3.1363 - yolo_layer_1_loss: 2.2210e-04 - yolo_layer_2_loss: 0.1405 - yolo_layer_3_loss: 2.9956resizing:  352 352\n"," 69/204 [=========>....................] - ETA: 1:24 - loss: 3.1715 - yolo_layer_1_loss: 2.2245e-04 - yolo_layer_2_loss: 0.1365 - yolo_layer_3_loss: 3.0348resizing:  384 384\n"," 84/204 [===========>..................] - ETA: 1:13 - loss: 3.2510 - yolo_layer_1_loss: 2.1874e-04 - yolo_layer_2_loss: 0.2214 - yolo_layer_3_loss: 3.0294resizing:  448 448\n"," 86/204 [===========>..................] - ETA: 1:12 - loss: 3.2472 - yolo_layer_1_loss: 2.1804e-04 - yolo_layer_2_loss: 0.2163 - yolo_layer_3_loss: 3.0307resizing:  384 384\n"," 89/204 [============>.................] - ETA: 1:10 - loss: 3.1999 - yolo_layer_1_loss: 2.1709e-04 - yolo_layer_2_loss: 0.2090 - yolo_layer_3_loss: 2.9906resizing:  352 352\n","109/204 [===============>..............] - ETA: 56s - loss: 3.2917 - yolo_layer_1_loss: 2.1437e-04 - yolo_layer_2_loss: 0.1709 - yolo_layer_3_loss: 3.1205resizing:  384 384\n","113/204 [===============>..............] - ETA: 53s - loss: 3.2806 - yolo_layer_1_loss: 2.1278e-04 - yolo_layer_2_loss: 0.1649 - yolo_layer_3_loss: 3.1155resizing:  384 384\n","115/204 [===============>..............] - ETA: 52s - loss: 3.3097 - yolo_layer_1_loss: 2.1226e-04 - yolo_layer_2_loss: 0.1620 - yolo_layer_3_loss: 3.1474resizing:  416 416\n","117/204 [================>.............] - ETA: 51s - loss: 3.3203 - yolo_layer_1_loss: 2.1162e-04 - yolo_layer_2_loss: 0.1696 - yolo_layer_3_loss: 3.1505resizing:  352 352\n","138/204 [===================>..........] - ETA: 38s - loss: 3.3541 - yolo_layer_1_loss: 2.0764e-04 - yolo_layer_2_loss: 0.1464 - yolo_layer_3_loss: 3.2074resizing:  384 384\n","140/204 [===================>..........] - ETA: 37s - loss: 3.3431 - yolo_layer_1_loss: 2.0717e-04 - yolo_layer_2_loss: 0.1444 - yolo_layer_3_loss: 3.1985resizing:  448 448\n","154/204 [=====================>........] - ETA: 28s - loss: 3.3527 - yolo_layer_1_loss: 2.0648e-04 - yolo_layer_2_loss: 0.1378 - yolo_layer_3_loss: 3.2148resizing:  416 416\n","157/204 [======================>.......] - ETA: 27s - loss: 3.3549 - yolo_layer_1_loss: 2.0773e-04 - yolo_layer_2_loss: 0.1399 - yolo_layer_3_loss: 3.2148resizing:  416 416\n","158/204 [======================>.......] - ETA: 26s - loss: 3.3485 - yolo_layer_1_loss: 2.0780e-04 - yolo_layer_2_loss: 0.1390 - yolo_layer_3_loss: 3.2093resizing:  384 384\n","160/204 [======================>.......] - ETA: 25s - loss: 3.3415 - yolo_layer_1_loss: 2.0784e-04 - yolo_layer_2_loss: 0.1373 - yolo_layer_3_loss: 3.2040resizing:  416 416\n","163/204 [======================>.......] - ETA: 23s - loss: 3.3254 - yolo_layer_1_loss: 2.0789e-04 - yolo_layer_2_loss: 0.1453 - yolo_layer_3_loss: 3.1800resizing:  448 448\n","176/204 [========================>.....] - ETA: 16s - loss: 3.3572 - yolo_layer_1_loss: 2.0843e-04 - yolo_layer_2_loss: 0.1422 - yolo_layer_3_loss: 3.2148resizing:  384 384\n","204/204 [==============================] - 120s 587ms/step - loss: 3.3472 - yolo_layer_1_loss: 2.0942e-04 - yolo_layer_2_loss: 0.1614 - yolo_layer_3_loss: 3.1856\n","\n","Epoch 00043: loss did not improve from 3.32299\n","Epoch 44/103\n","resizing:  352 352\n","  5/204 [..............................] - ETA: 1:45 - loss: 2.8604 - yolo_layer_1_loss: 1.7943e-04 - yolo_layer_2_loss: 8.8644e-04 - yolo_layer_3_loss: 2.8593resizing:  384 384\n"," 19/204 [=>............................] - ETA: 1:36 - loss: 2.8848 - yolo_layer_1_loss: 1.8315e-04 - yolo_layer_2_loss: 0.1120 - yolo_layer_3_loss: 2.7726resizing:  384 384\n"," 24/204 [==>...........................] - ETA: 1:34 - loss: 2.9493 - yolo_layer_1_loss: 1.8566e-04 - yolo_layer_2_loss: 0.0888 - yolo_layer_3_loss: 2.8602resizing:  448 448\n"," 26/204 [==>...........................] - ETA: 1:34 - loss: 2.8751 - yolo_layer_1_loss: 1.8482e-04 - yolo_layer_2_loss: 0.0821 - yolo_layer_3_loss: 2.7929resizing:  384 384\n"," 29/204 [===>..........................] - ETA: 1:32 - loss: 3.1265 - yolo_layer_1_loss: 1.8504e-04 - yolo_layer_2_loss: 0.0741 - yolo_layer_3_loss: 3.0523resizing:  352 352\n"," 53/204 [======>.......................] - ETA: 1:19 - loss: 3.5143 - yolo_layer_1_loss: 1.8813e-04 - yolo_layer_2_loss: 0.1447 - yolo_layer_3_loss: 3.3694resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:17 - loss: 3.5207 - yolo_layer_1_loss: 1.8882e-04 - yolo_layer_2_loss: 0.1347 - yolo_layer_3_loss: 3.3859resizing:  416 416\n"," 58/204 [=======>......................] - ETA: 1:16 - loss: 3.4927 - yolo_layer_1_loss: 1.8940e-04 - yolo_layer_2_loss: 0.1323 - yolo_layer_3_loss: 3.3601resizing:  384 384\n"," 60/204 [=======>......................] - ETA: 1:15 - loss: 3.4452 - yolo_layer_1_loss: 1.8910e-04 - yolo_layer_2_loss: 0.1282 - yolo_layer_3_loss: 3.3168resizing:  352 352\n"," 63/204 [========>.....................] - ETA: 1:13 - loss: 3.4157 - yolo_layer_1_loss: 1.8885e-04 - yolo_layer_2_loss: 0.1221 - yolo_layer_3_loss: 3.2934resizing:  448 448\n"," 88/204 [===========>..................] - ETA: 1:04 - loss: 3.3923 - yolo_layer_1_loss: 2.0050e-04 - yolo_layer_2_loss: 0.1575 - yolo_layer_3_loss: 3.2345resizing:  448 448\n","101/204 [=============>................] - ETA: 59s - loss: 3.3936 - yolo_layer_1_loss: 2.0704e-04 - yolo_layer_2_loss: 0.1630 - yolo_layer_3_loss: 3.2304resizing:  416 416\n","102/204 [==============>...............] - ETA: 58s - loss: 3.3830 - yolo_layer_1_loss: 2.0725e-04 - yolo_layer_2_loss: 0.1614 - yolo_layer_3_loss: 3.2214resizing:  384 384\n","108/204 [==============>...............] - ETA: 55s - loss: 3.3378 - yolo_layer_1_loss: 2.0833e-04 - yolo_layer_2_loss: 0.1624 - yolo_layer_3_loss: 3.1752resizing:  448 448\n","120/204 [================>.............] - ETA: 48s - loss: 3.2891 - yolo_layer_1_loss: 2.0915e-04 - yolo_layer_2_loss: 0.1535 - yolo_layer_3_loss: 3.1353resizing:  352 352\n","124/204 [=================>............] - ETA: 46s - loss: 3.2770 - yolo_layer_1_loss: 2.1010e-04 - yolo_layer_2_loss: 0.1628 - yolo_layer_3_loss: 3.1140resizing:  384 384\n","132/204 [==================>...........] - ETA: 42s - loss: 3.2179 - yolo_layer_1_loss: 2.1181e-04 - yolo_layer_2_loss: 0.1635 - yolo_layer_3_loss: 3.0542resizing:  384 384\n","154/204 [=====================>........] - ETA: 28s - loss: 3.2940 - yolo_layer_1_loss: 2.0882e-04 - yolo_layer_2_loss: 0.1937 - yolo_layer_3_loss: 3.1002resizing:  448 448\n","156/204 [=====================>........] - ETA: 27s - loss: 3.2792 - yolo_layer_1_loss: 2.0902e-04 - yolo_layer_2_loss: 0.1912 - yolo_layer_3_loss: 3.0877resizing:  416 416\n","160/204 [======================>.......] - ETA: 25s - loss: 3.2823 - yolo_layer_1_loss: 2.0932e-04 - yolo_layer_2_loss: 0.1917 - yolo_layer_3_loss: 3.0904resizing:  416 416\n","170/204 [========================>.....] - ETA: 19s - loss: 3.2418 - yolo_layer_1_loss: 2.0945e-04 - yolo_layer_2_loss: 0.1905 - yolo_layer_3_loss: 3.0512resizing:  416 416\n","173/204 [========================>.....] - ETA: 18s - loss: 3.2243 - yolo_layer_1_loss: 2.0965e-04 - yolo_layer_2_loss: 0.1938 - yolo_layer_3_loss: 3.0302resizing:  448 448\n","189/204 [==========================>...] - ETA: 8s - loss: 3.2609 - yolo_layer_1_loss: 2.1124e-04 - yolo_layer_2_loss: 0.2254 - yolo_layer_3_loss: 3.0353resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 3.2766 - yolo_layer_1_loss: 2.1338e-04 - yolo_layer_2_loss: 0.2334 - yolo_layer_3_loss: 3.0429resizing:  384 384\n","204/204 [==============================] - 122s 597ms/step - loss: 3.2718 - yolo_layer_1_loss: 2.1316e-04 - yolo_layer_2_loss: 0.2323 - yolo_layer_3_loss: 3.0392\n","\n","Epoch 00044: loss improved from 3.32299 to 3.27175, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","resizing:  384 384\n","Epoch 45/103\n"," 10/204 [>.............................] - ETA: 1:47 - loss: 2.9004 - yolo_layer_1_loss: 1.9192e-04 - yolo_layer_2_loss: 0.0497 - yolo_layer_3_loss: 2.8505resizing:  352 352\n"," 19/204 [=>............................] - ETA: 1:41 - loss: 3.1151 - yolo_layer_1_loss: 1.9097e-04 - yolo_layer_2_loss: 0.0265 - yolo_layer_3_loss: 3.0884resizing:  416 416\n"," 33/204 [===>..........................] - ETA: 1:33 - loss: 3.6355 - yolo_layer_1_loss: 1.9378e-04 - yolo_layer_2_loss: 0.0851 - yolo_layer_3_loss: 3.5502resizing:  416 416\n"," 37/204 [====>.........................] - ETA: 1:33 - loss: 3.6391 - yolo_layer_1_loss: 1.9509e-04 - yolo_layer_2_loss: 0.1328 - yolo_layer_3_loss: 3.5062resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:27 - loss: 3.3632 - yolo_layer_1_loss: 1.9675e-04 - yolo_layer_2_loss: 0.2006 - yolo_layer_3_loss: 3.1624resizing:  416 416\n"," 66/204 [========>.....................] - ETA: 1:21 - loss: 3.4432 - yolo_layer_1_loss: 1.9941e-04 - yolo_layer_2_loss: 0.1907 - yolo_layer_3_loss: 3.2522resizing:  416 416\n"," 71/204 [=========>....................] - ETA: 1:18 - loss: 3.4487 - yolo_layer_1_loss: 2.0288e-04 - yolo_layer_2_loss: 0.1966 - yolo_layer_3_loss: 3.2519resizing:  352 352\n"," 82/204 [===========>..................] - ETA: 1:13 - loss: 3.5192 - yolo_layer_1_loss: 2.0525e-04 - yolo_layer_2_loss: 0.2075 - yolo_layer_3_loss: 3.3115resizing:  352 352\n"," 83/204 [===========>..................] - ETA: 1:12 - loss: 3.5212 - yolo_layer_1_loss: 2.0477e-04 - yolo_layer_2_loss: 0.2050 - yolo_layer_3_loss: 3.3160resizing:  352 352\n"," 86/204 [===========>..................] - ETA: 1:10 - loss: 3.4907 - yolo_layer_1_loss: 2.0349e-04 - yolo_layer_2_loss: 0.1979 - yolo_layer_3_loss: 3.2926resizing:  352 352\n","105/204 [==============>...............] - ETA: 57s - loss: 3.5428 - yolo_layer_1_loss: 1.9828e-04 - yolo_layer_2_loss: 0.1688 - yolo_layer_3_loss: 3.3738resizing:  448 448\n","112/204 [===============>..............] - ETA: 52s - loss: 3.4872 - yolo_layer_1_loss: 2.0231e-04 - yolo_layer_2_loss: 0.1583 - yolo_layer_3_loss: 3.3287resizing:  352 352\n","120/204 [================>.............] - ETA: 49s - loss: 3.4938 - yolo_layer_1_loss: 2.0792e-04 - yolo_layer_2_loss: 0.1606 - yolo_layer_3_loss: 3.3330resizing:  448 448\n","124/204 [=================>............] - ETA: 46s - loss: 3.4629 - yolo_layer_1_loss: 2.0758e-04 - yolo_layer_2_loss: 0.1555 - yolo_layer_3_loss: 3.3072resizing:  448 448\n","128/204 [=================>............] - ETA: 44s - loss: 3.4618 - yolo_layer_1_loss: 2.0739e-04 - yolo_layer_2_loss: 0.1506 - yolo_layer_3_loss: 3.3109resizing:  448 448\n","139/204 [===================>..........] - ETA: 38s - loss: 3.4406 - yolo_layer_1_loss: 2.0828e-04 - yolo_layer_2_loss: 0.1482 - yolo_layer_3_loss: 3.2922resizing:  384 384\n","153/204 [=====================>........] - ETA: 30s - loss: 3.3966 - yolo_layer_1_loss: 2.1115e-04 - yolo_layer_2_loss: 0.1518 - yolo_layer_3_loss: 3.2446resizing:  352 352\n","154/204 [=====================>........] - ETA: 29s - loss: 3.4100 - yolo_layer_1_loss: 2.1126e-04 - yolo_layer_2_loss: 0.1508 - yolo_layer_3_loss: 3.2590resizing:  384 384\n","157/204 [======================>.......] - ETA: 27s - loss: 3.4201 - yolo_layer_1_loss: 2.1043e-04 - yolo_layer_2_loss: 0.1479 - yolo_layer_3_loss: 3.2720resizing:  352 352\n","171/204 [========================>.....] - ETA: 19s - loss: 3.4236 - yolo_layer_1_loss: 2.0769e-04 - yolo_layer_2_loss: 0.1456 - yolo_layer_3_loss: 3.2778resizing:  448 448\n","180/204 [=========================>....] - ETA: 13s - loss: 3.4363 - yolo_layer_1_loss: 2.0553e-04 - yolo_layer_2_loss: 0.1480 - yolo_layer_3_loss: 3.2881resizing:  384 384\n","184/204 [==========================>...] - ETA: 11s - loss: 3.4326 - yolo_layer_1_loss: 2.0569e-04 - yolo_layer_2_loss: 0.1517 - yolo_layer_3_loss: 3.2807resizing:  416 416\n","204/204 [==============================] - 120s 589ms/step - loss: 3.3510 - yolo_layer_1_loss: 2.0687e-04 - yolo_layer_2_loss: 0.1476 - yolo_layer_3_loss: 3.2032\n","\n","Epoch 00045: loss did not improve from 3.27175\n","Epoch 46/103\n","resizing:  448 448\n","  2/204 [..............................] - ETA: 2:11 - loss: 3.2884 - yolo_layer_1_loss: 1.9422e-04 - yolo_layer_2_loss: 8.1257e-04 - yolo_layer_3_loss: 3.2874resizing:  384 384\n","  3/204 [..............................] - ETA: 2:10 - loss: 2.6858 - yolo_layer_1_loss: 1.9617e-04 - yolo_layer_2_loss: 7.8927e-04 - yolo_layer_3_loss: 2.6848resizing:  352 352\n"," 19/204 [=>............................] - ETA: 1:46 - loss: 3.5148 - yolo_layer_1_loss: 2.0226e-04 - yolo_layer_2_loss: 0.1515 - yolo_layer_3_loss: 3.3632resizing:  352 352\n"," 20/204 [=>............................] - ETA: 1:44 - loss: 3.4833 - yolo_layer_1_loss: 1.9983e-04 - yolo_layer_2_loss: 0.1439 - yolo_layer_3_loss: 3.3391resizing:  384 384\n"," 26/204 [==>...........................] - ETA: 1:38 - loss: 3.3683 - yolo_layer_1_loss: 1.9388e-04 - yolo_layer_2_loss: 0.1117 - yolo_layer_3_loss: 3.2564resizing:  448 448\n"," 62/204 [========>.....................] - ETA: 1:26 - loss: 3.2917 - yolo_layer_1_loss: 2.1713e-04 - yolo_layer_2_loss: 0.2252 - yolo_layer_3_loss: 3.0663resizing:  448 448\n"," 74/204 [=========>....................] - ETA: 1:20 - loss: 3.1997 - yolo_layer_1_loss: 2.2155e-04 - yolo_layer_2_loss: 0.2379 - yolo_layer_3_loss: 2.9616resizing:  416 416\n"," 81/204 [==========>...................] - ETA: 1:17 - loss: 3.1193 - yolo_layer_1_loss: 2.2310e-04 - yolo_layer_2_loss: 0.2249 - yolo_layer_3_loss: 2.8942resizing:  352 352\n"," 84/204 [===========>..................] - ETA: 1:15 - loss: 3.1547 - yolo_layer_1_loss: 2.2329e-04 - yolo_layer_2_loss: 0.2173 - yolo_layer_3_loss: 2.9371resizing:  352 352\n"," 87/204 [===========>..................] - ETA: 1:14 - loss: 3.1349 - yolo_layer_1_loss: 2.2393e-04 - yolo_layer_2_loss: 0.2099 - yolo_layer_3_loss: 2.9248resizing:  416 416\n"," 88/204 [===========>..................] - ETA: 1:13 - loss: 3.1245 - yolo_layer_1_loss: 2.2351e-04 - yolo_layer_2_loss: 0.2075 - yolo_layer_3_loss: 2.9168resizing:  384 384\n","102/204 [==============>...............] - ETA: 1:03 - loss: 3.1564 - yolo_layer_1_loss: 2.2068e-04 - yolo_layer_2_loss: 0.2058 - yolo_layer_3_loss: 2.9504resizing:  384 384\n","104/204 [==============>...............] - ETA: 1:02 - loss: 3.1906 - yolo_layer_1_loss: 2.1985e-04 - yolo_layer_2_loss: 0.2072 - yolo_layer_3_loss: 2.9832resizing:  384 384\n","111/204 [===============>..............] - ETA: 57s - loss: 3.1576 - yolo_layer_1_loss: 2.1781e-04 - yolo_layer_2_loss: 0.1953 - yolo_layer_3_loss: 2.9621resizing:  352 352\n","128/204 [=================>............] - ETA: 46s - loss: 3.2778 - yolo_layer_1_loss: 2.1288e-04 - yolo_layer_2_loss: 0.1753 - yolo_layer_3_loss: 3.1022resizing:  448 448\n","134/204 [==================>...........] - ETA: 42s - loss: 3.3292 - yolo_layer_1_loss: 2.1102e-04 - yolo_layer_2_loss: 0.1675 - yolo_layer_3_loss: 3.1614resizing:  416 416\n","136/204 [===================>..........] - ETA: 40s - loss: 3.3208 - yolo_layer_1_loss: 2.1042e-04 - yolo_layer_2_loss: 0.1651 - yolo_layer_3_loss: 3.1555resizing:  352 352\n","154/204 [=====================>........] - ETA: 29s - loss: 3.2769 - yolo_layer_1_loss: 2.0993e-04 - yolo_layer_2_loss: 0.1848 - yolo_layer_3_loss: 3.0919resizing:  448 448\n","172/204 [========================>.....] - ETA: 19s - loss: 3.2772 - yolo_layer_1_loss: 2.1258e-04 - yolo_layer_2_loss: 0.2024 - yolo_layer_3_loss: 3.0746resizing:  416 416\n","175/204 [========================>.....] - ETA: 17s - loss: 3.3081 - yolo_layer_1_loss: 2.1391e-04 - yolo_layer_2_loss: 0.2296 - yolo_layer_3_loss: 3.0783resizing:  384 384\n","186/204 [==========================>...] - ETA: 10s - loss: 3.3157 - yolo_layer_1_loss: 2.1594e-04 - yolo_layer_2_loss: 0.2374 - yolo_layer_3_loss: 3.0780resizing:  352 352\n","187/204 [==========================>...] - ETA: 10s - loss: 3.3343 - yolo_layer_1_loss: 2.1589e-04 - yolo_layer_2_loss: 0.2362 - yolo_layer_3_loss: 3.0979resizing:  352 352\n","189/204 [==========================>...] - ETA: 9s - loss: 3.3359 - yolo_layer_1_loss: 2.1549e-04 - yolo_layer_2_loss: 0.2337 - yolo_layer_3_loss: 3.1020resizing:  448 448\n","204/204 [==============================] - 124s 606ms/step - loss: 3.3629 - yolo_layer_1_loss: 2.1398e-04 - yolo_layer_2_loss: 0.2454 - yolo_layer_3_loss: 3.1174\n","\n","Epoch 00046: loss did not improve from 3.27175\n","Epoch 47/103\n","  1/204 [..............................] - ETA: 2:20 - loss: 5.4891 - yolo_layer_1_loss: 3.2677e-04 - yolo_layer_2_loss: 0.9022 - yolo_layer_3_loss: 4.5866resizing:  448 448\n","  5/204 [..............................] - ETA: 2:21 - loss: 2.9693 - yolo_layer_1_loss: 2.9306e-04 - yolo_layer_2_loss: 0.4939 - yolo_layer_3_loss: 2.4751resizing:  384 384\n"," 18/204 [=>............................] - ETA: 2:05 - loss: 3.0434 - yolo_layer_1_loss: 2.4399e-04 - yolo_layer_2_loss: 0.2802 - yolo_layer_3_loss: 2.7629resizing:  448 448\n"," 31/204 [===>..........................] - ETA: 1:48 - loss: 2.9306 - yolo_layer_1_loss: 2.2511e-04 - yolo_layer_2_loss: 0.1632 - yolo_layer_3_loss: 2.7672resizing:  416 416\n"," 35/204 [====>.........................] - ETA: 1:47 - loss: 2.8011 - yolo_layer_1_loss: 2.2707e-04 - yolo_layer_2_loss: 0.1447 - yolo_layer_3_loss: 2.6562resizing:  416 416\n"," 36/204 [====>.........................] - ETA: 1:47 - loss: 2.8240 - yolo_layer_1_loss: 2.2755e-04 - yolo_layer_2_loss: 0.1407 - yolo_layer_3_loss: 2.6831resizing:  448 448\n"," 52/204 [======>.......................] - ETA: 1:38 - loss: 2.9658 - yolo_layer_1_loss: 2.3086e-04 - yolo_layer_2_loss: 0.2660 - yolo_layer_3_loss: 2.6996resizing:  352 352\n","resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:35 - loss: 3.0315 - yolo_layer_1_loss: 2.3386e-04 - yolo_layer_2_loss: 0.3311 - yolo_layer_3_loss: 2.7002resizing:  384 384\n"," 66/204 [========>.....................] - ETA: 1:27 - loss: 3.0141 - yolo_layer_1_loss: 2.2596e-04 - yolo_layer_2_loss: 0.2862 - yolo_layer_3_loss: 2.7276resizing:  416 416\n"," 68/204 [=========>....................] - ETA: 1:25 - loss: 2.9671 - yolo_layer_1_loss: 2.2372e-04 - yolo_layer_2_loss: 0.2778 - yolo_layer_3_loss: 2.6890resizing:  448 448\n"," 85/204 [===========>..................] - ETA: 1:14 - loss: 3.0343 - yolo_layer_1_loss: 2.2323e-04 - yolo_layer_2_loss: 0.3001 - yolo_layer_3_loss: 2.7339resizing:  384 384\n","101/204 [=============>................] - ETA: 1:04 - loss: 3.0382 - yolo_layer_1_loss: 2.2613e-04 - yolo_layer_2_loss: 0.3406 - yolo_layer_3_loss: 2.6974resizing:  448 448\n","123/204 [=================>............] - ETA: 51s - loss: 3.0021 - yolo_layer_1_loss: 2.2781e-04 - yolo_layer_2_loss: 0.3074 - yolo_layer_3_loss: 2.6945resizing:  448 448\n","124/204 [=================>............] - ETA: 51s - loss: 3.0214 - yolo_layer_1_loss: 2.2811e-04 - yolo_layer_2_loss: 0.3049 - yolo_layer_3_loss: 2.7163resizing:  416 416\n","126/204 [=================>............] - ETA: 50s - loss: 2.9951 - yolo_layer_1_loss: 2.2805e-04 - yolo_layer_2_loss: 0.3001 - yolo_layer_3_loss: 2.6948resizing:  416 416\n","134/204 [==================>...........] - ETA: 45s - loss: 3.0268 - yolo_layer_1_loss: 2.2892e-04 - yolo_layer_2_loss: 0.3209 - yolo_layer_3_loss: 2.7057resizing:  416 416\n","139/204 [===================>..........] - ETA: 41s - loss: 3.0138 - yolo_layer_1_loss: 2.2826e-04 - yolo_layer_2_loss: 0.3141 - yolo_layer_3_loss: 2.6995resizing:  384 384\n","152/204 [=====================>........] - ETA: 33s - loss: 3.0225 - yolo_layer_1_loss: 2.2660e-04 - yolo_layer_2_loss: 0.3090 - yolo_layer_3_loss: 2.7132resizing:  416 416\n","153/204 [=====================>........] - ETA: 32s - loss: 3.0537 - yolo_layer_1_loss: 2.2635e-04 - yolo_layer_2_loss: 0.3132 - yolo_layer_3_loss: 2.7402resizing:  448 448\n","160/204 [======================>.......] - ETA: 28s - loss: 3.1327 - yolo_layer_1_loss: 2.2644e-04 - yolo_layer_2_loss: 0.3164 - yolo_layer_3_loss: 2.8160resizing:  352 352\n","165/204 [=======================>......] - ETA: 25s - loss: 3.0882 - yolo_layer_1_loss: 2.2669e-04 - yolo_layer_2_loss: 0.3070 - yolo_layer_3_loss: 2.7811resizing:  352 352\n","167/204 [=======================>......] - ETA: 23s - loss: 3.0763 - yolo_layer_1_loss: 2.2740e-04 - yolo_layer_2_loss: 0.3033 - yolo_layer_3_loss: 2.7728resizing:  448 448\n","170/204 [========================>.....] - ETA: 22s - loss: 3.0577 - yolo_layer_1_loss: 2.2788e-04 - yolo_layer_2_loss: 0.2980 - yolo_layer_3_loss: 2.7595resizing:  352 352\n","204/204 [==============================] - 128s 627ms/step - loss: 3.1810 - yolo_layer_1_loss: 2.2114e-04 - yolo_layer_2_loss: 0.2642 - yolo_layer_3_loss: 2.9166\n","\n","Epoch 00047: loss improved from 3.27175 to 3.18102, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 48/103\n","resizing:  384 384\n","  5/204 [..............................] - ETA: 1:42 - loss: 3.2568 - yolo_layer_1_loss: 2.3268e-04 - yolo_layer_2_loss: 0.3378 - yolo_layer_3_loss: 2.9188resizing:  448 448\n"," 10/204 [>.............................] - ETA: 1:43 - loss: 3.2567 - yolo_layer_1_loss: 2.1633e-04 - yolo_layer_2_loss: 0.2107 - yolo_layer_3_loss: 3.0457resizing:  384 384\n"," 11/204 [>.............................] - ETA: 1:43 - loss: 3.2685 - yolo_layer_1_loss: 2.1313e-04 - yolo_layer_2_loss: 0.1917 - yolo_layer_3_loss: 3.0766resizing:  384 384\n"," 12/204 [>.............................] - ETA: 1:42 - loss: 3.3753 - yolo_layer_1_loss: 2.1144e-04 - yolo_layer_2_loss: 0.2710 - yolo_layer_3_loss: 3.1040resizing:  352 352\n"," 25/204 [==>...........................] - ETA: 1:45 - loss: 2.7412 - yolo_layer_1_loss: 2.1714e-04 - yolo_layer_2_loss: 0.2251 - yolo_layer_3_loss: 2.5159resizing:  448 448\n"," 62/204 [========>.....................] - ETA: 1:28 - loss: 3.0617 - yolo_layer_1_loss: 2.1621e-04 - yolo_layer_2_loss: 0.2339 - yolo_layer_3_loss: 2.8276resizing:  416 416\n"," 63/204 [========>.....................] - ETA: 1:27 - loss: 3.0477 - yolo_layer_1_loss: 2.1605e-04 - yolo_layer_2_loss: 0.2302 - yolo_layer_3_loss: 2.8173resizing:  384 384\n"," 73/204 [=========>....................] - ETA: 1:22 - loss: 3.0615 - yolo_layer_1_loss: 2.2045e-04 - yolo_layer_2_loss: 0.2074 - yolo_layer_3_loss: 2.8538resizing:  352 352\n"," 79/204 [==========>...................] - ETA: 1:18 - loss: 3.1383 - yolo_layer_1_loss: 2.1718e-04 - yolo_layer_2_loss: 0.1991 - yolo_layer_3_loss: 2.9390resizing:  384 384\n"," 89/204 [============>.................] - ETA: 1:10 - loss: 3.1281 - yolo_layer_1_loss: 2.1366e-04 - yolo_layer_2_loss: 0.1895 - yolo_layer_3_loss: 2.9384resizing:  352 352\n"," 90/204 [============>.................] - ETA: 1:10 - loss: 3.1491 - yolo_layer_1_loss: 2.1327e-04 - yolo_layer_2_loss: 0.1874 - yolo_layer_3_loss: 2.9615resizing:  352 352\n","103/204 [==============>...............] - ETA: 1:00 - loss: 3.2146 - yolo_layer_1_loss: 2.0833e-04 - yolo_layer_2_loss: 0.1849 - yolo_layer_3_loss: 3.0295resizing:  384 384\n","108/204 [==============>...............] - ETA: 57s - loss: 3.2337 - yolo_layer_1_loss: 2.0737e-04 - yolo_layer_2_loss: 0.1764 - yolo_layer_3_loss: 3.0572resizing:  384 384\n","109/204 [===============>..............] - ETA: 56s - loss: 3.2497 - yolo_layer_1_loss: 2.0701e-04 - yolo_layer_2_loss: 0.1748 - yolo_layer_3_loss: 3.0747resizing:  384 384\n","116/204 [================>.............] - ETA: 52s - loss: 3.3355 - yolo_layer_1_loss: 2.0594e-04 - yolo_layer_2_loss: 0.2218 - yolo_layer_3_loss: 3.1134resizing:  416 416\n","122/204 [================>.............] - ETA: 48s - loss: 3.3278 - yolo_layer_1_loss: 2.0470e-04 - yolo_layer_2_loss: 0.2124 - yolo_layer_3_loss: 3.1152resizing:  448 448\n","124/204 [=================>............] - ETA: 47s - loss: 3.3313 - yolo_layer_1_loss: 2.0427e-04 - yolo_layer_2_loss: 0.2090 - yolo_layer_3_loss: 3.1221resizing:  384 384\n","160/204 [======================>.......] - ETA: 25s - loss: 3.2942 - yolo_layer_1_loss: 2.0297e-04 - yolo_layer_2_loss: 0.2349 - yolo_layer_3_loss: 3.0591resizing:  352 352\n","161/204 [======================>.......] - ETA: 25s - loss: 3.2842 - yolo_layer_1_loss: 2.0286e-04 - yolo_layer_2_loss: 0.2335 - yolo_layer_3_loss: 3.0506resizing:  448 448\n","162/204 [======================>.......] - ETA: 24s - loss: 3.2936 - yolo_layer_1_loss: 2.0287e-04 - yolo_layer_2_loss: 0.2321 - yolo_layer_3_loss: 3.0614resizing:  352 352\n","167/204 [=======================>......] - ETA: 21s - loss: 3.3366 - yolo_layer_1_loss: 2.0186e-04 - yolo_layer_2_loss: 0.2251 - yolo_layer_3_loss: 3.1113resizing:  416 416\n","169/204 [=======================>......] - ETA: 20s - loss: 3.3383 - yolo_layer_1_loss: 2.0145e-04 - yolo_layer_2_loss: 0.2225 - yolo_layer_3_loss: 3.1156resizing:  352 352\n","182/204 [=========================>....] - ETA: 12s - loss: 3.3218 - yolo_layer_1_loss: 2.0006e-04 - yolo_layer_2_loss: 0.2067 - yolo_layer_3_loss: 3.1149resizing:  448 448\n","204/204 [==============================] - 119s 584ms/step - loss: 3.3219 - yolo_layer_1_loss: 2.0139e-04 - yolo_layer_2_loss: 0.2126 - yolo_layer_3_loss: 3.1090\n","\n","Epoch 00048: loss did not improve from 3.18102\n","Epoch 49/103\n","  1/204 [..............................] - ETA: 2:19 - loss: 6.9553 - yolo_layer_1_loss: 2.4052e-04 - yolo_layer_2_loss: 1.1636 - yolo_layer_3_loss: 5.7915resizing:  416 416\n","  3/204 [..............................] - ETA: 2:20 - loss: 4.9373 - yolo_layer_1_loss: 2.3200e-04 - yolo_layer_2_loss: 0.3890 - yolo_layer_3_loss: 4.5481resizing:  448 448\n","  6/204 [..............................] - ETA: 2:17 - loss: 3.8667 - yolo_layer_1_loss: 2.3442e-04 - yolo_layer_2_loss: 0.4506 - yolo_layer_3_loss: 3.4158resizing:  448 448\n","  8/204 [>.............................] - ETA: 2:14 - loss: 4.0161 - yolo_layer_1_loss: 2.3237e-04 - yolo_layer_2_loss: 0.6091 - yolo_layer_3_loss: 3.4067resizing:  384 384\n"," 16/204 [=>............................] - ETA: 2:09 - loss: 3.7418 - yolo_layer_1_loss: 2.4005e-04 - yolo_layer_2_loss: 0.5794 - yolo_layer_3_loss: 3.1622resizing:  352 352\n"," 19/204 [=>............................] - ETA: 2:07 - loss: 3.6660 - yolo_layer_1_loss: 2.3798e-04 - yolo_layer_2_loss: 0.5348 - yolo_layer_3_loss: 3.1309resizing:  416 416\n"," 54/204 [======>.......................] - ETA: 1:35 - loss: 3.4647 - yolo_layer_1_loss: 2.1231e-04 - yolo_layer_2_loss: 0.2897 - yolo_layer_3_loss: 3.1748resizing:  352 352\n"," 55/204 [=======>......................] - ETA: 1:34 - loss: 3.4494 - yolo_layer_1_loss: 2.1278e-04 - yolo_layer_2_loss: 0.3003 - yolo_layer_3_loss: 3.1489resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:33 - loss: 3.4399 - yolo_layer_1_loss: 2.1145e-04 - yolo_layer_2_loss: 0.2898 - yolo_layer_3_loss: 3.1499resizing:  448 448\n"," 60/204 [=======>......................] - ETA: 1:31 - loss: 3.4447 - yolo_layer_1_loss: 2.0983e-04 - yolo_layer_2_loss: 0.2753 - yolo_layer_3_loss: 3.1692resizing:  416 416\n"," 63/204 [========>.....................] - ETA: 1:29 - loss: 3.4469 - yolo_layer_1_loss: 2.0957e-04 - yolo_layer_2_loss: 0.2654 - yolo_layer_3_loss: 3.1813resizing:  352 352\n"," 69/204 [=========>....................] - ETA: 1:24 - loss: 3.5443 - yolo_layer_1_loss: 2.0705e-04 - yolo_layer_2_loss: 0.2424 - yolo_layer_3_loss: 3.3017resizing:  416 416\n","101/204 [=============>................] - ETA: 1:04 - loss: 3.4881 - yolo_layer_1_loss: 2.0232e-04 - yolo_layer_2_loss: 0.2453 - yolo_layer_3_loss: 3.2426resizing:  352 352\n","102/204 [==============>...............] - ETA: 1:03 - loss: 3.4752 - yolo_layer_1_loss: 2.0251e-04 - yolo_layer_2_loss: 0.2465 - yolo_layer_3_loss: 3.2285resizing:  384 384\n","103/204 [==============>...............] - ETA: 1:02 - loss: 3.4633 - yolo_layer_1_loss: 2.0265e-04 - yolo_layer_2_loss: 0.2441 - yolo_layer_3_loss: 3.2190resizing:  448 448\n","119/204 [================>.............] - ETA: 53s - loss: 3.5238 - yolo_layer_1_loss: 2.0535e-04 - yolo_layer_2_loss: 0.3503 - yolo_layer_3_loss: 3.1733resizing:  416 416\n","140/204 [===================>..........] - ETA: 40s - loss: 3.4005 - yolo_layer_1_loss: 2.0640e-04 - yolo_layer_2_loss: 0.3176 - yolo_layer_3_loss: 3.0827resizing:  352 352\n","141/204 [===================>..........] - ETA: 40s - loss: 3.4134 - yolo_layer_1_loss: 2.0626e-04 - yolo_layer_2_loss: 0.3153 - yolo_layer_3_loss: 3.0979resizing:  448 448\n","158/204 [======================>.......] - ETA: 29s - loss: 3.3736 - yolo_layer_1_loss: 2.0762e-04 - yolo_layer_2_loss: 0.3144 - yolo_layer_3_loss: 3.0590resizing:  352 352\n","resizing:  448 448\n","164/204 [=======================>......] - ETA: 25s - loss: 3.3336 - yolo_layer_1_loss: 2.0830e-04 - yolo_layer_2_loss: 0.3029 - yolo_layer_3_loss: 3.0305resizing:  384 384\n","168/204 [=======================>......] - ETA: 23s - loss: 3.3254 - yolo_layer_1_loss: 2.0869e-04 - yolo_layer_2_loss: 0.2961 - yolo_layer_3_loss: 3.0291resizing:  384 384\n","172/204 [========================>.....] - ETA: 20s - loss: 3.3131 - yolo_layer_1_loss: 2.0889e-04 - yolo_layer_2_loss: 0.2990 - yolo_layer_3_loss: 3.0138resizing:  448 448\n","185/204 [==========================>...] - ETA: 12s - loss: 3.2960 - yolo_layer_1_loss: 2.1012e-04 - yolo_layer_2_loss: 0.2988 - yolo_layer_3_loss: 2.9970resizing:  448 448\n","204/204 [==============================] - 132s 645ms/step - loss: 3.2666 - yolo_layer_1_loss: 2.1376e-04 - yolo_layer_2_loss: 0.2858 - yolo_layer_3_loss: 2.9806\n","\n","Epoch 00049: loss did not improve from 3.18102\n","resizing:  352 352\n","Epoch 50/103\n","  2/204 [..............................] - ETA: 2:21 - loss: 2.7344 - yolo_layer_1_loss: 2.6808e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 2.7330resizing:  416 416\n"," 14/204 [=>............................] - ETA: 1:53 - loss: 3.2718 - yolo_layer_1_loss: 1.9497e-04 - yolo_layer_2_loss: 0.1420 - yolo_layer_3_loss: 3.1296resizing:  384 384\n"," 21/204 [==>...........................] - ETA: 1:52 - loss: 3.0153 - yolo_layer_1_loss: 1.9847e-04 - yolo_layer_2_loss: 0.1937 - yolo_layer_3_loss: 2.8214resizing:  448 448\n"," 30/204 [===>..........................] - ETA: 1:45 - loss: 2.8854 - yolo_layer_1_loss: 1.9388e-04 - yolo_layer_2_loss: 0.1713 - yolo_layer_3_loss: 2.7140resizing:  448 448\n"," 33/204 [===>..........................] - ETA: 1:43 - loss: 2.8487 - yolo_layer_1_loss: 1.9437e-04 - yolo_layer_2_loss: 0.1787 - yolo_layer_3_loss: 2.6698resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:34 - loss: 3.0257 - yolo_layer_1_loss: 2.0542e-04 - yolo_layer_2_loss: 0.2910 - yolo_layer_3_loss: 2.7345resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:30 - loss: 3.0051 - yolo_layer_1_loss: 2.0330e-04 - yolo_layer_2_loss: 0.2652 - yolo_layer_3_loss: 2.7397resizing:  384 384\n"," 59/204 [=======>......................] - ETA: 1:27 - loss: 2.9508 - yolo_layer_1_loss: 2.0125e-04 - yolo_layer_2_loss: 0.2518 - yolo_layer_3_loss: 2.6988resizing:  384 384\n"," 65/204 [========>.....................] - ETA: 1:23 - loss: 3.0050 - yolo_layer_1_loss: 1.9910e-04 - yolo_layer_2_loss: 0.2287 - yolo_layer_3_loss: 2.7761resizing:  448 448\n"," 67/204 [========>.....................] - ETA: 1:22 - loss: 3.0081 - yolo_layer_1_loss: 1.9858e-04 - yolo_layer_2_loss: 0.2300 - yolo_layer_3_loss: 2.7778resizing:  384 384\n"," 89/204 [============>.................] - ETA: 1:07 - loss: 3.0833 - yolo_layer_1_loss: 1.9575e-04 - yolo_layer_2_loss: 0.1883 - yolo_layer_3_loss: 2.8948resizing:  448 448\n","102/204 [==============>...............] - ETA: 59s - loss: 3.0990 - yolo_layer_1_loss: 1.9570e-04 - yolo_layer_2_loss: 0.1838 - yolo_layer_3_loss: 2.9150 resizing:  416 416\n","103/204 [==============>...............] - ETA: 59s - loss: 3.0910 - yolo_layer_1_loss: 1.9575e-04 - yolo_layer_2_loss: 0.1874 - yolo_layer_3_loss: 2.9034resizing:  352 352\n","104/204 [==============>...............] - ETA: 58s - loss: 3.0738 - yolo_layer_1_loss: 1.9626e-04 - yolo_layer_2_loss: 0.1856 - yolo_layer_3_loss: 2.8880resizing:  416 416\n","107/204 [==============>...............] - ETA: 57s - loss: 3.1031 - yolo_layer_1_loss: 1.9696e-04 - yolo_layer_2_loss: 0.2365 - yolo_layer_3_loss: 2.8664resizing:  448 448\n","118/204 [================>.............] - ETA: 50s - loss: 3.1290 - yolo_layer_1_loss: 1.9702e-04 - yolo_layer_2_loss: 0.2146 - yolo_layer_3_loss: 2.9142resizing:  448 448\n","121/204 [================>.............] - ETA: 49s - loss: 3.1223 - yolo_layer_1_loss: 1.9766e-04 - yolo_layer_2_loss: 0.2146 - yolo_layer_3_loss: 2.9075resizing:  384 384\n","158/204 [======================>.......] - ETA: 27s - loss: 3.0902 - yolo_layer_1_loss: 1.9630e-04 - yolo_layer_2_loss: 0.2007 - yolo_layer_3_loss: 2.8893resizing:  448 448\n","159/204 [======================>.......] - ETA: 26s - loss: 3.0811 - yolo_layer_1_loss: 1.9644e-04 - yolo_layer_2_loss: 0.1995 - yolo_layer_3_loss: 2.8814resizing:  416 416\n","165/204 [=======================>......] - ETA: 23s - loss: 3.0835 - yolo_layer_1_loss: 1.9638e-04 - yolo_layer_2_loss: 0.1980 - yolo_layer_3_loss: 2.8853resizing:  384 384\n","175/204 [========================>.....] - ETA: 17s - loss: 3.1360 - yolo_layer_1_loss: 1.9689e-04 - yolo_layer_2_loss: 0.2520 - yolo_layer_3_loss: 2.8838resizing:  448 448\n","184/204 [==========================>...] - ETA: 11s - loss: 3.1372 - yolo_layer_1_loss: 1.9555e-04 - yolo_layer_2_loss: 0.2484 - yolo_layer_3_loss: 2.8886resizing:  352 352\n","186/204 [==========================>...] - ETA: 10s - loss: 3.1340 - yolo_layer_1_loss: 1.9529e-04 - yolo_layer_2_loss: 0.2457 - yolo_layer_3_loss: 2.8881resizing:  384 384\n","204/204 [==============================] - 121s 595ms/step - loss: 3.1596 - yolo_layer_1_loss: 1.9688e-04 - yolo_layer_2_loss: 0.2467 - yolo_layer_3_loss: 2.9128\n","\n","Epoch 00050: loss improved from 3.18102 to 3.15962, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 51/103\n","resizing:  416 416\n","  5/204 [..............................] - ETA: 1:50 - loss: 2.5842 - yolo_layer_1_loss: 1.8257e-04 - yolo_layer_2_loss: 9.8554e-04 - yolo_layer_3_loss: 2.5830resizing:  384 384\n","  6/204 [..............................] - ETA: 1:53 - loss: 2.5624 - yolo_layer_1_loss: 1.9122e-04 - yolo_layer_2_loss: 0.0838 - yolo_layer_3_loss: 2.4783    resizing:  448 448\n"," 12/204 [>.............................] - ETA: 1:57 - loss: 2.7507 - yolo_layer_1_loss: 2.0129e-04 - yolo_layer_2_loss: 0.0429 - yolo_layer_3_loss: 2.7076resizing:  352 352\n"," 27/204 [==>...........................] - ETA: 1:50 - loss: 2.9386 - yolo_layer_1_loss: 2.0013e-04 - yolo_layer_2_loss: 0.1740 - yolo_layer_3_loss: 2.7644resizing:  448 448\n"," 37/204 [====>.........................] - ETA: 1:38 - loss: 3.0855 - yolo_layer_1_loss: 1.9136e-04 - yolo_layer_2_loss: 0.1272 - yolo_layer_3_loss: 2.9582resizing:  416 416\n"," 50/204 [======>.......................] - ETA: 1:34 - loss: 3.0465 - yolo_layer_1_loss: 1.9913e-04 - yolo_layer_2_loss: 0.1468 - yolo_layer_3_loss: 2.8995resizing:  384 384\n"," 60/204 [=======>......................] - ETA: 1:27 - loss: 3.0873 - yolo_layer_1_loss: 1.9622e-04 - yolo_layer_2_loss: 0.1388 - yolo_layer_3_loss: 2.9483resizing:  352 352\n"," 61/204 [=======>......................] - ETA: 1:26 - loss: 3.0578 - yolo_layer_1_loss: 1.9580e-04 - yolo_layer_2_loss: 0.1366 - yolo_layer_3_loss: 2.9210resizing:  416 416\n"," 65/204 [========>.....................] - ETA: 1:23 - loss: 3.1047 - yolo_layer_1_loss: 1.9456e-04 - yolo_layer_2_loss: 0.1487 - yolo_layer_3_loss: 2.9558resizing:  384 384\n"," 68/204 [=========>....................] - ETA: 1:21 - loss: 3.1334 - yolo_layer_1_loss: 1.9358e-04 - yolo_layer_2_loss: 0.1422 - yolo_layer_3_loss: 2.9910resizing:  352 352\n"," 70/204 [=========>....................] - ETA: 1:20 - loss: 3.1549 - yolo_layer_1_loss: 1.9303e-04 - yolo_layer_2_loss: 0.1381 - yolo_layer_3_loss: 3.0165resizing:  416 416\n","104/204 [==============>...............] - ETA: 1:00 - loss: 3.0749 - yolo_layer_1_loss: 1.9222e-04 - yolo_layer_2_loss: 0.1599 - yolo_layer_3_loss: 2.9148resizing:  352 352\n","110/204 [===============>..............] - ETA: 57s - loss: 3.0753 - yolo_layer_1_loss: 1.9228e-04 - yolo_layer_2_loss: 0.1945 - yolo_layer_3_loss: 2.8806resizing:  384 384\n","112/204 [===============>..............] - ETA: 55s - loss: 3.0584 - yolo_layer_1_loss: 1.9204e-04 - yolo_layer_2_loss: 0.1911 - yolo_layer_3_loss: 2.8672resizing:  352 352\n","113/204 [===============>..............] - ETA: 55s - loss: 3.0765 - yolo_layer_1_loss: 1.9172e-04 - yolo_layer_2_loss: 0.1894 - yolo_layer_3_loss: 2.8870resizing:  416 416\n","124/204 [=================>............] - ETA: 47s - loss: 3.0700 - yolo_layer_1_loss: 1.9016e-04 - yolo_layer_2_loss: 0.1756 - yolo_layer_3_loss: 2.8942resizing:  384 384\n","141/204 [===================>..........] - ETA: 37s - loss: 3.0165 - yolo_layer_1_loss: 1.9028e-04 - yolo_layer_2_loss: 0.1617 - yolo_layer_3_loss: 2.8546resizing:  384 384\n","152/204 [=====================>........] - ETA: 30s - loss: 3.0516 - yolo_layer_1_loss: 1.8886e-04 - yolo_layer_2_loss: 0.1546 - yolo_layer_3_loss: 2.8969resizing:  416 416\n","154/204 [=====================>........] - ETA: 29s - loss: 3.0499 - yolo_layer_1_loss: 1.8975e-04 - yolo_layer_2_loss: 0.1700 - yolo_layer_3_loss: 2.8796resizing:  384 384\n","158/204 [======================>.......] - ETA: 27s - loss: 3.0538 - yolo_layer_1_loss: 1.8961e-04 - yolo_layer_2_loss: 0.1658 - yolo_layer_3_loss: 2.8879resizing:  416 416\n","161/204 [======================>.......] - ETA: 25s - loss: 3.0352 - yolo_layer_1_loss: 1.8993e-04 - yolo_layer_2_loss: 0.1627 - yolo_layer_3_loss: 2.8723resizing:  448 448\n","resizing:  416 416\n","178/204 [=========================>....] - ETA: 15s - loss: 3.0443 - yolo_layer_1_loss: 1.8948e-04 - yolo_layer_2_loss: 0.1810 - yolo_layer_3_loss: 2.8632resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 3.0735 - yolo_layer_1_loss: 1.9134e-04 - yolo_layer_2_loss: 0.1777 - yolo_layer_3_loss: 2.8956resizing:  384 384\n","204/204 [==============================] - 123s 602ms/step - loss: 3.0732 - yolo_layer_1_loss: 1.9137e-04 - yolo_layer_2_loss: 0.1768 - yolo_layer_3_loss: 2.8963\n","\n","Epoch 00051: loss improved from 3.15962 to 3.07323, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 52/103\n","  1/204 [..............................] - ETA: 1:56 - loss: 1.4230 - yolo_layer_1_loss: 1.5798e-04 - yolo_layer_2_loss: 8.2495e-04 - yolo_layer_3_loss: 1.4221resizing:  352 352\n"," 16/204 [=>............................] - ETA: 1:36 - loss: 3.2436 - yolo_layer_1_loss: 1.7278e-04 - yolo_layer_2_loss: 0.2432 - yolo_layer_3_loss: 3.0003resizing:  384 384\n"," 18/204 [=>............................] - ETA: 1:35 - loss: 3.1773 - yolo_layer_1_loss: 1.7236e-04 - yolo_layer_2_loss: 0.2162 - yolo_layer_3_loss: 2.9608resizing:  416 416\n"," 28/204 [===>..........................] - ETA: 1:29 - loss: 3.4687 - yolo_layer_1_loss: 1.7312e-04 - yolo_layer_2_loss: 0.1675 - yolo_layer_3_loss: 3.3011resizing:  416 416\n"," 39/204 [====>.........................] - ETA: 1:30 - loss: 3.4257 - yolo_layer_1_loss: 1.8106e-04 - yolo_layer_2_loss: 0.1345 - yolo_layer_3_loss: 3.2910resizing:  448 448\n"," 50/204 [======>.......................] - ETA: 1:27 - loss: 3.3179 - yolo_layer_1_loss: 1.8636e-04 - yolo_layer_2_loss: 0.1275 - yolo_layer_3_loss: 3.1902resizing:  448 448\n"," 58/204 [=======>......................] - ETA: 1:25 - loss: 3.3182 - yolo_layer_1_loss: 1.9242e-04 - yolo_layer_2_loss: 0.1804 - yolo_layer_3_loss: 3.1376resizing:  448 448\n"," 59/204 [=======>......................] - ETA: 1:25 - loss: 3.3016 - yolo_layer_1_loss: 1.9341e-04 - yolo_layer_2_loss: 0.1773 - yolo_layer_3_loss: 3.1240resizing:  448 448\n"," 69/204 [=========>....................] - ETA: 1:21 - loss: 3.4187 - yolo_layer_1_loss: 1.9833e-04 - yolo_layer_2_loss: 0.2376 - yolo_layer_3_loss: 3.1809resizing:  352 352\n"," 88/204 [===========>..................] - ETA: 1:10 - loss: 3.3072 - yolo_layer_1_loss: 2.0078e-04 - yolo_layer_2_loss: 0.2619 - yolo_layer_3_loss: 3.0451resizing:  448 448\n"," 90/204 [============>.................] - ETA: 1:08 - loss: 3.2740 - yolo_layer_1_loss: 2.0023e-04 - yolo_layer_2_loss: 0.2568 - yolo_layer_3_loss: 3.0170resizing:  448 448\n","103/204 [==============>...............] - ETA: 1:00 - loss: 3.2213 - yolo_layer_1_loss: 1.9852e-04 - yolo_layer_2_loss: 0.2245 - yolo_layer_3_loss: 2.9966resizing:  448 448\n","104/204 [==============>...............] - ETA: 59s - loss: 3.2527 - yolo_layer_1_loss: 1.9924e-04 - yolo_layer_2_loss: 0.2297 - yolo_layer_3_loss: 3.0228 resizing:  416 416\n","105/204 [==============>...............] - ETA: 59s - loss: 3.2381 - yolo_layer_1_loss: 1.9931e-04 - yolo_layer_2_loss: 0.2276 - yolo_layer_3_loss: 3.0103resizing:  384 384\n","119/204 [================>.............] - ETA: 51s - loss: 3.2741 - yolo_layer_1_loss: 1.9968e-04 - yolo_layer_2_loss: 0.2496 - yolo_layer_3_loss: 3.0243resizing:  384 384\n","123/204 [=================>............] - ETA: 48s - loss: 3.2781 - yolo_layer_1_loss: 1.9885e-04 - yolo_layer_2_loss: 0.2511 - yolo_layer_3_loss: 3.0268resizing:  384 384\n","133/204 [==================>...........] - ETA: 42s - loss: 3.2819 - yolo_layer_1_loss: 1.9749e-04 - yolo_layer_2_loss: 0.2328 - yolo_layer_3_loss: 3.0490resizing:  416 416\n","155/204 [=====================>........] - ETA: 29s - loss: 3.2355 - yolo_layer_1_loss: 1.9652e-04 - yolo_layer_2_loss: 0.2577 - yolo_layer_3_loss: 2.9777resizing:  384 384\n","156/204 [=====================>........] - ETA: 28s - loss: 3.2280 - yolo_layer_1_loss: 1.9673e-04 - yolo_layer_2_loss: 0.2560 - yolo_layer_3_loss: 2.9718resizing:  448 448\n","169/204 [=======================>......] - ETA: 21s - loss: 3.2347 - yolo_layer_1_loss: 1.9838e-04 - yolo_layer_2_loss: 0.2459 - yolo_layer_3_loss: 2.9887resizing:  448 448\n","172/204 [========================>.....] - ETA: 19s - loss: 3.2272 - yolo_layer_1_loss: 1.9938e-04 - yolo_layer_2_loss: 0.2483 - yolo_layer_3_loss: 2.9787resizing:  352 352\n","182/204 [=========================>....] - ETA: 13s - loss: 3.2370 - yolo_layer_1_loss: 2.0126e-04 - yolo_layer_2_loss: 0.2685 - yolo_layer_3_loss: 2.9683resizing:  416 416\n","187/204 [==========================>...] - ETA: 10s - loss: 3.2391 - yolo_layer_1_loss: 2.0140e-04 - yolo_layer_2_loss: 0.2707 - yolo_layer_3_loss: 2.9682resizing:  416 416\n","204/204 [==============================] - 123s 604ms/step - loss: 3.2624 - yolo_layer_1_loss: 2.0030e-04 - yolo_layer_2_loss: 0.2633 - yolo_layer_3_loss: 2.9989\n","\n","Epoch 00052: loss did not improve from 3.07323\n","Epoch 53/103\n","  1/204 [..............................] - ETA: 2:10 - loss: 1.5382 - yolo_layer_1_loss: 2.1911e-04 - yolo_layer_2_loss: 9.7061e-04 - yolo_layer_3_loss: 1.5370resizing:  384 384\n","  6/204 [..............................] - ETA: 2:07 - loss: 3.1141 - yolo_layer_1_loss: 2.0365e-04 - yolo_layer_2_loss: 0.7892 - yolo_layer_3_loss: 2.3247resizing:  352 352\n"," 11/204 [>.............................] - ETA: 1:55 - loss: 3.1752 - yolo_layer_1_loss: 1.9859e-04 - yolo_layer_2_loss: 0.4777 - yolo_layer_3_loss: 2.6973resizing:  416 416\n"," 13/204 [>.............................] - ETA: 1:53 - loss: 2.9896 - yolo_layer_1_loss: 1.9427e-04 - yolo_layer_2_loss: 0.4679 - yolo_layer_3_loss: 2.5216resizing:  352 352\n"," 20/204 [=>............................] - ETA: 1:44 - loss: 3.0788 - yolo_layer_1_loss: 1.8802e-04 - yolo_layer_2_loss: 0.3045 - yolo_layer_3_loss: 2.7741resizing:  448 448\n"," 28/204 [===>..........................] - ETA: 1:38 - loss: 3.2518 - yolo_layer_1_loss: 1.8461e-04 - yolo_layer_2_loss: 0.2194 - yolo_layer_3_loss: 3.0322resizing:  448 448\n"," 55/204 [=======>......................] - ETA: 1:31 - loss: 3.1678 - yolo_layer_1_loss: 2.0227e-04 - yolo_layer_2_loss: 0.1571 - yolo_layer_3_loss: 3.0104resizing:  352 352\n"," 56/204 [=======>......................] - ETA: 1:31 - loss: 3.1320 - yolo_layer_1_loss: 2.0290e-04 - yolo_layer_2_loss: 0.1544 - yolo_layer_3_loss: 2.9774resizing:  384 384\n"," 61/204 [=======>......................] - ETA: 1:29 - loss: 3.0691 - yolo_layer_1_loss: 2.0557e-04 - yolo_layer_2_loss: 0.1587 - yolo_layer_3_loss: 2.9102resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:29 - loss: 3.0726 - yolo_layer_1_loss: 2.0578e-04 - yolo_layer_2_loss: 0.1561 - yolo_layer_3_loss: 2.9163resizing:  352 352\n"," 73/204 [=========>....................] - ETA: 1:20 - loss: 3.0242 - yolo_layer_1_loss: 2.0327e-04 - yolo_layer_2_loss: 0.1327 - yolo_layer_3_loss: 2.8912resizing:  416 416\n"," 80/204 [==========>...................] - ETA: 1:15 - loss: 2.9905 - yolo_layer_1_loss: 2.0202e-04 - yolo_layer_2_loss: 0.1212 - yolo_layer_3_loss: 2.8691resizing:  384 384\n","103/204 [==============>...............] - ETA: 1:00 - loss: 3.0322 - yolo_layer_1_loss: 1.9985e-04 - yolo_layer_2_loss: 0.0951 - yolo_layer_3_loss: 2.9370resizing:  384 384\n","106/204 [==============>...............] - ETA: 58s - loss: 3.0120 - yolo_layer_1_loss: 1.9960e-04 - yolo_layer_2_loss: 0.0924 - yolo_layer_3_loss: 2.9194resizing:  384 384\n","113/204 [===============>..............] - ETA: 53s - loss: 2.9722 - yolo_layer_1_loss: 1.9901e-04 - yolo_layer_2_loss: 0.1036 - yolo_layer_3_loss: 2.8684resizing:  352 352\n","130/204 [==================>...........] - ETA: 43s - loss: 3.0335 - yolo_layer_1_loss: 1.9812e-04 - yolo_layer_2_loss: 0.1090 - yolo_layer_3_loss: 2.9243resizing:  384 384\n","134/204 [==================>...........] - ETA: 40s - loss: 3.0754 - yolo_layer_1_loss: 1.9739e-04 - yolo_layer_2_loss: 0.1121 - yolo_layer_3_loss: 2.9631resizing:  352 352\n","138/204 [===================>..........] - ETA: 38s - loss: 3.0622 - yolo_layer_1_loss: 1.9669e-04 - yolo_layer_2_loss: 0.1089 - yolo_layer_3_loss: 2.9531resizing:  384 384\n","155/204 [=====================>........] - ETA: 28s - loss: 3.1195 - yolo_layer_1_loss: 1.9410e-04 - yolo_layer_2_loss: 0.1410 - yolo_layer_3_loss: 2.9783resizing:  384 384\n","163/204 [======================>.......] - ETA: 23s - loss: 3.1509 - yolo_layer_1_loss: 1.9321e-04 - yolo_layer_2_loss: 0.1394 - yolo_layer_3_loss: 3.0113resizing:  416 416\n","164/204 [=======================>......] - ETA: 22s - loss: 3.1549 - yolo_layer_1_loss: 1.9310e-04 - yolo_layer_2_loss: 0.1385 - yolo_layer_3_loss: 3.0162resizing:  416 416\n","168/204 [=======================>......] - ETA: 20s - loss: 3.1970 - yolo_layer_1_loss: 1.9260e-04 - yolo_layer_2_loss: 0.1652 - yolo_layer_3_loss: 3.0316resizing:  384 384\n","170/204 [========================>.....] - ETA: 19s - loss: 3.2226 - yolo_layer_1_loss: 1.9266e-04 - yolo_layer_2_loss: 0.1931 - yolo_layer_3_loss: 3.0293resizing:  384 384\n","171/204 [========================>.....] - ETA: 18s - loss: 3.2331 - yolo_layer_1_loss: 1.9247e-04 - yolo_layer_2_loss: 0.1920 - yolo_layer_3_loss: 3.0409resizing:  352 352\n","204/204 [==============================] - 115s 562ms/step - loss: 3.2789 - yolo_layer_1_loss: 1.8891e-04 - yolo_layer_2_loss: 0.1784 - yolo_layer_3_loss: 3.1004\n","\n","Epoch 00053: loss did not improve from 3.07323\n","Epoch 54/103\n","  4/204 [..............................] - ETA: 1:40 - loss: 4.5521 - yolo_layer_1_loss: 1.6445e-04 - yolo_layer_2_loss: 8.3543e-04 - yolo_layer_3_loss: 4.5511resizing:  384 384\n"," 15/204 [=>............................] - ETA: 1:36 - loss: 4.0652 - yolo_layer_1_loss: 1.6826e-04 - yolo_layer_2_loss: 0.1454 - yolo_layer_3_loss: 3.9196resizing:  384 384\n"," 16/204 [=>............................] - ETA: 1:36 - loss: 4.0157 - yolo_layer_1_loss: 1.6945e-04 - yolo_layer_2_loss: 0.1364 - yolo_layer_3_loss: 3.8792resizing:  416 416\n"," 30/204 [===>..........................] - ETA: 1:33 - loss: 3.5008 - yolo_layer_1_loss: 1.8044e-04 - yolo_layer_2_loss: 0.1344 - yolo_layer_3_loss: 3.3663resizing:  384 384\n"," 33/204 [===>..........................] - ETA: 1:33 - loss: 3.3941 - yolo_layer_1_loss: 1.8247e-04 - yolo_layer_2_loss: 0.1223 - yolo_layer_3_loss: 3.2717resizing:  384 384\n"," 35/204 [====>.........................] - ETA: 1:33 - loss: 3.3161 - yolo_layer_1_loss: 1.8352e-04 - yolo_layer_2_loss: 0.1153 - yolo_layer_3_loss: 3.2006resizing:  352 352\n"," 50/204 [======>.......................] - ETA: 1:25 - loss: 3.1606 - yolo_layer_1_loss: 1.8582e-04 - yolo_layer_2_loss: 0.1427 - yolo_layer_3_loss: 3.0177resizing:  448 448\n"," 54/204 [======>.......................] - ETA: 1:24 - loss: 3.1566 - yolo_layer_1_loss: 1.8533e-04 - yolo_layer_2_loss: 0.1323 - yolo_layer_3_loss: 3.0241resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:23 - loss: 3.1315 - yolo_layer_1_loss: 1.8655e-04 - yolo_layer_2_loss: 0.1505 - yolo_layer_3_loss: 2.9809resizing:  448 448\n"," 60/204 [=======>......................] - ETA: 1:22 - loss: 3.0681 - yolo_layer_1_loss: 1.8982e-04 - yolo_layer_2_loss: 0.1405 - yolo_layer_3_loss: 2.9274resizing:  384 384\n"," 66/204 [========>.....................] - ETA: 1:20 - loss: 3.1181 - yolo_layer_1_loss: 1.9099e-04 - yolo_layer_2_loss: 0.1373 - yolo_layer_3_loss: 2.9807resizing:  384 384\n"," 82/204 [===========>..................] - ETA: 1:11 - loss: 3.1285 - yolo_layer_1_loss: 1.9197e-04 - yolo_layer_2_loss: 0.1375 - yolo_layer_3_loss: 2.9909resizing:  416 416\n","102/204 [==============>...............] - ETA: 59s - loss: 3.0501 - yolo_layer_1_loss: 1.9081e-04 - yolo_layer_2_loss: 0.1364 - yolo_layer_3_loss: 2.9135 resizing:  352 352\n","107/204 [==============>...............] - ETA: 56s - loss: 3.0122 - yolo_layer_1_loss: 1.9125e-04 - yolo_layer_2_loss: 0.1400 - yolo_layer_3_loss: 2.8719resizing:  448 448\n","108/204 [==============>...............] - ETA: 56s - loss: 3.0231 - yolo_layer_1_loss: 1.9094e-04 - yolo_layer_2_loss: 0.1388 - yolo_layer_3_loss: 2.8841resizing:  352 352\n","118/204 [================>.............] - ETA: 50s - loss: 3.0780 - yolo_layer_1_loss: 1.9034e-04 - yolo_layer_2_loss: 0.1271 - yolo_layer_3_loss: 2.9507resizing:  448 448\n","121/204 [================>.............] - ETA: 48s - loss: 3.0981 - yolo_layer_1_loss: 1.8976e-04 - yolo_layer_2_loss: 0.1282 - yolo_layer_3_loss: 2.9697resizing:  384 384\n","123/204 [=================>............] - ETA: 46s - loss: 3.0905 - yolo_layer_1_loss: 1.8922e-04 - yolo_layer_2_loss: 0.1261 - yolo_layer_3_loss: 2.9641resizing:  384 384\n","165/204 [=======================>......] - ETA: 22s - loss: 3.1225 - yolo_layer_1_loss: 1.9088e-04 - yolo_layer_2_loss: 0.1269 - yolo_layer_3_loss: 2.9954resizing:  448 448\n","168/204 [=======================>......] - ETA: 20s - loss: 3.1022 - yolo_layer_1_loss: 1.9064e-04 - yolo_layer_2_loss: 0.1247 - yolo_layer_3_loss: 2.9773resizing:  384 384\n","173/204 [========================>.....] - ETA: 17s - loss: 3.1125 - yolo_layer_1_loss: 1.9014e-04 - yolo_layer_2_loss: 0.1241 - yolo_layer_3_loss: 2.9882resizing:  352 352\n","174/204 [========================>.....] - ETA: 17s - loss: 3.1095 - yolo_layer_1_loss: 1.9004e-04 - yolo_layer_2_loss: 0.1282 - yolo_layer_3_loss: 2.9811resizing:  384 384\n","184/204 [==========================>...] - ETA: 11s - loss: 3.1164 - yolo_layer_1_loss: 1.8994e-04 - yolo_layer_2_loss: 0.1257 - yolo_layer_3_loss: 2.9905resizing:  384 384\n","187/204 [==========================>...] - ETA: 9s - loss: 3.1123 - yolo_layer_1_loss: 1.8963e-04 - yolo_layer_2_loss: 0.1237 - yolo_layer_3_loss: 2.9885 resizing:  416 416\n","203/204 [============================>.] - ETA: 0s - loss: 3.1381 - yolo_layer_1_loss: 1.8946e-04 - yolo_layer_2_loss: 0.1225 - yolo_layer_3_loss: 3.0154resizing:  352 352\n","204/204 [==============================] - 116s 570ms/step - loss: 3.1318 - yolo_layer_1_loss: 1.8943e-04 - yolo_layer_2_loss: 0.1219 - yolo_layer_3_loss: 3.0098\n","\n","Epoch 00054: loss did not improve from 3.07323\n","Epoch 55/103\n","resizing:  416 416\n","  4/204 [..............................] - ETA: 1:47 - loss: 4.1197 - yolo_layer_1_loss: 1.7096e-04 - yolo_layer_2_loss: 1.1197 - yolo_layer_3_loss: 2.9998resizing:  384 384\n"," 27/204 [==>...........................] - ETA: 1:40 - loss: 3.3935 - yolo_layer_1_loss: 1.7950e-04 - yolo_layer_2_loss: 0.3883 - yolo_layer_3_loss: 3.0051resizing:  448 448\n"," 29/204 [===>..........................] - ETA: 1:39 - loss: 3.4797 - yolo_layer_1_loss: 1.7941e-04 - yolo_layer_2_loss: 0.3615 - yolo_layer_3_loss: 3.1180resizing:  384 384\n"," 31/204 [===>..........................] - ETA: 1:37 - loss: 3.4154 - yolo_layer_1_loss: 1.7865e-04 - yolo_layer_2_loss: 0.3385 - yolo_layer_3_loss: 3.0768resizing:  352 352\n"," 57/204 [=======>......................] - ETA: 1:20 - loss: 3.5347 - yolo_layer_1_loss: 1.7843e-04 - yolo_layer_2_loss: 0.3656 - yolo_layer_3_loss: 3.1690resizing:  416 416\n"," 61/204 [=======>......................] - ETA: 1:17 - loss: 3.5059 - yolo_layer_1_loss: 1.7896e-04 - yolo_layer_2_loss: 0.3659 - yolo_layer_3_loss: 3.1398resizing:  416 416\n"," 62/204 [========>.....................] - ETA: 1:17 - loss: 3.5027 - yolo_layer_1_loss: 1.7877e-04 - yolo_layer_2_loss: 0.3600 - yolo_layer_3_loss: 3.1425resizing:  384 384\n"," 76/204 [==========>...................] - ETA: 1:10 - loss: 3.3306 - yolo_layer_1_loss: 1.7796e-04 - yolo_layer_2_loss: 0.3113 - yolo_layer_3_loss: 3.0192resizing:  416 416\n"," 77/204 [==========>...................] - ETA: 1:09 - loss: 3.3155 - yolo_layer_1_loss: 1.7795e-04 - yolo_layer_2_loss: 0.3072 - yolo_layer_3_loss: 3.0081resizing:  384 384\n"," 78/204 [==========>...................] - ETA: 1:09 - loss: 3.2922 - yolo_layer_1_loss: 1.7769e-04 - yolo_layer_2_loss: 0.3033 - yolo_layer_3_loss: 2.9887resizing:  448 448\n","108/204 [==============>...............] - ETA: 55s - loss: 3.2281 - yolo_layer_1_loss: 1.9069e-04 - yolo_layer_2_loss: 0.2796 - yolo_layer_3_loss: 2.9484resizing:  416 416\n","109/204 [===============>..............] - ETA: 54s - loss: 3.2554 - yolo_layer_1_loss: 1.9105e-04 - yolo_layer_2_loss: 0.2770 - yolo_layer_3_loss: 2.9782resizing:  384 384\n","113/204 [===============>..............] - ETA: 52s - loss: 3.2651 - yolo_layer_1_loss: 1.9203e-04 - yolo_layer_2_loss: 0.2673 - yolo_layer_3_loss: 2.9976resizing:  384 384\n","119/204 [================>.............] - ETA: 49s - loss: 3.2484 - yolo_layer_1_loss: 1.9310e-04 - yolo_layer_2_loss: 0.2541 - yolo_layer_3_loss: 2.9941resizing:  416 416\n","136/204 [===================>..........] - ETA: 39s - loss: 3.2003 - yolo_layer_1_loss: 1.9235e-04 - yolo_layer_2_loss: 0.2225 - yolo_layer_3_loss: 2.9776resizing:  448 448\n","138/204 [===================>..........] - ETA: 38s - loss: 3.1778 - yolo_layer_1_loss: 1.9209e-04 - yolo_layer_2_loss: 0.2193 - yolo_layer_3_loss: 2.9583resizing:  416 416\n","155/204 [=====================>........] - ETA: 29s - loss: 3.1456 - yolo_layer_1_loss: 1.9271e-04 - yolo_layer_2_loss: 0.2275 - yolo_layer_3_loss: 2.9180resizing:  416 416\n","156/204 [=====================>........] - ETA: 28s - loss: 3.1367 - yolo_layer_1_loss: 1.9251e-04 - yolo_layer_2_loss: 0.2260 - yolo_layer_3_loss: 2.9104resizing:  448 448\n","159/204 [======================>.......] - ETA: 26s - loss: 3.1307 - yolo_layer_1_loss: 1.9265e-04 - yolo_layer_2_loss: 0.2218 - yolo_layer_3_loss: 2.9087resizing:  384 384\n","171/204 [========================>.....] - ETA: 19s - loss: 3.1714 - yolo_layer_1_loss: 1.9439e-04 - yolo_layer_2_loss: 0.2235 - yolo_layer_3_loss: 2.9477resizing:  352 352\n","172/204 [========================>.....] - ETA: 19s - loss: 3.1744 - yolo_layer_1_loss: 1.9432e-04 - yolo_layer_2_loss: 0.2222 - yolo_layer_3_loss: 2.9519resizing:  416 416\n","173/204 [========================>.....] - ETA: 18s - loss: 3.1901 - yolo_layer_1_loss: 1.9410e-04 - yolo_layer_2_loss: 0.2209 - yolo_layer_3_loss: 2.9689resizing:  448 448\n","204/204 [==============================] - 124s 608ms/step - loss: 3.1140 - yolo_layer_1_loss: 1.9562e-04 - yolo_layer_2_loss: 0.2422 - yolo_layer_3_loss: 2.8716\n","\n","Epoch 00055: loss did not improve from 3.07323\n","\n","Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","Epoch 56/103\n","  2/204 [..............................] - ETA: 2:22 - loss: 2.7688 - yolo_layer_1_loss: 2.0394e-04 - yolo_layer_2_loss: 0.0014 - yolo_layer_3_loss: 2.7672resizing:  448 448\n","  4/204 [..............................] - ETA: 2:20 - loss: 2.5360 - yolo_layer_1_loss: 2.0349e-04 - yolo_layer_2_loss: 0.0037 - yolo_layer_3_loss: 2.5321resizing:  384 384\n"," 22/204 [==>...........................] - ETA: 1:53 - loss: 2.4126 - yolo_layer_1_loss: 1.9621e-04 - yolo_layer_2_loss: 0.1364 - yolo_layer_3_loss: 2.2760resizing:  384 384\n"," 23/204 [==>...........................] - ETA: 1:52 - loss: 2.3894 - yolo_layer_1_loss: 1.9489e-04 - yolo_layer_2_loss: 0.1339 - yolo_layer_3_loss: 2.2552resizing:  352 352\n"," 27/204 [==>...........................] - ETA: 1:47 - loss: 2.4787 - yolo_layer_1_loss: 1.9445e-04 - yolo_layer_2_loss: 0.1726 - yolo_layer_3_loss: 2.3059resizing:  448 448\n"," 28/204 [===>..........................] - ETA: 1:46 - loss: 2.4809 - yolo_layer_1_loss: 1.9584e-04 - yolo_layer_2_loss: 0.1665 - yolo_layer_3_loss: 2.3143resizing:  384 384\n"," 57/204 [=======>......................] - ETA: 1:24 - loss: 2.9750 - yolo_layer_1_loss: 1.8575e-04 - yolo_layer_2_loss: 0.1794 - yolo_layer_3_loss: 2.7954resizing:  448 448\n"," 66/204 [========>.....................] - ETA: 1:18 - loss: 2.8997 - yolo_layer_1_loss: 1.8438e-04 - yolo_layer_2_loss: 0.1699 - yolo_layer_3_loss: 2.7296resizing:  384 384\n"," 70/204 [=========>....................] - ETA: 1:17 - loss: 2.9105 - yolo_layer_1_loss: 1.8733e-04 - yolo_layer_2_loss: 0.1604 - yolo_layer_3_loss: 2.7500resizing:  416 416\n"," 71/204 [=========>....................] - ETA: 1:17 - loss: 2.9017 - yolo_layer_1_loss: 1.8828e-04 - yolo_layer_2_loss: 0.1648 - yolo_layer_3_loss: 2.7367resizing:  448 448\n"," 77/204 [==========>...................] - ETA: 1:14 - loss: 2.8470 - yolo_layer_1_loss: 1.9026e-04 - yolo_layer_2_loss: 0.1521 - yolo_layer_3_loss: 2.6948resizing:  416 416\n"," 84/204 [===========>..................] - ETA: 1:10 - loss: 2.8089 - yolo_layer_1_loss: 1.8949e-04 - yolo_layer_2_loss: 0.1521 - yolo_layer_3_loss: 2.6566resizing:  384 384\n","105/204 [==============>...............] - ETA: 58s - loss: 2.9817 - yolo_layer_1_loss: 1.9040e-04 - yolo_layer_2_loss: 0.1471 - yolo_layer_3_loss: 2.8344resizing:  384 384\n","110/204 [===============>..............] - ETA: 55s - loss: 2.9992 - yolo_layer_1_loss: 1.8908e-04 - yolo_layer_2_loss: 0.1405 - yolo_layer_3_loss: 2.8585resizing:  448 448\n","113/204 [===============>..............] - ETA: 53s - loss: 2.9956 - yolo_layer_1_loss: 1.8868e-04 - yolo_layer_2_loss: 0.1420 - yolo_layer_3_loss: 2.8535resizing:  352 352\n","132/204 [==================>...........] - ETA: 42s - loss: 2.9995 - yolo_layer_1_loss: 1.8728e-04 - yolo_layer_2_loss: 0.1308 - yolo_layer_3_loss: 2.8686resizing:  416 416\n","133/204 [==================>...........] - ETA: 41s - loss: 2.9889 - yolo_layer_1_loss: 1.8708e-04 - yolo_layer_2_loss: 0.1298 - yolo_layer_3_loss: 2.8590resizing:  352 352\n","138/204 [===================>..........] - ETA: 38s - loss: 3.0022 - yolo_layer_1_loss: 1.8597e-04 - yolo_layer_2_loss: 0.1251 - yolo_layer_3_loss: 2.8769resizing:  384 384\n","154/204 [=====================>........] - ETA: 28s - loss: 2.9789 - yolo_layer_1_loss: 1.8368e-04 - yolo_layer_2_loss: 0.1196 - yolo_layer_3_loss: 2.8591resizing:  448 448\n","158/204 [======================>.......] - ETA: 26s - loss: 2.9735 - yolo_layer_1_loss: 1.8345e-04 - yolo_layer_2_loss: 0.1256 - yolo_layer_3_loss: 2.8477resizing:  416 416\n","161/204 [======================>.......] - ETA: 24s - loss: 2.9892 - yolo_layer_1_loss: 1.8412e-04 - yolo_layer_2_loss: 0.1233 - yolo_layer_3_loss: 2.8657resizing:  448 448\n","165/204 [=======================>......] - ETA: 22s - loss: 2.9932 - yolo_layer_1_loss: 1.8527e-04 - yolo_layer_2_loss: 0.1208 - yolo_layer_3_loss: 2.8721resizing:  352 352\n","167/204 [=======================>......] - ETA: 21s - loss: 3.0246 - yolo_layer_1_loss: 1.8549e-04 - yolo_layer_2_loss: 0.1194 - yolo_layer_3_loss: 2.9050resizing:  416 416\n","181/204 [=========================>....] - ETA: 13s - loss: 3.0152 - yolo_layer_1_loss: 1.8585e-04 - yolo_layer_2_loss: 0.1154 - yolo_layer_3_loss: 2.8996resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 3.0750 - yolo_layer_1_loss: 1.8609e-04 - yolo_layer_2_loss: 0.1205 - yolo_layer_3_loss: 2.9543resizing:  416 416\n","resizing:  416 416\n","204/204 [==============================] - 119s 582ms/step - loss: 3.0821 - yolo_layer_1_loss: 1.8586e-04 - yolo_layer_2_loss: 0.1243 - yolo_layer_3_loss: 2.9577\n","\n","Epoch 00056: loss did not improve from 3.07323\n","Epoch 57/103\n","  3/204 [..............................] - ETA: 2:11 - loss: 2.1710 - yolo_layer_1_loss: 1.9006e-04 - yolo_layer_2_loss: 0.0013 - yolo_layer_3_loss: 2.1695resizing:  352 352\n","  4/204 [..............................] - ETA: 2:10 - loss: 3.0050 - yolo_layer_1_loss: 1.9451e-04 - yolo_layer_2_loss: 0.0012 - yolo_layer_3_loss: 3.0036resizing:  352 352\n","  8/204 [>.............................] - ETA: 2:07 - loss: 3.3151 - yolo_layer_1_loss: 1.9236e-04 - yolo_layer_2_loss: 0.0011 - yolo_layer_3_loss: 3.3139resizing:  384 384\n"," 38/204 [====>.........................] - ETA: 1:32 - loss: 2.9103 - yolo_layer_1_loss: 1.7105e-04 - yolo_layer_2_loss: 0.0487 - yolo_layer_3_loss: 2.8614resizing:  416 416\n"," 56/204 [=======>......................] - ETA: 1:23 - loss: 2.8233 - yolo_layer_1_loss: 1.7233e-04 - yolo_layer_2_loss: 0.0519 - yolo_layer_3_loss: 2.7712resizing:  448 448\n","resizing:  448 448\n"," 59/204 [=======>......................] - ETA: 1:22 - loss: 2.8638 - yolo_layer_1_loss: 1.7494e-04 - yolo_layer_2_loss: 0.0493 - yolo_layer_3_loss: 2.8142resizing:  384 384\n"," 80/204 [==========>...................] - ETA: 1:12 - loss: 2.8499 - yolo_layer_1_loss: 1.8077e-04 - yolo_layer_2_loss: 0.1079 - yolo_layer_3_loss: 2.7418resizing:  416 416\n"," 81/204 [==========>...................] - ETA: 1:11 - loss: 2.8415 - yolo_layer_1_loss: 1.8064e-04 - yolo_layer_2_loss: 0.1066 - yolo_layer_3_loss: 2.7347resizing:  448 448\n"," 85/204 [===========>..................] - ETA: 1:08 - loss: 2.8410 - yolo_layer_1_loss: 1.8091e-04 - yolo_layer_2_loss: 0.1133 - yolo_layer_3_loss: 2.7275resizing:  384 384\n","110/204 [===============>..............] - ETA: 54s - loss: 2.7359 - yolo_layer_1_loss: 1.8098e-04 - yolo_layer_2_loss: 0.1241 - yolo_layer_3_loss: 2.6116resizing:  448 448\n","117/204 [================>.............] - ETA: 50s - loss: 2.7828 - yolo_layer_1_loss: 1.8041e-04 - yolo_layer_2_loss: 0.1168 - yolo_layer_3_loss: 2.6658resizing:  352 352\n","118/204 [================>.............] - ETA: 49s - loss: 2.7774 - yolo_layer_1_loss: 1.8029e-04 - yolo_layer_2_loss: 0.1158 - yolo_layer_3_loss: 2.6614resizing:  416 416\n","123/204 [=================>............] - ETA: 46s - loss: 2.7870 - yolo_layer_1_loss: 1.8148e-04 - yolo_layer_2_loss: 0.1403 - yolo_layer_3_loss: 2.6466resizing:  416 416\n","127/204 [=================>............] - ETA: 44s - loss: 2.7964 - yolo_layer_1_loss: 1.8189e-04 - yolo_layer_2_loss: 0.1359 - yolo_layer_3_loss: 2.6604resizing:  352 352\n","132/204 [==================>...........] - ETA: 42s - loss: 2.8283 - yolo_layer_1_loss: 1.8263e-04 - yolo_layer_2_loss: 0.1308 - yolo_layer_3_loss: 2.6973resizing:  416 416\n","152/204 [=====================>........] - ETA: 30s - loss: 2.9199 - yolo_layer_1_loss: 1.8295e-04 - yolo_layer_2_loss: 0.1423 - yolo_layer_3_loss: 2.7774resizing:  416 416\n","resizing:  448 448\n","158/204 [======================>.......] - ETA: 27s - loss: 2.9115 - yolo_layer_1_loss: 1.8371e-04 - yolo_layer_2_loss: 0.1370 - yolo_layer_3_loss: 2.7744resizing:  352 352\n","168/204 [=======================>......] - ETA: 21s - loss: 2.9597 - yolo_layer_1_loss: 1.8691e-04 - yolo_layer_2_loss: 0.1554 - yolo_layer_3_loss: 2.8041resizing:  448 448\n","186/204 [==========================>...] - ETA: 10s - loss: 2.9557 - yolo_layer_1_loss: 1.8755e-04 - yolo_layer_2_loss: 0.1489 - yolo_layer_3_loss: 2.8066resizing:  384 384\n","187/204 [==========================>...] - ETA: 10s - loss: 2.9579 - yolo_layer_1_loss: 1.8791e-04 - yolo_layer_2_loss: 0.1537 - yolo_layer_3_loss: 2.8040resizing:  384 384\n","204/204 [==============================] - 122s 600ms/step - loss: 2.9395 - yolo_layer_1_loss: 1.8926e-04 - yolo_layer_2_loss: 0.1478 - yolo_layer_3_loss: 2.7915\n","\n","Epoch 00057: loss improved from 3.07323 to 2.93947, saving model to /drive/My Drive/GTSDB/gtsdb.h5\n","Epoch 58/103\n","resizing:  416 416\n","  4/204 [..............................] - ETA: 1:50 - loss: 3.4558 - yolo_layer_1_loss: 1.6769e-04 - yolo_layer_2_loss: 0.2611 - yolo_layer_3_loss: 3.1945resizing:  384 384\n","  6/204 [..............................] - ETA: 1:52 - loss: 3.4500 - yolo_layer_1_loss: 1.7175e-04 - yolo_layer_2_loss: 0.2906 - yolo_layer_3_loss: 3.1593resizing:  448 448\n","  9/204 [>.............................] - ETA: 1:55 - loss: 3.0244 - yolo_layer_1_loss: 1.8118e-04 - yolo_layer_2_loss: 0.1940 - yolo_layer_3_loss: 2.8303resizing:  448 448\n"," 32/204 [===>..........................] - ETA: 1:51 - loss: 2.8649 - yolo_layer_1_loss: 2.1008e-04 - yolo_layer_2_loss: 0.2743 - yolo_layer_3_loss: 2.5904resizing:  352 352\n"," 39/204 [====>.........................] - ETA: 1:48 - loss: 2.8894 - yolo_layer_1_loss: 2.1149e-04 - yolo_layer_2_loss: 0.2353 - yolo_layer_3_loss: 2.6539resizing:  352 352\n"," 52/204 [======>.......................] - ETA: 1:36 - loss: 2.9117 - yolo_layer_1_loss: 2.1186e-04 - yolo_layer_2_loss: 0.2127 - yolo_layer_3_loss: 2.6988resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:32 - loss: 2.8853 - yolo_layer_1_loss: 2.0918e-04 - yolo_layer_2_loss: 0.1976 - yolo_layer_3_loss: 2.6875resizing:  352 352\n"," 60/204 [=======>......................] - ETA: 1:29 - loss: 2.8566 - yolo_layer_1_loss: 2.0670e-04 - yolo_layer_2_loss: 0.1844 - yolo_layer_3_loss: 2.6719resizing:  448 448\n"," 67/204 [========>.....................] - ETA: 1:23 - loss: 2.9129 - yolo_layer_1_loss: 2.0149e-04 - yolo_layer_2_loss: 0.1653 - yolo_layer_3_loss: 2.7474resizing:  416 416\n"," 68/204 [=========>....................] - ETA: 1:22 - loss: 2.9163 - yolo_layer_1_loss: 2.0072e-04 - yolo_layer_2_loss: 0.1629 - yolo_layer_3_loss: 2.7533resizing:  416 416\n"," 80/204 [==========>...................] - ETA: 1:16 - loss: 2.9868 - yolo_layer_1_loss: 2.0256e-04 - yolo_layer_2_loss: 0.1700 - yolo_layer_3_loss: 2.8166resizing:  448 448\n","103/204 [==============>...............] - ETA: 1:03 - loss: 2.9978 - yolo_layer_1_loss: 2.0357e-04 - yolo_layer_2_loss: 0.1677 - yolo_layer_3_loss: 2.8299resizing:  448 448\n","107/204 [==============>...............] - ETA: 1:01 - loss: 2.9664 - yolo_layer_1_loss: 2.0470e-04 - yolo_layer_2_loss: 0.1614 - yolo_layer_3_loss: 2.8048resizing:  352 352\n","110/204 [===============>..............] - ETA: 59s - loss: 2.9399 - yolo_layer_1_loss: 2.0685e-04 - yolo_layer_2_loss: 0.1643 - yolo_layer_3_loss: 2.7754resizing:  384 384\n","116/204 [================>.............] - ETA: 55s - loss: 2.9280 - yolo_layer_1_loss: 2.0777e-04 - yolo_layer_2_loss: 0.1686 - yolo_layer_3_loss: 2.7592resizing:  448 448\n","117/204 [================>.............] - ETA: 55s - loss: 2.9148 - yolo_layer_1_loss: 2.0761e-04 - yolo_layer_2_loss: 0.1671 - yolo_layer_3_loss: 2.7475resizing:  448 448\n","119/204 [================>.............] - ETA: 53s - loss: 2.9338 - yolo_layer_1_loss: 2.0672e-04 - yolo_layer_2_loss: 0.1643 - yolo_layer_3_loss: 2.7693resizing:  352 352\n","153/204 [=====================>........] - ETA: 31s - loss: 3.0063 - yolo_layer_1_loss: 1.9889e-04 - yolo_layer_2_loss: 0.1564 - yolo_layer_3_loss: 2.8496resizing:  448 448\n","155/204 [=====================>........] - ETA: 29s - loss: 3.0180 - yolo_layer_1_loss: 1.9838e-04 - yolo_layer_2_loss: 0.1544 - yolo_layer_3_loss: 2.8634resizing:  384 384\n","157/204 [======================>.......] - ETA: 28s - loss: 3.0178 - yolo_layer_1_loss: 1.9826e-04 - yolo_layer_2_loss: 0.1545 - yolo_layer_3_loss: 2.8631resizing:  416 416\n","168/204 [=======================>......] - ETA: 21s - loss: 3.0033 - yolo_layer_1_loss: 1.9828e-04 - yolo_layer_2_loss: 0.1654 - yolo_layer_3_loss: 2.8377resizing:  384 384\n","169/204 [=======================>......] - ETA: 21s - loss: 3.0026 - yolo_layer_1_loss: 1.9819e-04 - yolo_layer_2_loss: 0.1644 - yolo_layer_3_loss: 2.8380resizing:  352 352\n","184/204 [==========================>...] - ETA: 12s - loss: 2.9499 - yolo_layer_1_loss: 1.9682e-04 - yolo_layer_2_loss: 0.1679 - yolo_layer_3_loss: 2.7818resizing:  416 416\n","204/204 [==============================] - 123s 604ms/step - loss: 2.9997 - yolo_layer_1_loss: 1.9565e-04 - yolo_layer_2_loss: 0.1607 - yolo_layer_3_loss: 2.8388\n","\n","Epoch 00058: loss did not improve from 2.93947\n","Epoch 59/103\n","  6/204 [..............................] - ETA: 2:08 - loss: 3.2733 - yolo_layer_1_loss: 1.7970e-04 - yolo_layer_2_loss: 8.4024e-04 - yolo_layer_3_loss: 3.2723resizing:  352 352\n"," 12/204 [>.............................] - ETA: 2:05 - loss: 3.6251 - yolo_layer_1_loss: 1.8071e-04 - yolo_layer_2_loss: 0.2449 - yolo_layer_3_loss: 3.3800resizing:  384 384\n"," 17/204 [=>............................] - ETA: 2:01 - loss: 3.3702 - yolo_layer_1_loss: 1.8408e-04 - yolo_layer_2_loss: 0.3267 - yolo_layer_3_loss: 3.0434resizing:  448 448\n"," 18/204 [=>............................] - ETA: 1:59 - loss: 3.2863 - yolo_layer_1_loss: 1.8138e-04 - yolo_layer_2_loss: 0.3086 - yolo_layer_3_loss: 2.9775resizing:  416 416\n"," 25/204 [==>...........................] - ETA: 1:48 - loss: 3.2718 - yolo_layer_1_loss: 1.7722e-04 - yolo_layer_2_loss: 0.2224 - yolo_layer_3_loss: 3.0492resizing:  416 416\n"," 32/204 [===>..........................] - ETA: 1:44 - loss: 3.2252 - yolo_layer_1_loss: 1.7739e-04 - yolo_layer_2_loss: 0.3695 - yolo_layer_3_loss: 2.8556resizing:  384 384\n"," 59/204 [=======>......................] - ETA: 1:26 - loss: 3.1185 - yolo_layer_1_loss: 1.7899e-04 - yolo_layer_2_loss: 0.3009 - yolo_layer_3_loss: 2.8174resizing:  416 416\n"," 76/204 [==========>...................] - ETA: 1:16 - loss: 3.0100 - yolo_layer_1_loss: 1.7841e-04 - yolo_layer_2_loss: 0.2399 - yolo_layer_3_loss: 2.7700resizing:  352 352\n"," 81/204 [==========>...................] - ETA: 1:13 - loss: 3.0055 - yolo_layer_1_loss: 1.7919e-04 - yolo_layer_2_loss: 0.2251 - yolo_layer_3_loss: 2.7802resizing:  352 352\n"," 85/204 [===========>..................] - ETA: 1:11 - loss: 3.0718 - yolo_layer_1_loss: 1.7924e-04 - yolo_layer_2_loss: 0.2146 - yolo_layer_3_loss: 2.8570resizing:  384 384\n"," 86/204 [===========>..................] - ETA: 1:10 - loss: 3.0543 - yolo_layer_1_loss: 1.7928e-04 - yolo_layer_2_loss: 0.2121 - yolo_layer_3_loss: 2.8420resizing:  352 352\n"," 88/204 [===========>..................] - ETA: 1:09 - loss: 3.0407 - yolo_layer_1_loss: 1.7958e-04 - yolo_layer_2_loss: 0.2075 - yolo_layer_3_loss: 2.8330resizing:  448 448\n","105/204 [==============>...............] - ETA: 58s - loss: 3.1480 - yolo_layer_1_loss: 1.8056e-04 - yolo_layer_2_loss: 0.2301 - yolo_layer_3_loss: 2.9177resizing:  448 448\n","107/204 [==============>...............] - ETA: 58s - loss: 3.1192 - yolo_layer_1_loss: 1.8120e-04 - yolo_layer_2_loss: 0.2258 - yolo_layer_3_loss: 2.8932resizing:  384 384\n","111/204 [===============>..............] - ETA: 55s - loss: 3.1194 - yolo_layer_1_loss: 1.8260e-04 - yolo_layer_2_loss: 0.2221 - yolo_layer_3_loss: 2.8971resizing:  352 352\n","112/204 [===============>..............] - ETA: 55s - loss: 3.1133 - yolo_layer_1_loss: 1.8325e-04 - yolo_layer_2_loss: 0.2240 - yolo_layer_3_loss: 2.8892resizing:  384 384\n","128/204 [=================>............] - ETA: 45s - loss: 3.0742 - yolo_layer_1_loss: 1.8585e-04 - yolo_layer_2_loss: 0.2133 - yolo_layer_3_loss: 2.8607resizing:  416 416\n","140/204 [===================>..........] - ETA: 38s - loss: 3.0420 - yolo_layer_1_loss: 1.8413e-04 - yolo_layer_2_loss: 0.1955 - yolo_layer_3_loss: 2.8463resizing:  416 416\n","153/204 [=====================>........] - ETA: 30s - loss: 3.0529 - yolo_layer_1_loss: 1.8513e-04 - yolo_layer_2_loss: 0.2256 - yolo_layer_3_loss: 2.8271resizing:  384 384\n","154/204 [=====================>........] - ETA: 30s - loss: 3.0443 - yolo_layer_1_loss: 1.8529e-04 - yolo_layer_2_loss: 0.2242 - yolo_layer_3_loss: 2.8200resizing:  352 352\n","162/204 [======================>.......] - ETA: 25s - loss: 3.0259 - yolo_layer_1_loss: 1.8633e-04 - yolo_layer_2_loss: 0.2220 - yolo_layer_3_loss: 2.8038resizing:  416 416\n","173/204 [========================>.....] - ETA: 18s - loss: 3.0432 - yolo_layer_1_loss: 1.8460e-04 - yolo_layer_2_loss: 0.2079 - yolo_layer_3_loss: 2.8351resizing:  384 384\n","174/204 [========================>.....] - ETA: 17s - loss: 3.0321 - yolo_layer_1_loss: 1.8455e-04 - yolo_layer_2_loss: 0.2067 - yolo_layer_3_loss: 2.8252resizing:  416 416\n","187/204 [==========================>...] - ETA: 10s - loss: 2.9987 - yolo_layer_1_loss: 1.8472e-04 - yolo_layer_2_loss: 0.2047 - yolo_layer_3_loss: 2.7938resizing:  384 384\n","204/204 [==============================] - 122s 598ms/step - loss: 3.0190 - yolo_layer_1_loss: 1.8814e-04 - yolo_layer_2_loss: 0.2103 - yolo_layer_3_loss: 2.8086\n","\n","Epoch 00059: loss did not improve from 2.93947\n","Epoch 60/103\n","  1/204 [..............................] - ETA: 1:47 - loss: 1.6432 - yolo_layer_1_loss: 1.6337e-04 - yolo_layer_2_loss: 7.1742e-04 - yolo_layer_3_loss: 1.6423resizing:  352 352\n","  3/204 [..............................] - ETA: 1:50 - loss: 2.3135 - yolo_layer_1_loss: 1.6287e-04 - yolo_layer_2_loss: 0.1620 - yolo_layer_3_loss: 2.1514resizing:  384 384\n","  8/204 [>.............................] - ETA: 1:44 - loss: 2.8316 - yolo_layer_1_loss: 1.7027e-04 - yolo_layer_2_loss: 0.1982 - yolo_layer_3_loss: 2.6332resizing:  352 352\n"," 28/204 [===>..........................] - ETA: 1:32 - loss: 3.8229 - yolo_layer_1_loss: 1.7034e-04 - yolo_layer_2_loss: 0.2247 - yolo_layer_3_loss: 3.5981resizing:  384 384\n"," 30/204 [===>..........................] - ETA: 1:31 - loss: 3.9567 - yolo_layer_1_loss: 1.6991e-04 - yolo_layer_2_loss: 0.2098 - yolo_layer_3_loss: 3.7467resizing:  416 416\n"," 34/204 [====>.........................] - ETA: 1:28 - loss: 3.8863 - yolo_layer_1_loss: 1.6719e-04 - yolo_layer_2_loss: 0.1852 - yolo_layer_3_loss: 3.7009resizing:  384 384\n"," 51/204 [======>.......................] - ETA: 1:20 - loss: 3.7705 - yolo_layer_1_loss: 1.6774e-04 - yolo_layer_2_loss: 0.1458 - yolo_layer_3_loss: 3.6246resizing:  448 448\n"," 55/204 [=======>......................] - ETA: 1:18 - loss: 3.7459 - yolo_layer_1_loss: 1.6775e-04 - yolo_layer_2_loss: 0.1647 - yolo_layer_3_loss: 3.5811resizing:  416 416\n"," 64/204 [========>.....................] - ETA: 1:17 - loss: 3.6379 - yolo_layer_1_loss: 1.7465e-04 - yolo_layer_2_loss: 0.1861 - yolo_layer_3_loss: 3.4516resizing:  416 416\n"," 69/204 [=========>....................] - ETA: 1:15 - loss: 3.6587 - yolo_layer_1_loss: 1.7664e-04 - yolo_layer_2_loss: 0.1851 - yolo_layer_3_loss: 3.4734resizing:  448 448\n"," 71/204 [=========>....................] - ETA: 1:14 - loss: 3.6242 - yolo_layer_1_loss: 1.7720e-04 - yolo_layer_2_loss: 0.1799 - yolo_layer_3_loss: 3.4441resizing:  384 384\n"," 76/204 [==========>...................] - ETA: 1:12 - loss: 3.6880 - yolo_layer_1_loss: 1.7969e-04 - yolo_layer_2_loss: 0.1934 - yolo_layer_3_loss: 3.4944resizing:  384 384\n","103/204 [==============>...............] - ETA: 57s - loss: 3.5159 - yolo_layer_1_loss: 1.7811e-04 - yolo_layer_2_loss: 0.1439 - yolo_layer_3_loss: 3.3718resizing:  416 416\n","104/204 [==============>...............] - ETA: 56s - loss: 3.5037 - yolo_layer_1_loss: 1.7825e-04 - yolo_layer_2_loss: 0.1426 - yolo_layer_3_loss: 3.3610resizing:  416 416\n","105/204 [==============>...............] - ETA: 56s - loss: 3.4873 - yolo_layer_1_loss: 1.7805e-04 - yolo_layer_2_loss: 0.1412 - yolo_layer_3_loss: 3.3459resizing:  448 448\n","130/204 [==================>...........] - ETA: 43s - loss: 3.4282 - yolo_layer_1_loss: 1.8813e-04 - yolo_layer_2_loss: 0.1981 - yolo_layer_3_loss: 3.2299resizing:  448 448\n","136/204 [===================>..........] - ETA: 40s - loss: 3.3846 - yolo_layer_1_loss: 1.9025e-04 - yolo_layer_2_loss: 0.1908 - yolo_layer_3_loss: 3.1935resizing:  416 416\n","139/204 [===================>..........] - ETA: 38s - loss: 3.3926 - yolo_layer_1_loss: 1.9080e-04 - yolo_layer_2_loss: 0.1932 - yolo_layer_3_loss: 3.1992resizing:  352 352\n","158/204 [======================>.......] - ETA: 27s - loss: 3.2813 - yolo_layer_1_loss: 1.9088e-04 - yolo_layer_2_loss: 0.1989 - yolo_layer_3_loss: 3.0822resizing:  384 384\n","173/204 [========================>.....] - ETA: 18s - loss: 3.2650 - yolo_layer_1_loss: 1.8890e-04 - yolo_layer_2_loss: 0.1853 - yolo_layer_3_loss: 3.0795resizing:  384 384\n","174/204 [========================>.....] - ETA: 17s - loss: 3.2783 - yolo_layer_1_loss: 1.8892e-04 - yolo_layer_2_loss: 0.1843 - yolo_layer_3_loss: 3.0938resizing:  416 416\n","185/204 [==========================>...] - ETA: 11s - loss: 3.2993 - yolo_layer_1_loss: 1.8756e-04 - yolo_layer_2_loss: 0.1855 - yolo_layer_3_loss: 3.1136resizing:  416 416\n","186/204 [==========================>...] - ETA: 10s - loss: 3.3081 - yolo_layer_1_loss: 1.8780e-04 - yolo_layer_2_loss: 0.1883 - yolo_layer_3_loss: 3.1196resizing:  352 352\n","192/204 [===========================>..] - ETA: 7s - loss: 3.2907 - yolo_layer_1_loss: 1.8899e-04 - yolo_layer_2_loss: 0.1893 - yolo_layer_3_loss: 3.1012resizing:  352 352\n","204/204 [==============================] - 120s 590ms/step - loss: 3.2425 - yolo_layer_1_loss: 1.8808e-04 - yolo_layer_2_loss: 0.1903 - yolo_layer_3_loss: 3.0520\n","\n","Epoch 00060: loss did not improve from 2.93947\n","Epoch 61/103\n","  2/204 [..............................] - ETA: 1:40 - loss: 2.6407 - yolo_layer_1_loss: 2.0957e-04 - yolo_layer_2_loss: 9.4045e-04 - yolo_layer_3_loss: 2.6395resizing:  416 416\n","  3/204 [..............................] - ETA: 1:41 - loss: 2.8728 - yolo_layer_1_loss: 1.9939e-04 - yolo_layer_2_loss: 9.1075e-04 - yolo_layer_3_loss: 2.8717resizing:  352 352\n","  8/204 [>.............................] - ETA: 1:41 - loss: 3.6007 - yolo_layer_1_loss: 1.7862e-04 - yolo_layer_2_loss: 8.1018e-04 - yolo_layer_3_loss: 3.5997resizing:  384 384\n","  9/204 [>.............................] - ETA: 1:40 - loss: 3.5141 - yolo_layer_1_loss: 1.7429e-04 - yolo_layer_2_loss: 8.0041e-04 - yolo_layer_3_loss: 3.5131resizing:  384 384\n"," 26/204 [==>...........................] - ETA: 1:31 - loss: 3.2373 - yolo_layer_1_loss: 1.7187e-04 - yolo_layer_2_loss: 0.1073 - yolo_layer_3_loss: 3.1299resizing:  384 384\n"," 35/204 [====>.........................] - ETA: 1:28 - loss: 3.3223 - yolo_layer_1_loss: 1.6911e-04 - yolo_layer_2_loss: 0.0802 - yolo_layer_3_loss: 3.2420resizing:  448 448\n"," 51/204 [======>.......................] - ETA: 1:23 - loss: 3.2635 - yolo_layer_1_loss: 1.7781e-04 - yolo_layer_2_loss: 0.0745 - yolo_layer_3_loss: 3.1888resizing:  384 384\n"," 53/204 [======>.......................] - ETA: 1:23 - loss: 3.2874 - yolo_layer_1_loss: 1.8102e-04 - yolo_layer_2_loss: 0.0894 - yolo_layer_3_loss: 3.1978resizing:  416 416\n"," 64/204 [========>.....................] - ETA: 1:18 - loss: 3.1422 - yolo_layer_1_loss: 1.8320e-04 - yolo_layer_2_loss: 0.0925 - yolo_layer_3_loss: 3.0495resizing:  448 448\n"," 68/204 [=========>....................] - ETA: 1:17 - loss: 3.0896 - yolo_layer_1_loss: 1.8468e-04 - yolo_layer_2_loss: 0.0954 - yolo_layer_3_loss: 2.9940resizing:  416 416\n"," 69/204 [=========>....................] - ETA: 1:16 - loss: 3.0860 - yolo_layer_1_loss: 1.8476e-04 - yolo_layer_2_loss: 0.0940 - yolo_layer_3_loss: 2.9918resizing:  448 448\n"," 86/204 [===========>..................] - ETA: 1:09 - loss: 3.1095 - yolo_layer_1_loss: 1.9040e-04 - yolo_layer_2_loss: 0.2187 - yolo_layer_3_loss: 2.8906resizing:  416 416\n","105/204 [==============>...............] - ETA: 1:00 - loss: 3.0748 - yolo_layer_1_loss: 1.9494e-04 - yolo_layer_2_loss: 0.2563 - yolo_layer_3_loss: 2.8183resizing:  448 448\n","107/204 [==============>...............] - ETA: 58s - loss: 3.0397 - yolo_layer_1_loss: 1.9512e-04 - yolo_layer_2_loss: 0.2515 - yolo_layer_3_loss: 2.7880resizing:  448 448\n","111/204 [===============>..............] - ETA: 56s - loss: 3.0526 - yolo_layer_1_loss: 1.9460e-04 - yolo_layer_2_loss: 0.2506 - yolo_layer_3_loss: 2.8018resizing:  352 352\n","118/204 [================>.............] - ETA: 52s - loss: 3.0063 - yolo_layer_1_loss: 1.9701e-04 - yolo_layer_2_loss: 0.2430 - yolo_layer_3_loss: 2.7632resizing:  384 384\n","140/204 [===================>..........] - ETA: 38s - loss: 3.0140 - yolo_layer_1_loss: 1.9486e-04 - yolo_layer_2_loss: 0.2395 - yolo_layer_3_loss: 2.7743resizing:  352 352\n","141/204 [===================>..........] - ETA: 38s - loss: 3.0325 - yolo_layer_1_loss: 1.9475e-04 - yolo_layer_2_loss: 0.2424 - yolo_layer_3_loss: 2.7899resizing:  448 448\n","152/204 [=====================>........] - ETA: 31s - loss: 3.0841 - yolo_layer_1_loss: 1.9300e-04 - yolo_layer_2_loss: 0.2514 - yolo_layer_3_loss: 2.8325resizing:  384 384\n","157/204 [======================>.......] - ETA: 28s - loss: 3.1272 - yolo_layer_1_loss: 1.9338e-04 - yolo_layer_2_loss: 0.2560 - yolo_layer_3_loss: 2.8709resizing:  448 448\n","171/204 [========================>.....] - ETA: 19s - loss: 3.1737 - yolo_layer_1_loss: 1.9405e-04 - yolo_layer_2_loss: 0.2506 - yolo_layer_3_loss: 2.9228resizing:  416 416\n","184/204 [==========================>...] - ETA: 12s - loss: 3.1837 - yolo_layer_1_loss: 1.9562e-04 - yolo_layer_2_loss: 0.2511 - yolo_layer_3_loss: 2.9324resizing:  448 448\n","191/204 [===========================>..] - ETA: 7s - loss: 3.1791 - yolo_layer_1_loss: 1.9532e-04 - yolo_layer_2_loss: 0.2419 - yolo_layer_3_loss: 2.9370resizing:  352 352\n","192/204 [===========================>..] - ETA: 7s - loss: 3.1963 - yolo_layer_1_loss: 1.9532e-04 - yolo_layer_2_loss: 0.2407 - yolo_layer_3_loss: 2.9554resizing:  416 416\n","204/204 [==============================] - 125s 613ms/step - loss: 3.1794 - yolo_layer_1_loss: 1.9593e-04 - yolo_layer_2_loss: 0.2432 - yolo_layer_3_loss: 2.9360\n","\n","Epoch 00061: loss did not improve from 2.93947\n","\n","Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n","Epoch 62/103\n","resizing:  352 352\n","  2/204 [..............................] - ETA: 2:11 - loss: 1.8774 - yolo_layer_1_loss: 1.7563e-04 - yolo_layer_2_loss: 9.1019e-04 - yolo_layer_3_loss: 1.8763resizing:  416 416\n","  7/204 [>.............................] - ETA: 1:46 - loss: 2.9101 - yolo_layer_1_loss: 1.7171e-04 - yolo_layer_2_loss: 7.9491e-04 - yolo_layer_3_loss: 2.9091resizing:  448 448\n"," 22/204 [==>...........................] - ETA: 1:55 - loss: 3.3371 - yolo_layer_1_loss: 1.9854e-04 - yolo_layer_2_loss: 0.4901 - yolo_layer_3_loss: 2.8468resizing:  352 352\n"," 23/204 [==>...........................] - ETA: 1:55 - loss: 3.3839 - yolo_layer_1_loss: 1.9882e-04 - yolo_layer_2_loss: 0.4688 - yolo_layer_3_loss: 2.9149resizing:  448 448\n"," 34/204 [====>.........................] - ETA: 1:51 - loss: 3.1441 - yolo_layer_1_loss: 2.1121e-04 - yolo_layer_2_loss: 0.3803 - yolo_layer_3_loss: 2.7636resizing:  416 416\n"," 51/204 [======>.......................] - ETA: 1:41 - loss: 2.9573 - yolo_layer_1_loss: 2.0991e-04 - yolo_layer_2_loss: 0.3225 - yolo_layer_3_loss: 2.6346resizing:  352 352\n"," 59/204 [=======>......................] - ETA: 1:34 - loss: 2.9140 - yolo_layer_1_loss: 2.0463e-04 - yolo_layer_2_loss: 0.2827 - yolo_layer_3_loss: 2.6311resizing:  352 352\n"," 61/204 [=======>......................] - ETA: 1:32 - loss: 2.9356 - yolo_layer_1_loss: 2.1191e-04 - yolo_layer_2_loss: 0.2734 - yolo_layer_3_loss: 2.6620resizing:  352 352\n"," 72/204 [=========>....................] - ETA: 1:22 - loss: 2.9298 - yolo_layer_1_loss: 2.0557e-04 - yolo_layer_2_loss: 0.2318 - yolo_layer_3_loss: 2.6978resizing:  416 416\n"," 85/204 [===========>..................] - ETA: 1:12 - loss: 2.9808 - yolo_layer_1_loss: 1.9896e-04 - yolo_layer_2_loss: 0.2213 - yolo_layer_3_loss: 2.7593resizing:  448 448\n"," 87/204 [===========>..................] - ETA: 1:10 - loss: 2.9767 - yolo_layer_1_loss: 1.9894e-04 - yolo_layer_2_loss: 0.2163 - yolo_layer_3_loss: 2.7602resizing:  384 384\n","102/204 [==============>...............] - ETA: 1:02 - loss: 2.9359 - yolo_layer_1_loss: 1.9731e-04 - yolo_layer_2_loss: 0.2227 - yolo_layer_3_loss: 2.7130resizing:  448 448\n","104/204 [==============>...............] - ETA: 1:00 - loss: 2.9359 - yolo_layer_1_loss: 1.9669e-04 - yolo_layer_2_loss: 0.2281 - yolo_layer_3_loss: 2.7076resizing:  384 384\n","108/204 [==============>...............] - ETA: 58s - loss: 2.9502 - yolo_layer_1_loss: 1.9906e-04 - yolo_layer_2_loss: 0.2311 - yolo_layer_3_loss: 2.7189resizing:  448 448\n","133/204 [==================>...........] - ETA: 44s - loss: 2.9514 - yolo_layer_1_loss: 2.0304e-04 - yolo_layer_2_loss: 0.2089 - yolo_layer_3_loss: 2.7424resizing:  448 448\n","136/204 [===================>..........] - ETA: 42s - loss: 2.9517 - yolo_layer_1_loss: 2.0303e-04 - yolo_layer_2_loss: 0.2104 - yolo_layer_3_loss: 2.7411resizing:  416 416\n","138/204 [===================>..........] - ETA: 41s - loss: 2.9304 - yolo_layer_1_loss: 2.0327e-04 - yolo_layer_2_loss: 0.2103 - yolo_layer_3_loss: 2.7199resizing:  448 448\n","154/204 [=====================>........] - ETA: 31s - loss: 2.9586 - yolo_layer_1_loss: 2.0531e-04 - yolo_layer_2_loss: 0.2527 - yolo_layer_3_loss: 2.7057resizing:  384 384\n","155/204 [=====================>........] - ETA: 30s - loss: 2.9488 - yolo_layer_1_loss: 2.0528e-04 - yolo_layer_2_loss: 0.2511 - yolo_layer_3_loss: 2.6975resizing:  448 448\n","158/204 [======================>.......] - ETA: 29s - loss: 2.9192 - yolo_layer_1_loss: 2.0571e-04 - yolo_layer_2_loss: 0.2463 - yolo_layer_3_loss: 2.6726resizing:  448 448\n","160/204 [======================>.......] - ETA: 27s - loss: 2.9106 - yolo_layer_1_loss: 2.0551e-04 - yolo_layer_2_loss: 0.2433 - yolo_layer_3_loss: 2.6671resizing:  384 384\n","166/204 [=======================>......] - ETA: 24s - loss: 2.9152 - yolo_layer_1_loss: 2.0582e-04 - yolo_layer_2_loss: 0.2417 - yolo_layer_3_loss: 2.6733resizing:  384 384\n","185/204 [==========================>...] - ETA: 11s - loss: 2.9740 - yolo_layer_1_loss: 2.0407e-04 - yolo_layer_2_loss: 0.2254 - yolo_layer_3_loss: 2.7484resizing:  384 384\n","203/204 [============================>.] - ETA: 0s - loss: 3.0136 - yolo_layer_1_loss: 2.0219e-04 - yolo_layer_2_loss: 0.2194 - yolo_layer_3_loss: 2.7941resizing:  384 384\n","204/204 [==============================] - 127s 621ms/step - loss: 3.0296 - yolo_layer_1_loss: 2.0201e-04 - yolo_layer_2_loss: 0.2221 - yolo_layer_3_loss: 2.8073\n","\n","Epoch 00062: loss did not improve from 2.93947\n","Epoch 63/103\n","  2/204 [..............................] - ETA: 1:47 - loss: 3.3825 - yolo_layer_1_loss: 1.6673e-04 - yolo_layer_2_loss: 0.0015 - yolo_layer_3_loss: 3.3807    resizing:  352 352\n","  8/204 [>.............................] - ETA: 1:45 - loss: 3.6445 - yolo_layer_1_loss: 1.6926e-04 - yolo_layer_2_loss: 0.0482 - yolo_layer_3_loss: 3.5962resizing:  384 384\n","  9/204 [>.............................] - ETA: 1:44 - loss: 3.4835 - yolo_layer_1_loss: 1.6782e-04 - yolo_layer_2_loss: 0.0429 - yolo_layer_3_loss: 3.4404resizing:  352 352\n"," 11/204 [>.............................] - ETA: 1:42 - loss: 3.1554 - yolo_layer_1_loss: 1.6512e-04 - yolo_layer_2_loss: 0.0352 - yolo_layer_3_loss: 3.1200resizing:  416 416\n"," 15/204 [=>............................] - ETA: 1:38 - loss: 3.2617 - yolo_layer_1_loss: 1.6380e-04 - yolo_layer_2_loss: 0.0840 - yolo_layer_3_loss: 3.1775resizing:  384 384\n"," 50/204 [======>.......................] - ETA: 1:22 - loss: 3.2733 - yolo_layer_1_loss: 1.6874e-04 - yolo_layer_2_loss: 0.2601 - yolo_layer_3_loss: 3.0130resizing:  448 448\n"," 51/204 [======>.......................] - ETA: 1:22 - loss: 3.2726 - yolo_layer_1_loss: 1.6876e-04 - yolo_layer_2_loss: 0.2551 - yolo_layer_3_loss: 3.0173resizing:  416 416\n"," 54/204 [======>.......................] - ETA: 1:22 - loss: 3.2036 - yolo_layer_1_loss: 1.7129e-04 - yolo_layer_2_loss: 0.2409 - yolo_layer_3_loss: 2.9624resizing:  384 384\n"," 60/204 [=======>......................] - ETA: 1:20 - loss: 3.0663 - yolo_layer_1_loss: 1.7267e-04 - yolo_layer_2_loss: 0.2181 - yolo_layer_3_loss: 2.8481resizing:  352 352\n"," 77/204 [==========>...................] - ETA: 1:10 - loss: 3.1590 - yolo_layer_1_loss: 1.7334e-04 - yolo_layer_2_loss: 0.1940 - yolo_layer_3_loss: 2.9648resizing:  448 448\n"," 78/204 [==========>...................] - ETA: 1:09 - loss: 3.1823 - yolo_layer_1_loss: 1.7302e-04 - yolo_layer_2_loss: 0.1916 - yolo_layer_3_loss: 2.9905resizing:  448 448\n","106/204 [==============>...............] - ETA: 56s - loss: 3.0786 - yolo_layer_1_loss: 1.8354e-04 - yolo_layer_2_loss: 0.1789 - yolo_layer_3_loss: 2.8995resizing:  448 448\n","118/204 [================>.............] - ETA: 50s - loss: 3.0982 - yolo_layer_1_loss: 1.8894e-04 - yolo_layer_2_loss: 0.1815 - yolo_layer_3_loss: 2.9165resizing:  384 384\n","124/204 [=================>............] - ETA: 47s - loss: 3.0574 - yolo_layer_1_loss: 1.9026e-04 - yolo_layer_2_loss: 0.1770 - yolo_layer_3_loss: 2.8802resizing:  384 384\n","126/204 [=================>............] - ETA: 46s - loss: 3.0648 - yolo_layer_1_loss: 1.9123e-04 - yolo_layer_2_loss: 0.1742 - yolo_layer_3_loss: 2.8905resizing:  384 384\n","128/204 [=================>............] - ETA: 45s - loss: 3.1414 - yolo_layer_1_loss: 1.9213e-04 - yolo_layer_2_loss: 0.2105 - yolo_layer_3_loss: 2.9307resizing:  416 416\n","131/204 [==================>...........] - ETA: 43s - loss: 3.1284 - yolo_layer_1_loss: 1.9159e-04 - yolo_layer_2_loss: 0.2057 - yolo_layer_3_loss: 2.9225resizing:  384 384\n","158/204 [======================>.......] - ETA: 27s - loss: 3.1965 - yolo_layer_1_loss: 1.8841e-04 - yolo_layer_2_loss: 0.1879 - yolo_layer_3_loss: 3.0084resizing:  352 352\n","168/204 [=======================>......] - ETA: 21s - loss: 3.1979 - yolo_layer_1_loss: 1.8685e-04 - yolo_layer_2_loss: 0.1813 - yolo_layer_3_loss: 3.0164resizing:  448 448\n","176/204 [========================>.....] - ETA: 16s - loss: 3.1609 - yolo_layer_1_loss: 1.8572e-04 - yolo_layer_2_loss: 0.1733 - yolo_layer_3_loss: 2.9874resizing:  352 352\n","180/204 [=========================>....] - ETA: 13s - loss: 3.1519 - yolo_layer_1_loss: 1.8569e-04 - yolo_layer_2_loss: 0.1734 - yolo_layer_3_loss: 2.9783resizing:  416 416\n","182/204 [=========================>....] - ETA: 12s - loss: 3.1342 - yolo_layer_1_loss: 1.8590e-04 - yolo_layer_2_loss: 0.1715 - yolo_layer_3_loss: 2.9625resizing:  416 416\n","192/204 [===========================>..] - ETA: 7s - loss: 3.1605 - yolo_layer_1_loss: 1.8710e-04 - yolo_layer_2_loss: 0.1677 - yolo_layer_3_loss: 2.9926resizing:  384 384\n","204/204 [==============================] - 120s 587ms/step - loss: 3.1720 - yolo_layer_1_loss: 1.8813e-04 - yolo_layer_2_loss: 0.1679 - yolo_layer_3_loss: 3.0039\n","\n","Epoch 00063: loss did not improve from 2.93947\n","Epoch 64/103\n","resizing:  384 384\n","  1/204 [..............................] - ETA: 1:46 - loss: 4.5650 - yolo_layer_1_loss: 1.5635e-04 - yolo_layer_2_loss: 8.0387e-04 - yolo_layer_3_loss: 4.5640resizing:  384 384\n","  8/204 [>.............................] - ETA: 1:47 - loss: 3.9983 - yolo_layer_1_loss: 1.6521e-04 - yolo_layer_2_loss: 7.8442e-04 - yolo_layer_3_loss: 3.9973resizing:  448 448\n","  9/204 [>.............................] - ETA: 1:47 - loss: 3.9152 - yolo_layer_1_loss: 1.6903e-04 - yolo_layer_2_loss: 7.8641e-04 - yolo_layer_3_loss: 3.9143resizing:  416 416\n"," 17/204 [=>............................] - ETA: 1:42 - loss: 3.5217 - yolo_layer_1_loss: 1.7458e-04 - yolo_layer_2_loss: 0.0552 - yolo_layer_3_loss: 3.4663resizing:  384 384\n"," 29/204 [===>..........................] - ETA: 1:42 - loss: 3.4230 - yolo_layer_1_loss: 1.8084e-04 - yolo_layer_2_loss: 0.1626 - yolo_layer_3_loss: 3.2603resizing:  352 352\n"," 50/204 [======>.......................] - ETA: 1:25 - loss: 3.5455 - yolo_layer_1_loss: 1.7356e-04 - yolo_layer_2_loss: 0.2341 - yolo_layer_3_loss: 3.3112resizing:  448 448\n"," 51/204 [======>.......................] - ETA: 1:24 - loss: 3.6116 - yolo_layer_1_loss: 1.7336e-04 - yolo_layer_2_loss: 0.2295 - yolo_layer_3_loss: 3.3819resizing:  384 384\n"," 56/204 [=======>......................] - ETA: 1:22 - loss: 3.5914 - yolo_layer_1_loss: 1.7347e-04 - yolo_layer_2_loss: 0.2503 - yolo_layer_3_loss: 3.3409resizing:  352 352\n"," 58/204 [=======>......................] - ETA: 1:21 - loss: 3.6481 - yolo_layer_1_loss: 1.7288e-04 - yolo_layer_2_loss: 0.2417 - yolo_layer_3_loss: 3.4062resizing:  384 384\n"," 62/204 [========>.....................] - ETA: 1:18 - loss: 3.5740 - yolo_layer_1_loss: 1.7221e-04 - yolo_layer_2_loss: 0.2402 - yolo_layer_3_loss: 3.3337resizing:  352 352\n"," 67/204 [========>.....................] - ETA: 1:15 - loss: 3.5905 - yolo_layer_1_loss: 1.7093e-04 - yolo_layer_2_loss: 0.2227 - yolo_layer_3_loss: 3.3676resizing:  416 416\n","105/204 [==============>...............] - ETA: 56s - loss: 3.3555 - yolo_layer_1_loss: 1.7650e-04 - yolo_layer_2_loss: 0.1567 - yolo_layer_3_loss: 3.1987resizing:  384 384\n","107/204 [==============>...............] - ETA: 55s - loss: 3.3147 - yolo_layer_1_loss: 1.7687e-04 - yolo_layer_2_loss: 0.1537 - yolo_layer_3_loss: 3.1608resizing:  416 416\n","120/204 [================>.............] - ETA: 48s - loss: 3.3583 - yolo_layer_1_loss: 1.7801e-04 - yolo_layer_2_loss: 0.1807 - yolo_layer_3_loss: 3.1774resizing:  352 352\n","126/204 [=================>............] - ETA: 45s - loss: 3.2954 - yolo_layer_1_loss: 1.7871e-04 - yolo_layer_2_loss: 0.1721 - yolo_layer_3_loss: 3.1231resizing:  448 448\n","133/204 [==================>...........] - ETA: 41s - loss: 3.3204 - yolo_layer_1_loss: 1.7920e-04 - yolo_layer_2_loss: 0.1772 - yolo_layer_3_loss: 3.1431resizing:  352 352\n","137/204 [===================>..........] - ETA: 38s - loss: 3.4041 - yolo_layer_1_loss: 1.7893e-04 - yolo_layer_2_loss: 0.2132 - yolo_layer_3_loss: 3.1907resizing:  352 352\n","154/204 [=====================>........] - ETA: 29s - loss: 3.3140 - yolo_layer_1_loss: 1.8028e-04 - yolo_layer_2_loss: 0.2114 - yolo_layer_3_loss: 3.1024resizing:  352 352\n","158/204 [======================>.......] - ETA: 26s - loss: 3.3110 - yolo_layer_1_loss: 1.7974e-04 - yolo_layer_2_loss: 0.2061 - yolo_layer_3_loss: 3.1047resizing:  448 448\n","166/204 [=======================>......] - ETA: 21s - loss: 3.3501 - yolo_layer_1_loss: 1.7941e-04 - yolo_layer_2_loss: 0.2043 - yolo_layer_3_loss: 3.1456resizing:  352 352\n","176/204 [========================>.....] - ETA: 16s - loss: 3.3216 - yolo_layer_1_loss: 1.8202e-04 - yolo_layer_2_loss: 0.1990 - yolo_layer_3_loss: 3.1224resizing:  352 352\n","180/204 [=========================>....] - ETA: 14s - loss: 3.3557 - yolo_layer_1_loss: 1.8173e-04 - yolo_layer_2_loss: 0.2026 - yolo_layer_3_loss: 3.1529resizing:  384 384\n","181/204 [=========================>....] - ETA: 13s - loss: 3.3544 - yolo_layer_1_loss: 1.8158e-04 - yolo_layer_2_loss: 0.2014 - yolo_layer_3_loss: 3.1528resizing:  352 352\n","203/204 [============================>.] - ETA: 0s - loss: 3.3259 - yolo_layer_1_loss: 1.7975e-04 - yolo_layer_2_loss: 0.1955 - yolo_layer_3_loss: 3.1302resizing:  384 384\n","204/204 [==============================] - 117s 573ms/step - loss: 3.3450 - yolo_layer_1_loss: 1.7968e-04 - yolo_layer_2_loss: 0.1995 - yolo_layer_3_loss: 3.1453\n","\n","Epoch 00064: loss did not improve from 2.93947\n","Epoch 00064: early stopping\n","danger: 0.9405\n","mandatory: 0.5877\n","other: 0.5488\n","prohibitory: 0.8656\n","mAP: 0.7357\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sbfLLZ3S_OZg"},"source":["infer_model.save_weights('/drive/My Drive/Dataset_TrafficSignals/gtsdb3_ONLY_WEIGHTS.weights')"],"execution_count":null,"outputs":[]}]}